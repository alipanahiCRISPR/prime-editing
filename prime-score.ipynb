{"cells":[{"cell_type":"markdown","metadata":{"id":"lknTxcvPjoza"},"source":["# Install package"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210429,"status":"ok","timestamp":1693456764097,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"Rq3WZBywzbOK","outputId":"84c799bc-ed3b-4a4e-b93f-ea72e1bf9b35"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: conda: command not found\n","/bin/bash: line 1: conda: command not found\n","Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n","Collecting git+https://github.com/Goosang-Yu/genet-models.git\n","  Cloning https://github.com/Goosang-Yu/genet-models.git to /tmp/pip-req-build-cq5vcocz\n","  Running command git clone --filter=blob:none --quiet https://github.com/Goosang-Yu/genet-models.git /tmp/pip-req-build-cq5vcocz\n","  Resolved https://github.com/Goosang-Yu/genet-models.git to commit b2cab377046542d665a17c3e6efcae971c9926f6\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting genet\n","  Downloading genet-0.9.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from genet) (1.5.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from genet) (2023.6.3)\n","Collecting biopython (from genet)\n","  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow==2.8.0 (from genet)\n","  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/dist-packages (from genet) (3.20.3)\n","Collecting silence-tensorflow (from genet)\n","  Downloading silence_tensorflow-1.2.1.tar.gz (3.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from genet) (9.0.0)\n","Collecting fastparquet (from genet)\n","  Downloading fastparquet-2023.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from genet) (4.66.1)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (23.5.26)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (3.9.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0->genet)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (4.7.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.14.1)\n","Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0->genet)\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0->genet)\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0->genet)\n","  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (0.33.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.57.0)\n","Collecting cramjam>=2.3 (from fastparquet->genet)\n","  Downloading cramjam-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet->genet) (2023.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet->genet) (23.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->genet) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->genet) (2023.3)\n","Collecting support_developer (from silence-tensorflow->genet)\n","  Downloading support_developer-1.0.5.tar.gz (4.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0->genet) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2.17.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet)\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2.3.7)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (3.2.2)\n","Building wheels for collected packages: genet-models, silence-tensorflow, support_developer\n","  Building wheel for genet-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for genet-models: filename=genet_models-1.1.0-py3-none-any.whl size=472873181 sha256=20002668099084e9932dd0752841e3706bcefe3c2907ac9e62a7d14f0ae4f504\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-hi0_3zai/wheels/83/27/01/a11e7f5f0200b1bcb21127b6c98bb346ecf074d30fd11502df\n","  Building wheel for silence-tensorflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for silence-tensorflow: filename=silence_tensorflow-1.2.1-py3-none-any.whl size=4464 sha256=b8da447ad869b18fd223c87ee7b933f69ea9f3c6f5f9935ed9fc0cca19c10963\n","  Stored in directory: /root/.cache/pip/wheels/7d/2c/24/e130d6102c0df56631b9db7479d9a6a53c5d97fb06b5f61b98\n","  Building wheel for support_developer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for support_developer: filename=support_developer-1.0.5-py3-none-any.whl size=5629 sha256=cce2becb64c575a49ad6925eaccf8c84ada2d7cff370bf8e36c1aad7db1a2e56\n","  Stored in directory: /root/.cache/pip/wheels/b6/72/c8/3054a5897ba0713dfa7a941364d68cbd42b0755c8e2ec1c18c\n","Successfully built genet-models silence-tensorflow support_developer\n","Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, support_developer, keras, tensorboard-data-server, silence-tensorflow, keras-preprocessing, genet-models, cramjam, biopython, google-auth-oauthlib, fastparquet, tensorboard, tensorflow, genet\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.1\n","    Uninstalling tensorboard-data-server-0.7.1:\n","      Successfully uninstalled tensorboard-data-server-0.7.1\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.3\n","    Uninstalling tensorboard-2.12.3:\n","      Successfully uninstalled tensorboard-2.12.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","Successfully installed biopython-1.81 cramjam-2.7.0 fastparquet-2023.8.0 genet-0.9.0 genet-models-1.1.0 google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 silence-tensorflow-1.2.1 support_developer-1.0.5 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"]}],"source":["!conda create -n genet python=3.8\n","!conda activate genet\n","\n","# install genet package in your env.\n","!pip3 install genet -f https://download.pytorch.org/whl/cu113/torch_stable.html git+https://github.com/Goosang-Yu/genet-models.git\n","\n","# install ViennaRNA package for prediction module\n","#!pip install viennarna"]},{"cell_type":"markdown","metadata":{"id":"In2HNtYqMExf"},"source":[" basic RNA secondary structure analysis software-                               مجموعه‌ای از ابزارها و کتابخانه‌های مستقل برای پیش‌بینی و تحلیل ساختار دوم اسید نوکلئیک است."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8973,"status":"ok","timestamp":1693456773066,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"OSx3Vg_08sZU","outputId":"27f5b8a9-dffe-48bb-d2a2-981141fd3239"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ViennaRNA\n","  Downloading ViennaRNA-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ViennaRNA\n","Successfully installed ViennaRNA-2.6.3\n"]}],"source":["!pip3 install ViennaRNA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7050,"status":"ok","timestamp":1693456780114,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"x08mrvhbDp9P","outputId":"879cc800-50b2-4cea-bab5-21ca49957e48"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting biopy\n","  Downloading biopy-0.1.2-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: biopy\n","Successfully installed biopy-0.1.2\n"]}],"source":["!pip3 install biopy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6269,"status":"ok","timestamp":1693456786380,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"iY70FXNLLdkR","outputId":"e1a62f1b-dd43-4f74-9d01-909f706c59a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting RNA\n","  Downloading rna-0.11.0-py3-none-any.whl (66 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m61.4/66.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from RNA) (3.7.1)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from RNA) (1.23.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->RNA) (1.16.0)\n","Installing collected packages: RNA\n","Successfully installed RNA-0.11.0\n"]}],"source":["!pip3 install RNA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eC-CjWZ2Nf5n"},"outputs":[],"source":["from genet import predict as prd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ch7nMbnfQWUn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xQ7IoOV7jeAW"},"source":["# Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsDP-5bkLX-o"},"outputs":[],"source":["#اینکدینگ مرحله 2----برای این 2 مرحله کردم که بتوانم تاثیر روش اینکدینگ خودم رو بسنجم\n","import numpy as np\n","\n","class Encoder:\n","    def __init__(self, seq_wt, seq_et, with_category = False, label = None, with_reg_val = False, value = None):\n","        tlen = 24\n","        self.seq_wt = \"-\" *(tlen-len(seq_wt)) +  seq_wt\n","        self.seq_et = \"-\" *(tlen-len(seq_et)) + seq_et\n","        self.encoded_dict_indel = {'A': [1, 0, 0, 0, 0], 'T': [0, 1, 0, 0, 0],\n","                                   'G': [0, 0, 1, 0, 0], 'C': [0, 0, 0, 1, 0], '_': [0, 0, 0, 0, 1], '-': [0, 0, 0, 0, 0]}\n","        self.direction_dict = {'A':5, 'G':4, 'C':3, 'T':2, '_':1}\n","        if with_category:\n","            self.label = label\n","        if with_reg_val:\n","            self.value = value\n","        self.encode_wt_ed()\n","\n","    def encode_seq_wt(self):\n","        code_list = []\n","        encoded_dict = self.encoded_dict_indel\n","        sgRNA_bases = list(self.seq_wt)\n","        for i in range(len(sgRNA_bases)):\n","            if sgRNA_bases[i] == \"N\":\n","                sgRNA_bases[i] = list(self.off_seq)[i]\n","            code_list.append(encoded_dict[sgRNA_bases[i]])\n","        self.sgRNA_code = np.array(code_list)\n","\n","    def encode_seq_et(self):\n","        code_list = []\n","        encoded_dict = self.encoded_dict_indel\n","        off_bases = list(self.seq_et)\n","        for i in range(len(off_bases)):\n","            code_list.append(encoded_dict[off_bases[i]])\n","        self.off_code = np.array(code_list)\n","\n","    def encode_wt_ed(self):\n","        self.encode_seq_wt()\n","        self.encode_seq_et()\n","        on_bases = list(self.seq_wt)\n","        off_bases = list(self.seq_et)\n","        on_off_dim7_codes = []\n","        for i in range(len(on_bases)):\n","            diff_code = np.bitwise_or(self.sgRNA_code[i], self.off_code[i])\n","            on_b = on_bases[i]\n","            off_b = off_bases[i]\n","            if on_b == \"N\":\n","                on_b = off_b\n","\n","            dir_code = np.zeros(2)\n","            if on_b == \"-\" or off_b == \"-\" or self.direction_dict[on_b] == self.direction_dict[off_b]:\n","                pass\n","            else:\n","                if self.direction_dict[on_b] > self.direction_dict[off_b]:\n","                    dir_code[0] = 1\n","                else:\n","                    dir_code[1] = 1\n","            on_off_dim7_codes.append(np.concatenate((diff_code, dir_code)))\n","        self.on_off_code = np.array(on_off_dim7_codes)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MOBrF1dOwdFN"},"source":["چک اینکدینگ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693456976458,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"nN7UHWHfwcAe","outputId":"fa97af29-ab16-4149-f3c0-92bd2d331b7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 1. 0. 1. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 1. 1. 0.]\n"," [0. 1. 1. 0. 0. 0. 1.]\n"," [0. 1. 1. 0. 0. 1. 0.]\n"," [1. 1. 0. 0. 0. 1. 0.]\n"," [0. 1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0.]\n"," [1. 0. 1. 0. 0. 1. 0.]]\n"]}],"source":["e = Encoder(seq_wt=\"AGCTGATTTTA\", seq_et=\"CG_GTTTTTTG\")\n","print(e.on_off_code)"]},{"cell_type":"markdown","source":["# Embedding"],"metadata":{"id":"vcwkAnYyDr39"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9U_4iDuAFYA8","executionInfo":{"status":"ok","timestamp":1693644604167,"user_tz":-210,"elapsed":13165,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"}},"outputId":"58434cd6-7926-454a-c446-d50be977efb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import DistilBertForSequenceClassification\n","\n","DNABERTmodel = DistilBertForSequenceClassification.from_pretrained('Peltarion/dnabert-distilbert')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["1c155b3d74c2405bb4540a3aaee253b8","813363e6576f45abb8c00adbc907dd57","1662bfe054944570af1d7a21eca7fa35","4823f9fc3386403395b7bc632beaaf20","b26e5762c972496f8bd3e6211580f764","f438617b09c246f6a7feb1e7fec7a970","481236939b3f4dc9bea725e98fa546ae","bea2b9b50ace43909f255dbc60807d2e","62070c96f5b14e9f88b434a274bf1fb4","982ebf474326463594631a06ae3c5f66","3dc5ba9278f44128995a28fc56e9b077","9632be642e1646158bee913582e8b44b","3b2b28054d1e4f4b96deeb7d5772d2e8","b2ae4a32e73c44e89aa90c5de9be3b5d","53ab2127905c45f086d458566ab4b290","8ffc0cd03e5d461fb6e20521917a2479","e07c3ae0af5e48429306c3bfd45e0eca","b0a0c52704dd45348fa390f7d746c3ea","ca5e8c834e734b81b3855549f6cb002d","54097f16bef749b1a81f7b319f6d8467","b3ac4c5365d84e28a235b868e498d57d","afebb2a91a314a82ad92a33afd6ca783"]},"id":"B1QZKw9iDpv_","executionInfo":{"status":"ok","timestamp":1693644619186,"user_tz":-210,"elapsed":15023,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"}},"outputId":"0491c3ad-a0d7-4e85-c87d-5ab6fd6254c4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/536 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c155b3d74c2405bb4540a3aaee253b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/187M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9632be642e1646158bee913582e8b44b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Peltarion/dnabert-distilbert and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","metadata":{"id":"01nhG_0KkKep"},"source":["# Main function for Prime Editing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jD96n2ON0yZ"},"outputs":[],"source":["#from genet.predict.models import DeepSpCas9, DeepPrime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ew80A06LSOon"},"outputs":[],"source":["# from genet.utils import *\n","import genet\n","import genet.utils\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","import inspect\n","\n","\n","\n","import os, sys, time, regex, logging\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow.compat.v1 as tf\n","\n","from glob import glob\n","from Bio.SeqUtils import MeltingTemp as mt\n","from Bio.SeqUtils import gc_fraction as gc\n","from Bio.Seq import Seq\n","from RNA import fold_compound  #compute minimum free energy (mfe)\n","\n","np.set_printoptions(threshold=sys.maxsize)\n","tf.disable_v2_behavior()\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","\n","\n","\n","\n","#تعریف مدل در کریسپر\n","\n","class Deep_xCas9(object):\n","    def __init__(self, filter_size, filter_num, node_1=80, node_2=60, l_rate=0.005):\n","        length = 30\n","        self.inputs = tf.placeholder(tf.float32, [None, 1, length, 4])\n","        self.targets = tf.placeholder(tf.float32, [None, 1])\n","        self.is_training = tf.placeholder(tf.bool)\n","\n","\n","#این لایه ها با توجه به مدل انتخاب شده برای اسکور دهی تعریف می شوند.\"\n","\n","        def create_new_conv_layer(input_data, num_input_channels, num_filters, filter_shape, pool_shape, name):\n","            # setup the filter input shape for tf.nn.conv_2d\n","            conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,\n","                               num_filters]\n","\n","            # initialise weights and bias for the filter\n","            weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev=0.03), name=name + '_W')\n","            bias = tf.Variable(tf.truncated_normal([num_filters]), name=name + '_b')\n","\n","            # setup the convolutional layer operation\n","            out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='VALID')\n","\n","            # add the bias\n","            out_layer += bias\n","\n","            # apply a ReLU non-linear activation\n","            out_layer = tf.layers.dropout(tf.nn.relu(out_layer), 0.3, self.is_training)\n","\n","            # now perform max pooling\n","            ksize = [1, pool_shape[0], pool_shape[1], 1]\n","            strides = [1, 1, 2, 1]\n","            out_layer = tf.nn.avg_pool(out_layer, ksize=ksize, strides=strides, padding='SAME')\n","\n","            return out_layer\n","\n","        # def end: create_new_conv_layer\n","\n","        L_pool_0 = create_new_conv_layer(self.inputs, 4, filter_num[0], [1, filter_size[0]], [1, 2], name='conv1')\n","        L_pool_1 = create_new_conv_layer(self.inputs, 4, filter_num[1], [1, filter_size[1]], [1, 2], name='conv2')\n","        L_pool_2 = create_new_conv_layer(self.inputs, 4, filter_num[2], [1, filter_size[2]], [1, 2], name='conv3')\n","\n","        with tf.variable_scope('Fully_Connected_Layer1'):\n","            layer_node_0 = int((length - filter_size[0]) / 2) + 1\n","            node_num_0   = layer_node_0 * filter_num[0]\n","            layer_node_1 = int((length - filter_size[1]) / 2) + 1\n","            node_num_1   = layer_node_1 * filter_num[1]\n","            layer_node_2 = int((length - filter_size[2]) / 2) + 1\n","            node_num_2   = layer_node_2 * filter_num[2]\n","\n","            L_flatten_0  = tf.reshape(L_pool_0, [-1, node_num_0])\n","            L_flatten_1  = tf.reshape(L_pool_1, [-1, node_num_1])\n","            L_flatten_2  = tf.reshape(L_pool_2, [-1, node_num_2])\n","            L_flatten    = tf.concat([L_flatten_0, L_flatten_1, L_flatten_2], 1, name='concat')\n","\n","            node_num     = node_num_0 + node_num_1 + node_num_2\n","            W_fcl1       = tf.get_variable(\"W_fcl1\", shape=[node_num, node_1])\n","            B_fcl1       = tf.get_variable(\"B_fcl1\", shape=[node_1])\n","            L_fcl1_pre   = tf.nn.bias_add(tf.matmul(L_flatten, W_fcl1), B_fcl1)\n","            L_fcl1       = tf.nn.relu(L_fcl1_pre)\n","            L_fcl1_drop  = tf.layers.dropout(L_fcl1, 0.3, self.is_training)\n","\n","        with tf.variable_scope('Fully_Connected_Layer2'):\n","            W_fcl2       = tf.get_variable(\"W_fcl2\", shape=[node_1, node_2])\n","            B_fcl2       = tf.get_variable(\"B_fcl2\", shape=[node_2])\n","            L_fcl2_pre   = tf.nn.bias_add(tf.matmul(L_fcl1_drop, W_fcl2), B_fcl2)\n","            L_fcl2       = tf.nn.relu(L_fcl2_pre)\n","            L_fcl2_drop  = tf.layers.dropout(L_fcl2, 0.3, self.is_training)\n","\n","        with tf.variable_scope('Output_Layer'):\n","            W_out        = tf.get_variable(\"W_out\", shape=[node_2, 1])\n","            B_out        = tf.get_variable(\"B_out\", shape=[1])\n","            self.outputs = tf.nn.bias_add(tf.matmul(L_fcl2_drop, W_out), B_out)\n","\n","        # Define loss function and optimizer\n","        self.obj_loss    = tf.reduce_mean(tf.square(self.targets - self.outputs))\n","        self.optimizer   = tf.train.AdamOptimizer(l_rate).minimize(self.obj_loss)\n","\n","    # def end: def __init__\n","# class end: Deep_xCas9\n","\n","#این تابع با توجه به مدل از پیش آموزش دیده اسکور همه رشته های طراحی شده را حساب می کند.\"\n","def Model_Finaltest(sess, TEST_X, model):\n","    test_batch = 500\n","    TEST_Z = np.zeros((TEST_X.shape[0], 1), dtype=float)\n","\n","# به ازای هر 500 تا از مدل تعریف شده در بالا درخواست خروجی می کنیم.\n","    for i in range(int(np.ceil(float(TEST_X.shape[0]) / float(test_batch)))):\n","        Dict = {model.inputs: TEST_X[i * test_batch:(i + 1) * test_batch], model.is_training: False}\n","        TEST_Z[i * test_batch:(i + 1) * test_batch] = sess.run([model.outputs], feed_dict=Dict)[0]\n","#  این برای حالتی است که طول دنباله بیش از 500 است ولی طول دنباله من 63 است و این جمع در واقع جمع اسکور عوامل تاثیرگذار است.\n","    list_score = sum(TEST_Z.tolist(), [])\n","\n","    return list_score\n","\n","\n","# def end: Model_Finaltest\n","\n","\n","#این تابع برای  اینکدینگ مرحله 1 است\"\n","def preprocess_seq(data, seq_length):\n","\n","    seq_onehot = np.zeros((len(data), 1, seq_length, 4), dtype=float)\n","\n","    for l in range(len(data)):\n","        for i in range(seq_length):\n","            try:\n","                data[l][i]\n","            except Exception:\n","                print(data[l], i, seq_length, len(data))\n","\n","            if   data[l][i] in \"Aa\":  seq_onehot[l, 0, i, 0] = 1\n","            elif data[l][i] in \"Cc\":  seq_onehot[l, 0, i, 1] = 1\n","            elif data[l][i] in \"Gg\":  seq_onehot[l, 0, i, 2] = 1\n","            elif data[l][i] in \"Tt\":  seq_onehot[l, 0, i, 3] = 1\n","            elif data[l][i] in \"Xx\":  pass\n","            elif data[l][i] in \"Nn.\": pass\n","            else:\n","                print(\"[Input Error] Non-ATGC character \" + data[l])\n","                sys.exit()\n","\n","    return seq_onehot\n","\n","#  برای فراخوانی تابعی که در بالال برای اینکدینگ تعریف کردم\n","def preprocess_seq2(seq_wt, seq_et):\n","\n","    e = Encoder(seq_wt, seq_et)\n","\n","    #self.on_off_code = np.array(on_off_dim7_codes)\n","    #return self.on_off_code\n","\n","\n","#\"اسکور دهی بر اساس کریسپر و مدل انتخابی\"\n","def spcas9_score(list_target30:list , gpu_env=0):\n","    '''\n","    input:: list_target  with length 30 n\n","    The list_target30 should have a 30bp sequence in the form of a list.\n","    Also, sequence [24:27] should contain NGG PAM.\n","    >>> list_out = spcas9_score(list_target30)\n","\n","\n","'''\n","  #  best_model را تغییر دادم در ادامه شاید \"\n","  #در حال حاضر از مدل سایر محققین استفاده می کنم\"\n","\n","  # TensorFlow config\n","    conf = tf.ConfigProto()\n","    conf.gpu_options.allow_growth = True\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '%d' % gpu_env\n","\n","    x_test = preprocess_seq(list_target30, 30)\n","\n","    from genet_models import load_\n","\n","\n","\n","    model_dir = load_deepspcas9()\n","\n","    best_model_path = model_dir\n","    best_model = 'PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60'\n","\n","    model_save = '%s/%s' % (best_model_path, best_model)\n","# شبکه کانولوشنی که در بالا تعریف کردم براساس این پارامترها ساخته می شود.\n","    filter_size = [3, 5, 7]\n","    filter_num  = [100, 70, 40]\n","    args        = [filter_size, filter_num, 0.001, 550]\n","\n","    tf.reset_default_graph()\n","\n","    with tf.Session(config=conf) as sess:\n","        sess.run(tf.global_variables_initializer())\n","        model = Deep_xCas9(filter_size, filter_num, 80, 60, args[2])\n","\n","        saver = tf.train.Saver()\n","        saver.restore(sess, model_save)\n","# تابع اسکور دهی در اینجا و بعد مشخص کردم مدل انتخابی فراخوانی می شود.\n","        list_score = Model_Finaltest(sess, x_test, model)\n","\n","    return list_score\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","#تعریف مدل در پرایم ادیتینگ\n","\n","#\" 3اتابع زیر برای کارهای پرایم ادیتینگ است ولی نمی دانم دقیقا چه می کنند ولی بودنشان برای ساخت تمام رشته های راهنمایی ممکن  ضروری است.\"\n","# پیش پردازش برای پرایم ادیتینگ\n","def reverse_complement(sSeq):\n","    dict_sBases = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N', 'U': 'U', 'n': '',\n","                   '.': '.', '*': '*', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}\n","    list_sSeq = list(sSeq)  # Turns the sequence in to a gigantic list\n","    list_sSeq = [dict_sBases[sBase] for sBase in list_sSeq]\n","    return ''.join(list_sSeq)[::-1]\n","\n","# def END: reverse_complement\n","\n","def set_alt_position_window(sStrand, sAltKey, nAltIndex, nIndexStart, nIndexEnd, nAltLen):\n","    if sStrand == '+':\n","\n","        if sAltKey.startswith('sub'):\n","            return (nAltIndex + 1) - (nIndexStart - 3)\n","        else:\n","            return (nAltIndex + 1) - (nIndexStart - 3)\n","\n","    else:\n","        if sAltKey.startswith('sub'):\n","            return nIndexEnd - nAltIndex + 3 - (nAltLen - 1)\n","\n","        elif sAltKey.startswith('del'):\n","            return nIndexEnd - nAltIndex + 3 - nAltLen\n","\n","        else:\n","            return nIndexEnd - nAltIndex + 3 + nAltLen\n","        # if END:\n","    # if END:\n","\n","# def END: set_alt_position_window\n","\n","\n","def set_PAM_nicking_pos(sStrand, sAltType, nAltLen, nAltIndex, nIndexStart, nIndexEnd):\n","    if sStrand == '-':\n","        nPAM_Nick = nIndexEnd + 3\n","    else:\n","        nPAM_Nick = nIndexStart - 3\n","\n","    return nPAM_Nick\n","\n","# def END: set_PAM_Nicking_Pos\n","\n","\n","def check_PAM_window(dict_sWinSize, sStrand, nIndexStart, nIndexEnd, sAltType, nAltLen, nAltIndex):\n","    nUp, nDown = dict_sWinSize[sAltType][nAltLen]\n","\n","    if sStrand == '+':\n","        nPAMCheck_min = nAltIndex - nUp + 1\n","        nPAMCheck_max = nAltIndex + nDown + 1\n","    else:\n","        nPAMCheck_min = nAltIndex - nDown + 1\n","        nPAMCheck_max = nAltIndex + nUp + 1\n","    # if END:\n","\n","    if nIndexStart < nPAMCheck_min or nIndexEnd > nPAMCheck_max:\n","        return 0\n","    else:\n","        return 1\n","\n","# def END: check_PAM_window\n","\n","\n","\n","#ویژگی های دخیل در دقت ویرایش پرایم ادیتینگ استخراج و  بر اساس آنها اسکور نهایی پرایم ادیتینگ حساب می شود.\"\n","class FeatureExtraction:\n","    def __init__(self):\n","        self.sGuideKey = ''\n","        self.sChrID = ''\n","        self.sStrand = ''\n","        self.nGenomicPos = 0\n","        self.nEditIndex = 0\n","        self.nPBSLen = 0\n","        self.nRTTLen = 0\n","        self.sPBSSeq = ''\n","        self.sRTSeq = ''\n","        self.sPegRNASeq = ''\n","        self.sWTSeq = ''\n","        self.sEditedSeq = ''\n","        self.list_sSeqs = []\n","        self.type_sub = 0\n","        self.type_ins = 0\n","        self.type_del = 0\n","        self.fTm1 = 0.0 # temp of melting\n","        self.fTm2 = 0.0\n","        self.fTm2new = 0.0\n","        self.fTm3 = 0.0\n","        self.fTm4 = 0.0\n","        self.fTmD = 0.0\n","        self.fMFE3 = 0.0 # minimum free energy (mfe)\n","        self.fMFE4 = 0.0\n","        self.nGCcnt1 = 0\n","        self.nGCcnt2 = 0\n","        self.nGCcnt3 = 0\n","        self.fGCcont1 = 0.0\n","        self.fGCcont2 = 0.0\n","        self.fGCcont3 = 0.0\n","        self.dict_sSeqs = {}\n","        self.dict_sCombos = {}\n","        self.dict_sOutput = {}\n","\n","    # def End: __init__\n","\n","\n","\n","  #\"   با توجه به ورودی که از کاربر می گیریم متغییر ها مقدار دهی می شود  من فعلا 3 متغییر را می گیرم \"\n","  #\"بعد تعریف پوسته برنامه این قسمت تغییر خواهد کرد.\"\n","    def get_input(self, wt_seq, ed_seq, edit_type, edit_len):\n","        self.sWTSeq = wt_seq.upper()\n","        self.sEditedSeq = ed_seq.upper()\n","        self.sAltKey = edit_type + str(edit_len)\n","        self.sAltType = edit_type\n","        self.nAltLen = edit_len\n","\n","        if   self.sAltType.startswith('sub'): self.type_sub = 1\n","        elif self.sAltType.startswith('del'): self.type_del = 1\n","        elif self.sAltType.startswith('ins'): self.type_ins = 1\n","\n","    # def End: get_input\n","\n","\n","\n","\n","   #\"بعد گرفتن پارامترها از کاربر تمام رشته های راهنمای ممکن باید طراحی و سپس اسکور دهی شوند.\"\n","   #\"برای ساخت تمام رشته های ممکن از کد های گیتاپ استفاده کرده ام.\"\n","\n","   #\" RT_PBS اول تمام \"\n","   #\"pegRNA بعد تمام \"\n","\n","    def get_sAltNotation(self, nAltIndex):\n","        if self.sAltType == 'sub':\n","            self.sAltNotation = '%s>%s' % (\n","                self.sWTSeq[nAltIndex:nAltIndex + self.nAltLen], self.sEditedSeq[nAltIndex:nAltIndex + self.nAltLen])\n","\n","        elif self.sAltType == 'del':\n","            self.sAltNotation = '%s>%s' % (\n","                self.sWTSeq[nAltIndex:nAltIndex + 1 + self.nAltLen], self.sEditedSeq[nAltIndex])\n","\n","        else:\n","            self.sAltNotation = '%s>%s' % (\n","                self.sWTSeq[nAltIndex], self.sEditedSeq[nAltIndex:nAltIndex + self.nAltLen + 1])\n","\n","    # def END: get_sAltNotation\n","\n","    def get_all_RT_PBS(self,\n","                    nAltIndex,\n","                    nMinPBS = 0,\n","                    nMaxPBS = 17,\n","                    nMaxRT = 40,\n","                    nSetPBSLen = 0,\n","                    nSetRTLen = 0,\n","                    pe_system = 'PE2'\n","                    ):\n","        \"\"\"\n","        nMinPBS: If you set specific number, lower than MinPBS will be not generated. Default=0\n","        nMaxPBS: If you set specific number, higher than MinPBS will be not generated. Default=17\n","        nMaxRT = : If you set specific number, higher than MinPBS will be not generated. Default=40\n","        nSetPBSLen = 0  # Fix PBS Len: Set if >0\n","        nSetRTLen = 0  # Fix RT  Len: Set if >0\n","        PAM: 4-nt sequence\n","        \"\"\"\n","\n","        nMaxEditPosWin = nMaxRT + 3  # Distance between PAM and mutation\n","\n","        dict_sWinSize = {'sub': {1: [nMaxRT - 1 - 3, 6], 2: [nMaxRT - 2 - 3, 6], 3: [nMaxRT - 3 - 3, 6]},\n","                        'ins': {1: [nMaxRT - 2 - 3, 6], 2: [nMaxRT - 3 - 3, 6], 3: [nMaxRT - 4 - 3, 6]},\n","                        'del': {1: [nMaxRT - 1 - 3, 6], 2: [nMaxRT - 1 - 3, 6], 3: [nMaxRT - 1 - 3, 6]}}\n","\n","\n","        if 'NRCH' in pe_system: # for NRCH-PE PAM\n","            dict_sRE = {'+': '[ACGT][ACGT]G[ACGT]|[ACGT][CG]A[ACGT]|[ACGT][AG]CC|[ATCG]ATG',\n","                        '-': '[ACGT]C[ACGT][ACGT]|[ACGT]T[CG][ACGT]|G[GT]T[ACGT]|ATT[ACGT]|CAT[ACGT]|GGC[ACGT]|GTA[ACGT]'}\n","        else:\n","            dict_sRE = {'+': '[ACGT]GG[ACGT]', '-': '[ACGT]CC[ACGT]'} # for Original-PE PAM\n","\n","        for sStrand in ['+', '-']:\n","\n","            sRE = dict_sRE[sStrand]\n","            for sReIndex in regex.finditer(sRE, self.sWTSeq, overlapped=True):\n","\n","                if sStrand == '+':\n","                    nIndexStart = sReIndex.start()\n","                    nIndexEnd = sReIndex.end() - 1\n","                    sPAMSeq = self.sWTSeq[nIndexStart:nIndexEnd]\n","                    sGuideSeq = self.sWTSeq[nIndexStart - 20:nIndexEnd]\n","                else:\n","                    nIndexStart = sReIndex.start() + 1\n","                    nIndexEnd = sReIndex.end()\n","                    sPAMSeq = reverse_complement(self.sWTSeq[nIndexStart:nIndexEnd])\n","                    sGuideSeq = reverse_complement(self.sWTSeq[nIndexStart:nIndexEnd + 20])\n","\n","                nAltPosWin = set_alt_position_window(sStrand, self.sAltKey, nAltIndex, nIndexStart, nIndexEnd,\n","                                                    self.nAltLen)\n","\n","                ## AltPosWin Filter ##\n","                if nAltPosWin <= 0:             continue\n","                if nAltPosWin > nMaxEditPosWin: continue\n","\n","                nPAM_Nick = set_PAM_nicking_pos(sStrand, self.sAltType, self.nAltLen, nAltIndex, nIndexStart, nIndexEnd)\n","\n","                if not check_PAM_window(dict_sWinSize, sStrand, nIndexStart, nIndexEnd, self.sAltType, self.nAltLen,\n","                                        nAltIndex): continue\n","\n","                sPAMKey = '%s,%s,%s,%s,%s,%s,%s' % (\n","                    self.sAltKey, self.sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq)\n","\n","                dict_sRT, dict_sPBS = self.determine_PBS_RT_seq(sStrand, nMinPBS, nMaxPBS, nMaxRT, nSetPBSLen,\n","                                                        nSetRTLen, nAltIndex, nPAM_Nick, nAltPosWin, self.sEditedSeq)\n","\n","                nCnt1, nCnt2 = len(dict_sRT), len(dict_sPBS)\n","                if nCnt1 == 0: continue\n","                if nCnt2 == 0: continue\n","\n","                if sPAMKey not in self.dict_sSeqs:\n","                    self.dict_sSeqs[sPAMKey] = ''\n","                self.dict_sSeqs[sPAMKey] = [dict_sRT, dict_sPBS]\n","\n","            # loop END: sReIndex\n","        # loop END: sStrand\n","\n","\n","    # def END: get_all_RT_PBS\n","\n","\n","\n"," #\"pegRNA تمام \"\n","\n","    def determine_PBS_RT_seq(self, sStrand, nMinPBS, nMaxPBS, nMaxRT, nSetPBSLen, nSetRTLen, nAltIndex, nPAM_Nick,\n","                            nAltPosWin, sForTempSeq):\n","        dict_sPBS = {}\n","        dict_sRT = {}\n","\n","        list_nPBSLen = [nNo + 1 for nNo in range(nMinPBS, nMaxPBS)]\n","        for nPBSLen in list_nPBSLen:\n","\n","            ## Set PBS Length ##\n","            if nSetPBSLen:\n","                if nPBSLen != nSetPBSLen: continue\n","\n","            if sStrand == '+':\n","                nPBSStart = nPAM_Nick - nPBSLen  # 5' -> PamNick\n","                nPBSEnd = nPAM_Nick\n","                sPBSSeq = sForTempSeq[nPBSStart:nPBSEnd] # sForTempSeq = self.EditedSeq\n","\n","            else:\n","                if self.sAltKey.startswith('sub'):\n","                    nPBSStart = nPAM_Nick\n","                elif self.sAltKey.startswith('ins'):\n","                    nPBSStart = nPAM_Nick + self.nAltLen\n","                elif self.sAltKey.startswith('del'):\n","                    nPBSStart = nPAM_Nick - self.nAltLen\n","\n","                sPBSSeq = reverse_complement(sForTempSeq[nPBSStart:nPBSStart + nPBSLen]) # sForTempSeq = self.EditedSeq\n","\n","            # if END: sStrand\n","\n","            sKey = len(sPBSSeq)\n","            if sKey not in dict_sPBS:\n","                dict_sPBS[sKey] = ''\n","            dict_sPBS[sKey] = sPBSSeq\n","        # loop END: nPBSLen\n","\n","        if sStrand == '+':\n","            if self.sAltKey.startswith('sub'):\n","                list_nRTPos = [nNo + 1 for nNo in range(nAltIndex + self.nAltLen, (nPAM_Nick + nMaxRT))]\n","            elif self.sAltKey.startswith('ins'):\n","                list_nRTPos = [nNo + 1 for nNo in range(nAltIndex + self.nAltLen, (nPAM_Nick + nMaxRT))]\n","            else:\n","                list_nRTPos = [nNo + 1 for nNo in range(nAltIndex, (nPAM_Nick + nMaxRT))]\n","        else:\n","            if self.sAltKey.startswith('sub'):\n","                list_nRTPos = [nNo for nNo in range(nPAM_Nick - 1 - nMaxRT, nAltIndex)]\n","            else:\n","                list_nRTPos = [nNo for nNo in range(nPAM_Nick - 3 - nMaxRT, nAltIndex + self.nAltLen - 1)]\n","        for nRTPos in list_nRTPos:\n","\n","            if sStrand == '+':\n","                nRTStart = nPAM_Nick  # PamNick -> 3'\n","                nRTEnd = nRTPos\n","                sRTSeq = sForTempSeq[nRTStart:nRTEnd]\n","\n","            else:\n","                if self.sAltKey.startswith('sub'):\n","                    nRTStart = nRTPos\n","                    nRTEnd = nPAM_Nick  # PamNick -> 3'\n","                elif self.sAltKey.startswith('ins'):\n","                    nRTStart = nRTPos\n","                    nRTEnd = nPAM_Nick + self.nAltLen  # PamNick -> 3'\n","                elif self.sAltKey.startswith('del'):\n","                    nRTStart = nRTPos\n","                    nRTEnd = nPAM_Nick - self.nAltLen  # PamNick -> 3'\n","\n","                sRTSeq = reverse_complement(sForTempSeq[nRTStart:nRTEnd])\n","\n","                if not sRTSeq: continue\n","            # if END: sStrand\n","\n","            sKey = len(sRTSeq)\n","\n","            ## Set RT Length ##\n","            if nSetRTLen:\n","                if sKey != nSetRTLen: continue\n","\n","            ## Limit Max RT len ##\n","            if sKey > nMaxRT: continue\n","\n","            ## min RT from nick site to mutation ##\n","            if self.sAltKey.startswith('sub'):\n","                if sStrand == '+':\n","                    if sKey < abs(nAltIndex - nPAM_Nick): continue\n","                else:\n","                    if sKey < abs(nAltIndex - nPAM_Nick + self.nAltLen - 1): continue ###\n","            else:\n","                if sStrand == '-':\n","                    if sKey < abs(nAltIndex - nPAM_Nick + self.nAltLen - 1): continue\n","\n","            if self.sAltKey.startswith('ins'):\n","                if sKey < nAltPosWin + 1: continue\n","\n","            if sKey not in dict_sRT:\n","                dict_sRT[sKey] = ''\n","            dict_sRT[sKey] = sRTSeq\n","        # loop END: nRTPos\n","\n","        return [dict_sRT, dict_sPBS]\n","\n","\n","    # def END: determine_PBS_RT_seq\n","\n","\n","\n","\n","\n","\n","\n","    def make_rt_pbs_combinations(self):\n","        for sPAMKey in self.dict_sSeqs:\n","\n","            dict_sRT, dict_sPBS = self.dict_sSeqs[sPAMKey]\n","\n","            list_sRT = [dict_sRT[sKey] for sKey in dict_sRT]\n","            list_sPBS = [dict_sPBS[sKey] for sKey in dict_sPBS]\n","\n","            if sPAMKey not in self.dict_sCombos:\n","                self.dict_sCombos[sPAMKey] = ''\n","            self.dict_sCombos[sPAMKey] = {'%s,%s' % (sRT, sPBS): {} for sRT in list_sRT for sPBS in list_sPBS}\n","        # loop END: sPAMKey\n","\n","\n","    # def END: make_rt_pbs_combinations\n","\n","# استخراج ویژگی های مهم دنباله های ورودی برای ساختار دوم\n","    def determine_seqs(self):\n","        for sPAMKey in self.dict_sSeqs:\n","\n","            sAltKey, sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq = sPAMKey.split(',')\n","            nAltPosWin = int(nAltPosWin)\n","            nNickIndex = int(nPAM_Nick)\n","\n","            # if sStrand == '+':\n","            #     sWTSeq74 = self.sWTSeq[nNickIndex - 21:nNickIndex + 53]\n","            # else:\n","            #     sWTSeq74 = reverse_complement(self.sWTSeq[nNickIndex - 53:nNickIndex + 21])\n","\n","            for sSeqKey in self.dict_sCombos[sPAMKey]:\n","\n","                sRTSeq, sPBSSeq = sSeqKey.split(',')\n","\n","                ## for Tm1\n","                sForTm1 = reverse_complement(sPBSSeq.replace('A', 'U'))\n","\n","                if sStrand == '+':\n","                    ## for Tm2\n","                    sForTm2 = self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq)]\n","\n","                    ## for Tm2new\n","                    if self.sAltType.startswith('sub'):\n","                        sForTm2new = self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq)]\n","                    elif self.sAltType.startswith('ins'):\n","                        sForTm2new = self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq) - self.nAltLen]\n","                    else:  # del\n","                        sForTm2new = self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq) + self.nAltLen]\n","\n","                    ## for Tm3\n","                    if self.sAltType.startswith('sub'):\n","                        sTm3antiSeq = reverse_complement(self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq)])\n","                    elif self.sAltType.startswith('ins'):\n","                        sTm3antiSeq = reverse_complement(self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq) - self.nAltLen])\n","                    else:  # del\n","                        sTm3antiSeq = reverse_complement(self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq) + self.nAltLen])\n","\n","                else:\n","                    ## for Tm2\n","                    sForTm2 = reverse_complement(self.sWTSeq[nNickIndex - len(sRTSeq):nNickIndex])\n","\n","                    ## for Tm2new\n","                    if self.sAltType.startswith('sub'):\n","                        sForTm2new = reverse_complement(self.sWTSeq[nNickIndex - len(sRTSeq):nNickIndex])\n","                    elif self.sAltType.startswith('ins'):\n","                        sForTm2new = reverse_complement(self.sWTSeq[nNickIndex - len(sRTSeq) + self.nAltLen:nNickIndex])\n","                    else:  # del\n","                        sForTm2new = reverse_complement(self.sWTSeq[nNickIndex - len(sRTSeq) - self.nAltLen:nNickIndex])\n","\n","                    ## for Tm3\n","                    if self.sAltType.startswith('sub'):\n","                        sTm3antiSeq = self.sWTSeq[nNickIndex - len(sRTSeq):nNickIndex]\n","                    elif self.sAltType.startswith('ins'):\n","                        sTm3antiSeq = self.sWTSeq[nNickIndex - len(sRTSeq) + self.nAltLen:nNickIndex]\n","                    else:  # del\n","                        sTm3antiSeq = self.sWTSeq[nNickIndex - len(sRTSeq) - self.nAltLen:nNickIndex]\n","\n","                # if END\n","\n","                sForTm3 = [sRTSeq, sTm3antiSeq]\n","\n","                ## for Tm4\n","                sForTm4 = [reverse_complement(sRTSeq.replace('A', 'U')), sRTSeq]\n","\n","\n","                self.dict_sCombos[sPAMKey][sSeqKey] = {'Tm1': sForTm1,\n","                                                        'Tm2': sForTm2,\n","                                                        'Tm2new': sForTm2new,\n","                                                        'Tm3': sForTm3,\n","                                                        'Tm4': sForTm4}\n","            # loop END: sSeqKey\n","        # loop END: sPAMKey\n","    # def END: determine_seqs\n","\n","\n","#\" تا اینجا تمام رشته های  PegRNA را تعریف کردم\"\n","\n","\n","#  \"حال ساختار دوم رشته ها \"\n","#   \"برای اسکور دهی کلا 3 نوع پارامتر در نظر گرفته می شود ویژگی های رشته های ورودی ، ساختار دوم و اینتراکشن ژن ها\"\n","#\"تا اینجا داشتیم  پارامترهای تاثیر گذار  را از ساختار رشته های ورودی استخراج می کردیم\n","#\" در ادامه ویژگی های مربوط به ساختار دوم ژن بررسی می شود.\"\n","\n","    def determine_secondary_structure(self):\n","        for sPAMKey in self.dict_sSeqs:\n","\n","            sAltKey, sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq = sPAMKey.split(',')\n","            list_sOutputKeys = ['Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD', 'nGCcnt1', 'nGCcnt2', 'nGCcnt3',\n","                        'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4']\n","\n","            if sPAMKey not in self.dict_sOutput:\n","                self.dict_sOutput[sPAMKey] = {}\n","\n","            for sSeqKey in self.dict_sCombos[sPAMKey]:\n","\n","                if sSeqKey not in self.dict_sOutput[sPAMKey]:\n","\n","                    self.dict_sOutput[sPAMKey][sSeqKey] = {sKey: '' for sKey in list_sOutputKeys}\n","\n","                self.determine_Tm(sPAMKey, sSeqKey)\n","                self.determine_GC(sPAMKey, sSeqKey)\n","                self.determine_MFE(sPAMKey, sSeqKey, sGuideSeq)\n","            # loop END: sSeqKey\n","        # loop END: sPAMKey\n","\n","\n","\n","#\"بررسی اینتراکشن ها \"\n","    def determine_Tm(self, sPAMKey, sSeqKey):\n","        sForTm1 = self.dict_sCombos[sPAMKey][sSeqKey]['Tm1']\n","        sForTm2 = self.dict_sCombos[sPAMKey][sSeqKey]['Tm2']\n","        sForTm2new = self.dict_sCombos[sPAMKey][sSeqKey]['Tm2new']\n","        sForTm3 = self.dict_sCombos[sPAMKey][sSeqKey]['Tm3']\n","        sForTm4 = self.dict_sCombos[sPAMKey][sSeqKey]['Tm4']\n","\n","        ## Tm1 DNA/RNA mm1 ##\n","        fTm1 = mt.Tm_NN(seq=Seq(sForTm1), nn_table=mt.R_DNA_NN1)\n","\n","        ## Tm2 DNA/DNA mm0 ##\n","        fTm2 = mt.Tm_NN(seq=Seq(sForTm2), nn_table=mt.DNA_NN3)\n","\n","        ## Tm2new DNA/DNA mm0 ##\n","        fTm2new = mt.Tm_NN(seq=Seq(sForTm2new), nn_table=mt.DNA_NN3)\n","\n","        ## Tm3 DNA/DNA mm1 ##\n","        if not sForTm3:\n","            fTm3 = 0\n","            fTm5 = 0\n","\n","        else:\n","            list_fTm3 = []\n","            for sSeq1, sSeq2 in zip(sForTm3[0], sForTm3[1]):\n","                try:\n","                    fTm3 = mt.Tm_NN(seq=sSeq1, c_seq=sSeq2, nn_table=mt.DNA_NN3)\n","                except ValueError:\n","                    continue\n","\n","                list_fTm3.append(fTm3)\n","            # loop END: sSeq1, sSeq2\n","\n","        # if END:\n","\n","        # Tm4 - revcom(AAGTcGATCC(RNA version)) + AAGTcGATCC\n","        fTm4 = mt.Tm_NN(seq=Seq(sForTm4[0]), nn_table=mt.R_DNA_NN1)\n","\n","        # Tm5 - Tm3 - Tm2\n","        fTm5 = fTm3 - fTm2\n","\n","        self.dict_sOutput[sPAMKey][sSeqKey]['Tm1'] = fTm1\n","        self.dict_sOutput[sPAMKey][sSeqKey]['Tm2'] = fTm2\n","        self.dict_sOutput[sPAMKey][sSeqKey]['Tm2new'] = fTm2new\n","        self.dict_sOutput[sPAMKey][sSeqKey]['Tm3'] = fTm3\n","        self.dict_sOutput[sPAMKey][sSeqKey]['Tm4'] = fTm4\n","        self.dict_sOutput[sPAMKey][sSeqKey]['TmD'] = fTm5\n","\n","    # def END: determine_Tm\n","\n","\n","    def determine_GC(self, sPAMKey, sSeqKey):\n","        sRTSeqAlt, sPBSSeq = sSeqKey.split(',')\n","\n","        self.nGCcnt1 = sPBSSeq.count('G') + sPBSSeq.count('C')\n","        self.nGCcnt2 = sRTSeqAlt.count('G') + sRTSeqAlt.count('C')\n","        self.nGCcnt3 = (sPBSSeq + sRTSeqAlt).count('G') + (sPBSSeq + sRTSeqAlt).count('C')\n","        self.fGCcont1 = 100 * gc(sPBSSeq)\n","        self.fGCcont2 = 100 * gc(sRTSeqAlt)\n","        self.fGCcont3 = 100 * gc(sPBSSeq + sRTSeqAlt)\n","        self.dict_sOutput[sPAMKey][sSeqKey]['nGCcnt1'] = self.nGCcnt1\n","        self.dict_sOutput[sPAMKey][sSeqKey]['nGCcnt2'] = self.nGCcnt2\n","        self.dict_sOutput[sPAMKey][sSeqKey]['nGCcnt3'] = self.nGCcnt3\n","        self.dict_sOutput[sPAMKey][sSeqKey]['fGCcont1'] = self.fGCcont1\n","        self.dict_sOutput[sPAMKey][sSeqKey]['fGCcont2'] = self.fGCcont2\n","        self.dict_sOutput[sPAMKey][sSeqKey]['fGCcont3'] = self.fGCcont3\n","\n","\n","    # def END: determine_GC\n","\n","    def determine_MFE(self, sPAMKey, sSeqKey, sGuideSeqExt):\n","\n","        sRTSeq, sPBSSeq = sSeqKey.split(',')\n","\n","        ## Set GuideRNA seq ##\n","        sGuideSeq = 'G' + sGuideSeqExt[1:-3] ## GN19 guide seq\n","\n","        # MFE_3 - RT + PBS + PolyT\n","        sInputSeq = reverse_complement(sPBSSeq + sRTSeq) + 'TTTTTT'\n","        sDBSeq, fMFE3 = fold_compound(sInputSeq).mfe()   #mfe= prediction of minimume free energe which refers to  the termodinamic stability of pegRNA-DNA interactions based on the sequence and structual features\n","        # MFE_4 - spacer only\n","        sInputSeq = sGuideSeq\n","        sDBSeq, fMFE4 = fold_compound(sInputSeq).mfe()\n","\n","        self.dict_sOutput[sPAMKey][sSeqKey]['MFE3'] = round(fMFE3, 1)\n","        self.dict_sOutput[sPAMKey][sSeqKey]['MFE4'] = round(fMFE4, 1)\n","\n","    # def END: determine_MFE\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","#\"این تابع برای مشخص  کردن ستون هایی است که در خروجی نمایش داده می شود.\"\n","#\" هر یک از این پارامترها را در بالا تعریف و حساب کرده ایم و حال نمایش می دهیم.\"\n","\n","#\"برای همه  رشته ها که اسکور آنها را حساب کردم این خروجی ها حساب می شود ولی من فقط 10 تا را نمایش می دهم.\"\n","\n","\n","    def make_output_df(self):\n","\n","        list_output = []\n","        list_sOutputKeys = ['Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD', 'nGCcnt1', 'nGCcnt2', 'nGCcnt3',\n","                        'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4']\n","\n","        for sPAMKey in self.dict_sSeqs:\n","\n","            sAltKey, sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq = sPAMKey.split(',')\n","            nNickIndex = int(nPAM_Nick)\n","\n","            if sStrand == '+':\n","                sWTSeq74 = self.sWTSeq[nNickIndex - 21:nNickIndex + 53]\n","                nEditPos = 61 - nNickIndex\n","            else:\n","                sWTSeq74 = reverse_complement(self.sWTSeq[nNickIndex - 53:nNickIndex + 21])\n","                if not self.sAltType.startswith('ins'):\n","                    nEditPos = nNickIndex - 60 - self.nAltLen + 1\n","                else:\n","                    nEditPos = nNickIndex - 59\n","\n","            for sSeqKey in self.dict_sOutput[sPAMKey]:\n","\n","                dict_seq = self.dict_sCombos[sPAMKey][sSeqKey]\n","                sRTTSeq, sPBSSeq = sSeqKey.split(',')\n","                PBSlen = len(sPBSSeq)\n","                RTlen = len(sRTTSeq)\n","\n","                sPBS_RTSeq = sPBSSeq + sRTTSeq\n","                s5Bufferlen = 21 - PBSlen\n","                s3Bufferlen = 53 - RTlen\n","                sEDSeq74 = 'x' * s5Bufferlen + sPBS_RTSeq + 'x' * s3Bufferlen\n","\n","                if self.sAltType.startswith('del'):\n","                    RHA_len = len(sRTTSeq) - nEditPos + 1\n","                else:\n","                    RHA_len = len(sRTTSeq) - nEditPos - self.nAltLen + 1\n","\n","\n","                list_sOut = [self.input_id, sWTSeq74, sEDSeq74,\n","                            len(sPBSSeq), len(sRTTSeq), len(sPBSSeq + sRTTSeq), nEditPos, self.nAltLen,\n","                            RHA_len, self.type_sub, self.type_ins, self.type_del\n","                            ] + [self.dict_sOutput[sPAMKey][sSeqKey][sKey] for sKey in list_sOutputKeys]\n","\n","                list_output.append(list_sOut)\n","\n","            # loop END: sSeqKey\n","\n","        hder_essen = ['ID', 'WT74_On', 'Edited74_On', 'PBSlen', 'RTlen', 'RT-PBSlen', 'Edit_pos', 'Edit_len', 'RHA_len',\n","                    'type_sub', 'type_ins', 'type_del','Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD',\n","                    'nGCcnt1', 'nGCcnt2', 'nGCcnt3', 'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4']\n","\n","        df_out = pd.DataFrame(list_output, columns=hder_essen)\n","\n","        # loop END: sPAMKey\n","\n","        return df_out\n","\n","# def END: make_output\n","\n","#\"برای اسکور دهی کلا 3 نوع پارامتر در نظر گرفته می شود ویژگی های رشته های ورودی ، ساختار دوم و اینتراکشن ژن ها\"\n","#\"تا اینجا داشتیم  پارامترهای تاثیر گذار  را از ساختار رشته های ورودی استخراج و ساختار دوم می کردیم\n","#\" در ادامه ویژگی های مربوط به اینتراکشن ژن ها بررسی می شود.\"\n","\n","\n","\n","\n","\n","\n","# ساخت یک شبکه CNN , GRU\n","#جدید برای پرایم\n","\n","class GeneInteractionModel(nn.Module):\n","\n","\n","    def __init__(self, hidden_size, num_layers, num_features=24, dropout=0.1):\n","        super(GeneInteractionModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        self.c1 = nn.Sequential(\n","            nn.Conv2d(in_channels=4, out_channels=128, kernel_size=(2, 3), stride=1, padding=(0, 1)),\n","            nn.BatchNorm2d(128),\n","            nn.GELU(),\n","        )\n","        self.c2 = nn.Sequential(\n","            nn.Conv1d(in_channels=128, out_channels=108, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm1d(108),\n","            nn.GELU(),\n","            nn.AvgPool1d(kernel_size=2, stride=2),\n","\n","            nn.Conv1d(in_channels=108, out_channels=108, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm1d(108),\n","            nn.GELU(),\n","            nn.AvgPool1d(kernel_size=2, stride=2),\n","\n","            nn.Conv1d(in_channels=108, out_channels=128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm1d(128),\n","            nn.GELU(),\n","            nn.AvgPool1d(kernel_size=2, stride=2),\n","        )\n","\n","        self.r = nn.GRU(128, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","\n","        self.s = nn.Linear(2 * hidden_size, 12, bias=False)\n","\n","        self.d = nn.Sequential(\n","            nn.Linear(num_features, 96, bias=False),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(96, 64, bias=False),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(64, 128, bias=False)\n","        )\n","\n","        self.head = nn.Sequential(\n","            nn.BatchNorm1d(140),\n","            nn.Dropout(dropout),\n","            nn.Linear(140, 1, bias=True),\n","        )\n","\n","    def forward(self, g, x):\n","        g = torch.squeeze(self.c1(g), 2)\n","        g = self.c2(g)\n","        g, _ = self.r(torch.transpose(g, 1, 2))\n","        g = self.s(g[:, -1, :])\n","\n","        x = self.d(x)\n","\n","        out = self.head(torch.cat((g, x), dim=1))\n","\n","        return F.softplus(out)\n","\n","\n","\n","\n","# شروع پایپ لاین اصلی\n","#ورودی هایی که از کاربر گرفتیم را به وان هات تبدیل می کند\n","def seq_concat(data, col1='WT74_On', col2='Edited74_On', seq_length=74):\n","#   wt = preprocess_seq2(data[col1], seq_length)\n","#   ed = preprocess_seq2(data[col2], seq_length)\n","\n","    wt = preprocess_seq(data[col1], seq_length)\n","    ed = preprocess_seq(data[col2], seq_length)\n","    g = np.concatenate((wt, ed), axis=1)\n","    g = 2 * g - 1\n","\n","    return g\n","\n"," #       1-the Tm (melting temperature) of the DNA:RNA hybrid from positions 16 - 20 of the sgRNA, i.e. the 5nts immediately proximal of the NGG PAM\n"," #       2-the Tm of the DNA:RNA hybrid from position 8 - 15 (i.e. 8 nt)\n"," #       3-the Tm of the DNA:RNA hybrid from position 3 - 7  (i.e. 5 nt)\n","#می خواهیم تک تک ویژگی ها را حساب و تعدادی از آنها را انتخاب و به عنوان ورودی به تابع مربوط به محاسبه اسکور می دهم.\n","def select_cols(data):\n","    features = data.loc[:, ['PBSlen', 'RTlen', 'RT-PBSlen', 'Edit_pos', 'Edit_len', 'RHA_len', 'type_sub',\n","                            'type_ins', 'type_del', 'Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD',\n","                            'nGCcnt1', 'nGCcnt2', 'nGCcnt3', 'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4', 'DeepSpCas9_score']]\n","\n","    return features\n","\n","\n","# برای محاسبه اسکور 3 ورودی می گیرد داده گرفته شده از کاربر، مدل پرایم و نوع سلول\n","def calculate_deepprime_score(df_input, pe_system='PE2max', cell_type='HEK293T'):\n","\n","    os.environ['CUDA_VISIBLE_DEVICES']='0'\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","#در ادامه کار با مدل برت من جایگزین می شود.\n","    from genet_models import load_deepprime\n","\n","    model_dir, model_type = load_deepprime(pe_system, cell_type)\n","\n","    mean = pd.read_csv('%s/DeepPrime_base/mean.csv' % model_dir, header=None, index_col=0).squeeze()\n","    std  = pd.read_csv('%s/DeepPrime_base/std.csv' % model_dir, header=None, index_col=0).squeeze()\n","\n","# در این خط ورودی را از کاربر می گیریم و تمام ویژگی ها را که در ابتدا تعریف کردیم را محاسبه می کنیم و در نهایت می خواهیم به عنوان ورودی به تابع مربوط به محاسبه اسکور بدهیم\n","    test_features = select_cols(df_input)\n","\n","    g_test = seq_concat(df_input)\n","\n","    # این وردی تابع مربوط به محاسبه اسکور است. دقت شود به جای مقادیر اصلی اختلاف آنها با میانگین به مدل داده می شود\n","    x_test = (test_features - mean) / std\n","\n","    g_test = torch.tensor(g_test, dtype=torch.float32, device=device)\n","    x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32, device=device)\n","\n","\n","    #  لود کردن مدل ها با توجه به تابعی که برای این کار نوشتم می خواهم چند مدل داشته باشم و از هر کدام خروجی بگیرم و میانگین پاسخ را به خروجی بفرستم\n","    models = [m_files for m_files in glob('%s/%s/*.pt' % (model_dir, model_type))]\n","    preds  = []\n","\n","    for m in models:\n","        model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)\n","        model.load_state_dict(torch.load(m))\n","        #محاسبه خروجی مدل که همان اسکور نهایی من است\n","        model.eval()\n","        with torch.no_grad():\n","            g, x = g_test, x_test\n","            g = g.permute((0, 3, 1, 2))\n","            pred = model(g, x).detach().cpu().numpy()\n","        preds.append(pred)\n","\n","    # میانگین پیش بینی ها\n","    preds = np.squeeze(np.array(preds))\n","    preds = np.mean(preds, axis=0)\n","    preds = np.exp(preds) - 1\n","\n","    return preds\n","\n","#فراخوانی تابعی که بر اساس مدل و ورودی ها پیش بینی ها را انجام می دهد\n","#تنها 3 تا از این متغییر ها در حال حاضر از کاربر گرفته می شود و بقیه با مقادیر اولیه مقدار دهی می شود در ادامه بعد از تعریف پوسته سایت این متغییر ها را از کاربر خواهیم گرفت.\n","# در پایان کد با فراخوانی این تابع اسکورها را محاسبه و چاپ می کنم.\n","def pe_score(Ref_seq: str,\n","            ED_seq: str,\n","            sAlt: str,\n","            sID:str       = 'Sample',\n","            pe_system:str = 'PE2max',\n","            cell_type:str = 'HEK293T',\n","            pbs_min:int   = 7,\n","            pbs_max:int   = 15,\n","            rtt_max:int   = 40\n","            ):\n","\n","    nAltIndex   = 60\n","    pbs_range   = [pbs_min, pbs_max]\n","    rtt_max     = rtt_max\n","    pe_system   = pe_system\n","\n","    edit_type   = sAlt[:-1].lower()\n","    edit_len    = int(sAlt[-1])\n","\n","    # check input parameters\n","    if pbs_max > 17: return print('sID:%s\\nPlease set PBS max length upto 17nt' % sID)\n","    if rtt_max > 40: return print('sID:%s\\nPlease set RTT max length upto 40nt' % sID)\n","    if edit_type not in ['sub', 'ins', 'del']: return print('sID:%s\\nPlease select proper edit type.\\nAvailable edit tyle: sub, ins, del' % sID)\n","    if edit_len > 3: return print('sID:%s\\nPlease set edit length upto 3nt. Available edit length range: 1~3nt' % sID)\n","    if edit_len < 1: return print('sID:%s\\nPlease set edit length at least 1nt. Available edit length range: 1~3nt' % sID)\n","\n","\n","#FeatureExtraction Class\n","# بتدا تمام رشته راهنما های ممکن ساخته می شود\n","# تابعی را فراخوانی می کنیم تا تمام ویژگی های مربوط به دنباله ها استخراج شود\n","# سپس اطلاعات مربوط به ساختار دوم\n","#در نهایت اطلاعات مربوط به اینتراکشن ژن ها\n","#تابع مربوط به استخراج اطلاعات مربوط به اینتراکشن ژن ها را دارم ولی هنوز نمی دانم چه اطلاعاتی در اسکور دهی پرایم ادیتینگ تاثیر گذار هستند تا آن را به مدل اضافه کنم.\n","\n","    cFeat = FeatureExtraction()\n","    cFeat.input_id = sID\n","    cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)\n","\n","    cFeat.get_sAltNotation(nAltIndex)\n","    cFeat.get_all_RT_PBS(nAltIndex, nMinPBS=pbs_range[0]-1, nMaxPBS=pbs_range[1], nMaxRT=rtt_max, pe_system=pe_system)\n","    cFeat.make_rt_pbs_combinations()\n","    #ویژگی سری 1\n","    cFeat.determine_seqs()\n","    #ویژگی سری 2\n","    cFeat.determine_secondary_structure()\n","    #ویژگی سری 1\n","    #تابع را باید بنویسم.\n","\n","\n","    df = cFeat.make_output_df()\n","\n","    if len(df) > 0:\n","      # برای کریسپر طول دنباله را 30 در نظر می گیرم\n","        list_Guide30 = [WT74[:30] for WT74 in df['WT74_On']]\n","        # هر دو اسکور اینجا حساب می شود\n","        df['DeepSpCas9_score'] = spcas9_score(list_Guide30)\n","        #همه ویژگی هایی را که استخراج کردم را به مدل می دهم\n","        df['%s_score' % pe_system]  = calculate_deepprime_score(df, pe_system, cell_type)\n","\n","    else:\n","        print('\\nsID:', sID)\n","        print('DeepPrime only support RTT length upto 40nt')\n","        print('There are no available pegRNAs, please check your input sequences\\n')\n","\n","    return df\n","\n","\n","\n","# برای حالتی که داده ها را از clinVar می گیریم\n","def pecv_score(cv_record,\n","               sID:str       = 'Sample',\n","               pe_system:str = 'PE2max',\n","               cell_type:str = 'HEK293T',\n","               pbs_min:int   = 7,\n","               pbs_max:int   = 15,\n","               rtt_max:int   = 40\n","               ):\n","\n","    '''\n","    Using variants records from GetClinVar in the database module.\\n\n","    You don't have to bring a sequence input to DeepPrime, but you calculate the score right away.\\n\n","    If DeepPrime is an unpredictable form of variants, it sends out a message.\\n\n","\n","    '''\n","\n","    # check input parameters\n","    if pbs_max > 17: return print('sID:%s\\nPlease set PBS max length upto 17nt' % sID)\n","    if rtt_max > 40: return print('sID:%s\\nPlease set RTT max length upto 40nt' % sID)\n","\n","    print('DeepPrime score of ClinVar record')\n","\n","    Ref_seq, ED_seq = cv_record.seq()\n","\n","    nAltIndex   = 60\n","    pbs_range   = [pbs_min, pbs_max]\n","    rtt_max     = rtt_max\n","    pe_system   = pe_system\n","\n","    edit_type   = cv_record.alt_type\n","    edit_len    = int(cv_record.alt_len)\n","\n","    ## FeatureExtraction Class\n","    cFeat = FeatureExtraction()\n","\n","    cFeat.input_id = sID\n","    cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)\n","\n","    cFeat.get_sAltNotation(nAltIndex)\n","    cFeat.get_all_RT_PBS(nAltIndex, nMinPBS=pbs_range[0]-1, nMaxPBS=pbs_range[1], nMaxRT=rtt_max, pe_system=pe_system)\n","    cFeat.make_rt_pbs_combinations()\n","    cFeat.determine_seqs()\n","    cFeat.determine_secondary_structure()\n","\n","    df = cFeat.make_output_df()\n","\n","    if len(df) > 0:\n","        list_Guide30 = [WT74[:30] for WT74 in df['WT74_On']]\n","        df['DeepSpCas9_score'] = spcas9_score(list_Guide30)\n","        df['%s_score' % pe_system]  = calculate_deepprime_score(df, pe_system, cell_type)\n","\n","    else:\n","        print('\\nsID:', sID)\n","        print('DeepPrime only support RTT length upto 40nt')\n","        print('There are no available pegRNAs, please check your input sequences\\n')\n","\n","    return df\n","\n","\n","\n","\n","\n","\n","\n","#کد های کلاس زیر برای کنترل ورودی ها از سایت نوشته شده است.\n","\n","\n","class DeepPrime:\n","    '''\n","    DeepPrime: pegRNA activity prediction models\\n\n","    Input  = 121 nt DNA sequence without edit\\n\n","    Output = 121 nt DNA sequence with edit\\n\n","\n","    ### Available Edit types\\n\n","    sub1, sub2, sub3, ins1, ins2, ins3, del1, del2, del3\\n\n","\n","    ### Available PE systems\\n\n","    PE2, PE2max, PE4max, NRCH_PE2, NRCH_PE2max, NRCH_PE4max\\n\n","\n","    ### Available Cell types\\n\n","    HEK293T, HCT116, MDA-MB-231, HeLa, DLD1, A549, NIH3T3\n","\n","    '''\n","    def __init__(self, sID:str, Ref_seq: str, ED_seq: str, edit_type: str, edit_len: int,\n","                pam:str = 'NGG', pbs_min:int = 7, pbs_max:int = 15,\n","                rtt_min:int = 0, rtt_max:int = 40, silence:bool = False,\n","                out_dir:str=os.getcwd(),\n","                ):\n","\n","        # input parameters\n","        self.nAltIndex = 60\n","        self.sID, self.Ref_seq, self.ED_seq = sID, Ref_seq, ED_seq\n","        self.edit_type, self.edit_len, self.pam = edit_type, edit_len, pam\n","        self.pbs_min, self.pbs_max = pbs_min, pbs_max\n","        self.pbs_range = [pbs_min, pbs_max]\n","        self.rtt_min, self.rtt_max   = rtt_min, rtt_max\n","        self.silence = silence\n","\n","        # output directory\n","        self.OUT_PATH = '%s/%s/'  % (out_dir, self.sID)\n","        self.TEMP_DIR = '%s/temp' % self.OUT_PATH\n","\n","        # initializing\n","        self.set_logging()\n","        self.check_input()\n","\n","        ## FeatureExtraction Class\n","        cFeat = FeatureExtraction()\n","\n","        cFeat.input_id = sID\n","        cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)\n","\n","        cFeat.get_sAltNotation(self.nAltIndex)\n","        cFeat.get_all_RT_PBS(self.nAltIndex, nMinPBS= self.pbs_min-1, nMaxPBS=self.pbs_max, nMaxRT=rtt_max, pam=self.pam)\n","        cFeat.make_rt_pbs_combinations()\n","        cFeat.determine_seqs()\n","        cFeat.determine_secondary_structure()\n","\n","        self.features = cFeat.make_output_df()\n","\n","        del cFeat\n","\n","        self.logger.info('Created an instance of DeepPrime')\n","\n","    # def __init__: END\n","\n","\n","    def submit(self, pe_system:str, cell_type:str = 'HEK293T'):\n","        print('start pe_scre', self.Ref_seq, self.ED_seq, )\n","\n","        return None\n","\n","    # def submit: END\n","\n","\n","    def set_logging(self):\n","\n","        self.logger = logging.getLogger(self.OUT_PATH)\n","        self.logger.setLevel(logging.DEBUG)\n","\n","        self.formatter = logging.Formatter(\n","            '%(levelname)-5s @ %(asctime)s:\\n\\t %(message)s \\n',\n","            datefmt='%a, %d %b %Y %H:%M:%S',\n","            )\n","\n","        self.error = self.logger.error\n","        self.warn  = self.logger.warn\n","        self.debug = self.logger.debug\n","        self.info  = self.logger.info\n","\n","        try:\n","            os.makedirs(self.OUT_PATH, exist_ok=True)\n","            os.makedirs(self.TEMP_DIR, exist_ok=True)\n","            self.info('Creating Folder %s' % self.OUT_PATH)\n","        except:\n","            self.error('Creating Folder failed')\n","            sys.exit(1)\n","\n","        self.file_handler = logging.FileHandler('%s/log_%s.log' % (self.OUT_PATH, self.sID))\n","        self.file_handler.setLevel(logging.DEBUG)\n","        self.file_handler.setFormatter(self.formatter)\n","        self.logger.addHandler(self.file_handler)\n","\n","        if self.silence != True:\n","            self.console_handler = logging.StreamHandler()\n","            self.console_handler.setLevel(logging.DEBUG)\n","            self.console_handler.setFormatter(self.formatter)\n","            self.logger.addHandler(self.console_handler)\n","\n","        self.info('DeepPrime: pegRNA activity prediction models\\n\\t version: %s' % genet.__version__)\n","\n","\n","        return None\n","\n","    # def set_logging: END\n","\n","\n","    def check_input(self):\n","\n","        if self.pbs_min < 1:\n","            self.error('sID:%s\\nPlease set PBS max length at least 1nt' % self.sID)\n","            raise ValueError('Please check your input: pbs_min')\n","\n","        if self.pbs_max > 17:\n","            self.error('sID:%s\\nPlease set PBS max length upto 17nt' % self.sID)\n","            raise ValueError('Please check your input: pbs_max')\n","\n","        if self.rtt_max > 40:\n","            self.error('sID:%s\\nPlease set RTT max length upto 40nt' % self.sID)\n","            raise ValueError('Please check your input: rtt_max')\n","\n","        if self.edit_type not in ['sub', 'ins', 'del']:\n","            self.error('sID:%s\\n\\t Please select proper edit type.\\n\\t Available edit tyle: sub, ins, del' % self.sID)\n","            raise ValueError('Please check your input: edit_type')\n","\n","        if self.edit_len > 3:\n","            self.error('sID:%s\\n\\t Please set edit length upto 3nt. Available edit length range: 1~3nt' % self.sID)\n","            raise ValueError('Please check your input: edit_len')\n","\n","        if self.edit_len < 1:\n","            self.error('sID:%s\\n\\t Please set edit length at least 1nt. Available edit length range: 1~3nt' % self.sID)\n","            raise ValueError('Please check your input: edit_len')\n","\n","        self.info('Input information\\n\\t ID: %s\\n\\t Refseq: %s\\n\\t EDseq :%s' % (self.sID, self.Ref_seq, self.ED_seq))\n","\n","        return None\n","\n","    # def check_input: END\n","\n","\n","    def do_something(self):\n","        self.logger.info('Something happened.')\n","\n","        return None\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":32386,"status":"ok","timestamp":1693457029963,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"trQb7FNz8S2w","outputId":"d6fe37dd-4d2d-4927-946e-e4de5373d819"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Warnning] genet.predict.pe_score will be deprecated in future.\n","\n","            Please consider genet.predict.DeepPrime instead.\n","\n","            Run DeepPrime now anyway.\n","\n","The model DeepSpCas9 is not installed. Download checkpoint files.\n","\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 0KB [00:00, ?KB/s]\n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepSpCas9/__init__.py\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 681KB [00:00, 4963.17KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepSpCas9/PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60.data-00000-of-00001\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 1KB [00:00, 3326.17KB/s]\n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepSpCas9/PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60.index\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 29KB [00:00, 1117.58KB/s]             \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepSpCas9/PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60.meta\n","The model DeepPrime/DP_variant_293T_PE2max_Opti_220428 is not installed. Download checkpoint files.\n","\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 0KB [00:00, ?KB/s]\n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/__init__.py\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 1KB [00:00, 3158.36KB/s]\n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/dp_mean.csv\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 1KB [00:00, 743.80KB/s]\n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/dp_std.csv\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 2880.30KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_0.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 2921.02KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_1.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3123.38KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_2.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3287.84KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_3.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3609.50KB/s]             \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_4.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3155.99KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_5.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3043.64KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_6.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3251.82KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_7.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3180.45KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_8.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3435.56KB/s]             \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_9.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3533.14KB/s]             \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_10.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3233.75KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_11.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3045.85KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_12.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3000.15KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_13.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3414.77KB/s]             \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_14.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 3826.18KB/s]             \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_15.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 2746.63KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_16.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 2839.33KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_17.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 2821.19KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_18.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 337KB [00:00, 2932.84KB/s]                         \n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/final_model_19.pt\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 1KB [00:00, 1324.38KB/s]\n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/mean.csv\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: 1KB [00:00, 907.66KB/s]\n"]},{"output_type":"stream","name":"stdout","text":["File downloaded successfully: /usr/local/lib/python3.10/dist-packages/genet/models/DeepPrime/DP_variant_293T_PE2max_Opti_220428/std.csv\n"]},{"output_type":"execute_result","data":{"text/plain":["                                              Target  \\\n","0  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","1  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","2  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","3  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","4  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","5  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","6  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","7  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","8  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","9  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n","\n","                           Spacer  \\\n","0  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","1  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","2  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","3  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","4  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","5  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","6  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","7  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","8  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","9  ATAAAAGACAACACCCTTGCCTTGTGGAGT   \n","\n","                                              RT-PBS  PBSlen  RTlen  \\\n","0       TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGG       7     37   \n","1      TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGG       8     37   \n","2     TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGT       9     37   \n","3    TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGTG      10     37   \n","4   TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGTGT      11     37   \n","5  TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGTGTT      12     37   \n","6  TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGT...      13     37   \n","7  TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGT...      14     37   \n","8  TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGT...      15     37   \n","9      GTTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGG       7     38   \n","\n","   RT-PBSlen  Edit_pos  Edit_len  RHA_len  PE2max_score  \n","0         44        34         3        1      0.183205  \n","1         45        34         3        1      0.567812  \n","2         46        34         3        1      0.555785  \n","3         47        34         3        1      0.880449  \n","4         48        34         3        1      0.843617  \n","5         49        34         3        1      0.726335  \n","6         50        34         3        1      0.878920  \n","7         51        34         3        1      0.807085  \n","8         52        34         3        1      0.650620  \n","9         45        34         3        2      0.320586  "],"text/html":["\n","  <div id=\"df-ebe4ae5a-4f50-492a-a5a1-d19c7b2e07d9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Target</th>\n","      <th>Spacer</th>\n","      <th>RT-PBS</th>\n","      <th>PBSlen</th>\n","      <th>RTlen</th>\n","      <th>RT-PBSlen</th>\n","      <th>Edit_pos</th>\n","      <th>Edit_len</th>\n","      <th>RHA_len</th>\n","      <th>PE2max_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGG</td>\n","      <td>7</td>\n","      <td>37</td>\n","      <td>44</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.183205</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGG</td>\n","      <td>8</td>\n","      <td>37</td>\n","      <td>45</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.567812</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGT</td>\n","      <td>9</td>\n","      <td>37</td>\n","      <td>46</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.555785</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGTG</td>\n","      <td>10</td>\n","      <td>37</td>\n","      <td>47</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.880449</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGTGT</td>\n","      <td>11</td>\n","      <td>37</td>\n","      <td>48</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.843617</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGTGTT</td>\n","      <td>12</td>\n","      <td>37</td>\n","      <td>49</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.726335</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGT...</td>\n","      <td>13</td>\n","      <td>37</td>\n","      <td>50</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.878920</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGT...</td>\n","      <td>14</td>\n","      <td>37</td>\n","      <td>51</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.807085</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>TTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGGGT...</td>\n","      <td>15</td>\n","      <td>37</td>\n","      <td>52</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.650620</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n","      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGT</td>\n","      <td>GTTCGTCTCAGTTTCTGGGAGCTTTGAAAACTCCACAAGGCAAGG</td>\n","      <td>7</td>\n","      <td>38</td>\n","      <td>45</td>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0.320586</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebe4ae5a-4f50-492a-a5a1-d19c7b2e07d9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ebe4ae5a-4f50-492a-a5a1-d19c7b2e07d9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ebe4ae5a-4f50-492a-a5a1-d19c7b2e07d9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a0dfc698-b32e-4d7f-8bf5-f0aed0cb21f0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0dfc698-b32e-4d7f-8bf5-f0aed0cb21f0')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a0dfc698-b32e-4d7f-8bf5-f0aed0cb21f0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}],"source":["\n","\n","\n","#  WT sequence and Edited sequence information,  select the edit type you want to make and put it in.\n","#Input seq: 60bp 5' context + 1bp center + 60bp 3' context (total 121bp)\n","\n","seq_wt   = 'ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT'\n","seq_ed   = 'ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT'\n","alt_type = 'sub3'\n","\n","df_pe = prd.pe_score(seq_wt, seq_ed, alt_type)\n","df_pe.head(10)\n"]},{"cell_type":"markdown","metadata":{"id":"hy8H7wJuGciM"},"source":["# Utilite"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4183,"status":"ok","timestamp":1693457044445,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"7sWoraYBqyCP","outputId":"9bb7de9f-2452-4036-c1d4-558cb9f97abd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: RNA in /usr/local/lib/python3.10/dist-packages (0.11.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from RNA) (3.7.1)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from RNA) (1.23.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->RNA) (1.16.0)\n"]}],"source":["!pip install RNA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4806,"status":"ok","timestamp":1693457090643,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"IF9rGCUnQoXp","outputId":"4535179c-19a5-4eaf-adab-1087346f3952"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Bio\n","  Downloading bio-1.5.9-py3-none-any.whl (276 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/276.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/276.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/dist-packages (from Bio) (1.81)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Bio) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Bio) (4.66.1)\n","Collecting mygene (from Bio)\n","  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Bio) (1.5.3)\n","Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from Bio) (1.7.0)\n","Collecting gprofiler-official (from Bio)\n","  Downloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->Bio) (1.23.5)\n","Collecting biothings-client>=0.2.6 (from mygene->Bio)\n","  Downloading biothings_client-0.3.0-py2.py3-none-any.whl (29 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2023.3)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (3.10.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (23.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2023.7.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->Bio) (1.16.0)\n","Installing collected packages: gprofiler-official, biothings-client, mygene, Bio\n","Successfully installed Bio-1.5.9 biothings-client-0.3.0 gprofiler-official-1.0.0 mygene-3.2.2\n"]}],"source":["!pip install Bio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4357,"status":"ok","timestamp":1693457094998,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"MNNxBtFgQwPP","outputId":"75c6810d-76b1-45aa-f68a-b67082aba65e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mechanize\n","  Downloading mechanize-0.4.8-py2.py3-none-any.whl (110 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/110.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.3/110.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: html5lib>=0.999999999 in /usr/local/lib/python3.10/dist-packages (from mechanize) (1.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=0.999999999->mechanize) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=0.999999999->mechanize) (0.5.1)\n","Installing collected packages: mechanize\n","Successfully installed mechanize-0.4.8\n"]}],"source":["!pip install mechanize"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":109756,"status":"ok","timestamp":1693457204751,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"ckOsDHvRSUW2","outputId":"f1e6814d-a451-4cd8-9c08-3ebddb66fc13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-bio\n","  Downloading scikit-bio-0.5.9.tar.gz (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (2.31.0)\n","Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (4.4.2)\n","Requirement already satisfied: IPython>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (7.34.0)\n","Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (3.7.1)\n","Requirement already satisfied: natsort>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (8.4.0)\n","Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (1.23.5)\n","Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (1.5.3)\n","Requirement already satisfied: scipy<=1.10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (1.10.1)\n","Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-bio) (3.9.0)\n","Collecting hdmedians>=0.14.1 (from scikit-bio)\n","  Downloading hdmedians-0.14.2.tar.gz (7.6 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Cython>=0.23 in /usr/local/lib/python3.10/dist-packages (from hdmedians>=0.14.1->scikit-bio) (0.29.36)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython>=3.2.0->scikit-bio) (67.7.2)\n","Collecting jedi>=0.16 (from IPython>=3.2.0->scikit-bio)\n","  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython>=3.2.0->scikit-bio) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython>=3.2.0->scikit-bio) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython>=3.2.0->scikit-bio) (3.0.39)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython>=3.2.0->scikit-bio) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython>=3.2.0->scikit-bio) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython>=3.2.0->scikit-bio) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython>=3.2.0->scikit-bio) (4.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->scikit-bio) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->scikit-bio) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->scikit-bio) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->scikit-bio) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->scikit-bio) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->scikit-bio) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->scikit-bio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->scikit-bio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->scikit-bio) (2023.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->scikit-bio) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->scikit-bio) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->scikit-bio) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->scikit-bio) (2023.7.22)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython>=3.2.0->scikit-bio) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython>=3.2.0->scikit-bio) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython>=3.2.0->scikit-bio) (0.2.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.3->scikit-bio) (1.16.0)\n","Building wheels for collected packages: scikit-bio, hdmedians\n","  Building wheel for scikit-bio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-bio: filename=scikit_bio-0.5.9-cp310-cp310-linux_x86_64.whl size=2469054 sha256=4d27b66e6954cd4d0dafa7abf8497c9fc12e46a53205fdea4d9adfdaa67f69a6\n","  Stored in directory: /root/.cache/pip/wheels/77/72/2c/993efbb4d69a86bee422bc96e4e2f1ec9af7cc596a08bb86e1\n","  Building wheel for hdmedians (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdmedians: filename=hdmedians-0.14.2-cp310-cp310-linux_x86_64.whl size=677851 sha256=a5fca4892122c67b2bf88210705b2f3338517b253c51406fa87c44f44b6fb961\n","  Stored in directory: /root/.cache/pip/wheels/82/8f/0d/0c61130cfad119482ebb95aecf8d5dfaddd0181f5680da2bec\n","Successfully built scikit-bio hdmedians\n","Installing collected packages: jedi, hdmedians, scikit-bio\n","Successfully installed hdmedians-0.14.2 jedi-0.19.0 scikit-bio-0.5.9\n"]}],"source":["!pip install scikit-bio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2Rafy7WJ9of"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","import os\n","import argparse\n","import shutil\n","import datetime\n","import getpass\n","import uuid\n","import mechanize\n","import re\n","import pandas as pd\n","import yaml\n","import itertools\n","import pickle\n","import subprocess\n","from skbio.alignment import global_pairwise_align_nucleotide\n","from skbio import DNA\n","import RNA\n","from copy import deepcopy as dp\n","import numpy as np\n","import sys\n","import math\n","#------------------ FILE IO ---------------------------\n","\n","def write_file(file_name,message):\n","\tout = open(file_name,\"wt\")\n","\tout.write(message)\n","\tout.close()\n","\n","# برای کنترل نتایج چاپ شده - می تواند جایگزین تابع بالا شود.\n","def print_parameters(myDict):\n","\tmyGroup = {}\n","\tmyGroup['Prime Editing'] = ['genome_fasta','scaffold','n_jobs','debug','PE2_model','PE3_model','extend_length']\n","\tmyGroup['PBS searching'] = ['min_PBS_length','max_PBS_length']\n","\tmyGroup['RTT searching'] = ['min_RTT_length','max_RTT_length','min_distance_RTT5','max_max_RTT_length']\n","\tmyGroup['sgRNA searching'] = ['gRNA_search_space','sgRNA_length','offset','PAM','max_target_to_sgRNA','max_max_target_to_sgRNA']\n","\tmyGroup['ngRNA searching'] = ['max_ngRNA_distance']\n","\tfor k in myGroup:\n","\t\tprint_group(myDict,myGroup[k],k)\n","\n","\n","def print_group(myDict,myList,group_title):\n","\tprint (\"-------- Parameter Group: %s --------\"%(group_title))\n","\tfor l in myList:\n","\t\tprint (\"%s: %s\"%(l,myDict[l]))\n","\n","\n","#تعریف پارامترهای پیش فرض\n","def get_parameters(config):\n","\tp_dir = os.path.dirname(os.path.realpath(__file__)) + \"/\"\n","\t# return dict\n","\tparameters = {}\n","\t# default parameters\n","\tpre_defined_list = {}\n","\t#------------ Prime Editing related-----------\n","\t#این ورودی را باید برای برنامه فراهم کنم\n","\tpre_defined_list[\"genome_fasta\"] = \"/home/yli11/Data/Human/hg19/fasta/hg19.fa\"\n","\tpre_defined_list[\"n_jobs\"] = -1\n","\tpre_defined_list[\"scaffold\"] = \"GTTTTAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCGTTATCAACTTGAAAAAGTGGCACCGAGTCGGTGC\"\n","\tpre_defined_list[\"debug\"] = 0\n","\tpre_defined_list[\"extend_length\"] = 1000 # extracting +- 1000bp center at target pos from the genome, in 99.9% cases, you don't need to change this. If change to less than 500, will trigger fasta input mode, may cause error.\n","\t#   مدل های از پیش آموزش دیده را اینجا معرفی می کنم.\n","\t# می تونی DEEPPRIME بزاری\n","\tpre_defined_list[\"PE2_model\"] = p_dir+\"../model/PE2_model_final.py\"\n","\tpre_defined_list[\"PE3_model\"] = p_dir+\"../model/PE3_model_final.py\"\n","\n","\t#------------ PBS -----------\n","\tpre_defined_list[\"min_PBS_length\"] = 10\n","\tpre_defined_list[\"max_PBS_length\"] = 15\n","\n","\t#------------ RTT -----------\n","\tpre_defined_list[\"min_RTT_length\"] = 10\n","\tpre_defined_list[\"max_RTT_length\"] = 20 # if no candidate is found, this value will be increased by 5, max to max_max_RTT_length\n","\tpre_defined_list[\"max_max_RTT_length\"] = 50\n","\tpre_defined_list[\"min_distance_RTT5\"] = 5\n","\n","\t#------------ sgRNA -----------\n","\tpre_defined_list[\"gRNA_search_space\"] = 200\n","\tpre_defined_list[\"sgRNA_length\"] = 20\n","\tpre_defined_list[\"offset\"] = -3\n","\tpre_defined_list[\"PAM\"] = \"NGG\"\n","\tpre_defined_list[\"max_target_to_sgRNA\"] = 10 # if no candidate is found, this value will be increased by 5, max to max_max_target_to_sgRNA\n","\tpre_defined_list[\"max_max_target_to_sgRNA\"] = 30\n","\n","\t#------------ ngRNA ------------\n","\tpre_defined_list[\"max_ngRNA_distance\"] = 100 # if no candidate is found, this value will be increased by 20, max to max_max_ngRNA_distance\n","\tpre_defined_list[\"max_max_ngRNA_distance\"] = 200\n","\tpre_defined_list[\"search_iteration\"] = 1 # not affect anything\n","\n","\ttry:\n","\t\twith open(config, 'r') as f:\n","\t\t\tmanifest_data = yaml.load(f,Loader=yaml.FullLoader)\n","\texcept:\n","\t\tprint (\"Config data is not provided or not parsed successfully, Default parameters were used.\")\n","\n","\tfor p in pre_defined_list:\n","\t\ttry:\n","\t\t\tparameters[p] = manifest_data[p]\n","\t\texcept:\n","\t\t\tparameters[p] = pre_defined_list[p]\n","\treturn parameters\n","\n","def to_bed3(chr,start,end):\n","\toutfile = str(uuid.uuid4()).split(\"-\")[-1]\n","\twrite_file(outfile,\"\\t\".join([chr,str(start),str(end)]))\n","\treturn outfile\n","\n","def write_fasta(file_name,myDict):\n","\tout = open(file_name,\"wt\")\n","\tfor k in myDict:\n","\t\tout.write(\">\"+k+\"\\n\")\n","\t\tout.write(myDict[k]+\"\\n\")\n","\tout.close()\n","\n","\n","#طراحی  sgRNA , در ادامه PegRNA\n","#------------------ sgRNA finder ---------------------------\n","from Bio import SeqUtils\n","def run_pam_finder(target_fa,seq,PAM,abs_start_pos,chr):\n","\n","\t# SeqUtils.nt_search(\"AGGCGGGGG\", \"NGG\")\n","\t# SeqUtils.nt_search(\"CCACCA\", \"NGG\")\n","\t# forward\n","\trev_seq = revcomp(target_fa)\n","\tfwd_search = SeqUtils.nt_search(target_fa, seq+PAM)\n","\trev_search = SeqUtils.nt_search(rev_seq, seq+PAM)\n","\tout = []\n","\tif len(fwd_search) > 1:\n","\t\tfor s in fwd_search[1:]:\n","\t\t\t# out.append([chr,s+abs_start_pos,s+abs_start_pos+len(seq),target_fa[s:(s+len(seq))],\".\",\"+\"])\n","\t\t\tout.append([chr,s+abs_start_pos,s+abs_start_pos+len(seq),target_fa[s:(s+len(seq))],target_fa[s:(s+len(seq)+len(PAM))],\"+\"])\n","\tif len(rev_search) > 1:\n","\t\tfor s in rev_search[1:]:\n","\t\t\t# out.append([chr,(len(target_fa)-s)+abs_start_pos-len(seq),(len(target_fa)-s)+abs_start_pos,rev_seq[s:(s+len(seq))],\".\",\"-\"])\n","\t\t\tout.append([chr,(len(target_fa)-s)+abs_start_pos-len(seq),(len(target_fa)-s)+abs_start_pos,rev_seq[s:(s+len(seq))],rev_seq[s:(s+len(seq)+len(PAM))],\"-\"])\n","\treturn pd.DataFrame(out)\n","\n","def force_recommend_dPAM_PE3b(r,max_eff):\n","\trank = 0\n","\tif \"dPAM\" in r.index:\n","\t\trank += 1\n","\tif \"PE3b\" in r.index:\n","\t\tif not max_eff-r.predicted_efficiency>max_eff*0.1:\n","\t\t\trank += 1\n","\treturn rank\n","\n","#------------------ Fasta Operators ---------------------------\n","from Bio import SeqIO\n","\n","def find_pos_ref_alt(x,y):\n","\t\"\"\"find variant pos, ref and alt given ref(x) and alt(y) sequences\n","\n","\tMethod\n","\n","\ttrim 5 end, then trim 3 end, what left is the ref and alt, pos the trim 5 position\n","\n","\t\"\"\"\n","\n","\tfor i in range(len(x)):\n","\t\tif x[i]!=y[i]:\n","\t\t\tnew_x = x[i:]\n","\t\t\tnew_y = y[i:]\n","\t\t\tpos = i+1\n","\t\t\tbreak\n","\t# print (new_x,new_y)\n","\tfor i in range(min(len(new_x),len(new_y))):\n","\t\ti=i+1\n","\t\t# print (\"second for\",i,new_x[-i],new_y[-i])\n","\t\tif new_x[-i]!=new_y[-i]:\n","\t\t\tref = new_x[:-i+1]\n","\t\t\talt = new_y[:-i+1]\n","\t\t\tbreak\n","\t\telse:\n","\n","\t\t\tref = new_x[:-i]\n","\t\t\talt = new_y[:-i]\n","\n","\t## check\n","\tcheck_y = x[:pos-1]+alt+x[pos+len(ref)-1:]\n","\t# print (\"debug\",pos,i,ref)\n","\t# print (\"new y\",x[:pos-1],x[pos+len(ref)-1:],alt)\n","\tif y!= check_y:\n","\t\tprint (\"something is wrong, please fix it\")\n","\t\tprint (x)\n","\t\tprint (y)\n","\t\treturn -1,ref,alt\n","\treturn pos,ref,alt\n","\n","def fasta2vcf(f):\n","\t\"\"\"convert fasta to vcf dataframe\n","\n","\tInput\n","\t-----\n","\n","\tFasta file, _ref is recognized as ref and _alt is used as alt, these are two keywords\n","\n","\tOutput\n","\t------\n","\n","\tvcf dataframe: chr, pos, name, ref, alt, reference sequence\n","\n","\n","\t\"\"\"\n","\t# آنچه یافتم را میخواهم اینجا بریزم\n","\tmy_dict = {}\n","\tfor r in SeqIO.parse(f, \"fasta\"):\n","\t\tmy_dict[r.id] = str(r.seq).upper()\n","\tprint (my_dict)\n","\tvcf = pd.DataFrame()\n","\tindex_list = []\n","\tchr_list = []\n","\tpos_list = []\n","\tref_list = []\n","\talt_list = []\n","\tseq_list = []\n","\tfor k in my_dict:\n","\t\tif not \"_ref\" in k:\n","\t\t\tcontinue\n","\t\tname = k.replace(\"_ref\",\"\")\n","\t\tif not name+\"_alt\" in my_dict:\n","\t\t\tprint (k,\"alt sequence not found. Please use _ref and _alt keywords. Skip...\")\n","\t\t\tcontinue\n","\t\tref_seq,alt_seq = my_dict[k],my_dict[name+\"_alt\"]\n","\t\tif len(ref_seq) < 30:\n","\t\t\tprint (k,\"Please input sequence length at least 30bp. Skip...\")\n","\t\t\tcontinue\n","\t\tif ref_seq == alt_seq:\n","\t\t\tprint (k,\"Ref and Alt sequence is the same. Please check. Skip...\")\n","\t\t\tcontinue\n","\t\tpos,ref,alt = find_pos_ref_alt(ref_seq,alt_seq)\n","\t\tindex_list.append(name)\n","\t\tchr_list.append(k)\n","\t\tseq_list.append(ref_seq)\n","\t\tpos_list.append(pos)\n","\t\tref_list.append(ref)\n","\t\talt_list.append(alt)\n","\tvcf[0] = chr_list\n","\tvcf[1] = pos_list\n","\tvcf[2] = index_list\n","\tvcf[3] = ref_list\n","\tvcf[4] = alt_list\n","\tvcf[5] = seq_list\n","\tvcf = vcf[vcf[1]!=-1]\n","\tif vcf.shape[0] == 0:\n","\t\tprint (\"no valid sequences in:\",f)\n","\t\tprint (\"Exit...\")\n","\t\tsys.exit(1)\n","\n","\treturn vcf\n","\n","def vcf2fasta(vcf,extend_length=None,genome_fasta=None,**kwargs):\n","\t\"\"\"extracting +- extend_length given vcf target mutation\n","\n","\tinput\n","\tvcf is a dataframe, chr, pos, id, ref, alt\n","\n","\treturn\n","\t--------\n","\n","\ta list of sequences, same order\n","\n","\t\"\"\"\n","\n","\tout_bed = str(uuid.uuid4()).split(\"-\")[-1]+\".bed\"\n","\tout_fa = out_bed+\".tab\"\n","\tdf = vcf.copy()\n","\tdf['chr'] = df[0]\n","\tdf['start'] = df[1]-extend_length\n","\tdf['end'] = df[1]+extend_length\n","\tdf[['chr','start','end']].to_csv(out_bed,sep=\"\\t\",header=False,index=False)\n","\n","\tp1 = subprocess.Popen(['bedtools','getfasta','-fi',genome_fasta,'-bed',out_bed,'-fo',out_fa,'-tab'],bufsize=0)\n","\tp1.communicate()\n","\tdf = pd.read_csv(out_fa,sep=\"\\t\",header=None,index_col=0)\n","\n","\tos.remove(out_bed)\n","\tos.remove(out_fa)\n","\n","\treturn [x.upper() for x in df[1]]\n","\n","def get_opposite_strand(x):\n","\tif x == \"+\":\n","\t\treturn \"-\"\n","\treturn \"+\"\n","\n","\n","def sub_fasta_single(target_fa,target_pos, abs_start,abs_end):\n","\t\"\"\"given the target_fa we extracted from target_pos, we get sub fasta\n","\n","\ttarget_fa: we extended +- N bp of the target set, this length is 2N\n","\n","\tuser sequence, abs start and end\n","\n","\ttarget_pos is 1 index, the target pos that we used to get target_fa\n","\n","\tAssumption and user query, target_fa on the same chr\n","\n","\t\"\"\"\n","\n","\tN = int(len(target_fa)/2)\n","\tstart =  N-(target_pos-abs_start)\n","\tend = abs_end - abs_start + start\n","\tseq = target_fa[start:end]\n","\tif len(target_fa)<1000:\n","\t\t## user input fasta:\n","\t\tseq = target_fa[abs_start:abs_end]\n","\treturn seq\n","\n","\n","\n","def get_fasta_simple(target_fa,df, target_pos,strand=False):\n","\t\"\"\"save time and memory get fasta\n","\n","\ttarget_fa: we extended +- N bp of the target set, this length is 2N\n","\n","\tdf is a normal bed file\n","\n","\ttarget_pos is 1 index\n","\n","\tdf and target_pos, all on the same chr\n","\n","\t\"\"\"\n","\ttemp = df.copy()\n","\t# print (\"len target_fa\",len(target_fa))\n","\tN = int(len(target_fa)/2)\n","\ttemp.columns = list(range(len(df.columns)))\n","\ttemp.index = temp[0]+\":\"+temp[1].astype(str)+\"-\"+temp[2].astype(str)\n","\tif len(target_fa)<1000:\n","\t\t## user input fasta:\n","\t\tseq_list = []\n","\t\tfor r in temp.values.tolist():\n","\t\t\tseq = target_fa[r[1]:r[2]]\n","\t\t\tif strand:\n","\t\t\t\tif r[5] == \"-\":\n","\t\t\t\t\tseq = revcomp(seq)\n","\t\t\tseq_list.append(seq)\n","\t\ttemp[3] = seq_list\n","\t\treturn temp\n","\ttemp[2] = temp[2]-temp[1]\n","\ttemp[1] = N-(target_pos-temp[1])\n","\ttemp[2] = temp[2]+temp[1]\n","\tseq_list = []\n","\tfor r in temp.values.tolist():\n","\t\tseq = target_fa[r[1]:r[2]]\n","\t\tif strand:\n","\t\t\tif r[5] == \"-\":\n","\t\t\t\tseq = revcomp(seq)\n","\t\tseq_list.append(seq)\n","\ttemp[3] = seq_list\n","\treturn temp\n","\n","\n","\n","tab = str.maketrans(\"ACTG\", \"TGAC\")\n","def revcomp(seq):\n","\treturn seq.translate(tab)[::-1]\n","\n","\n","\n","#------------------ pegRNA Operators ---------------------------\n","\n","\n","def distance_matrix(lines):\n","\t\"\"\"given sgRNA bed dataframe (the 5th is the name), get gRNA distance matrix\n","\n","\tindex: chr_start_end_strand_seq (5th column)\n","\n","\tuse the last element as the pos to calculate distance\n","\n","\tcomparing to D Liu distance, this is always 1 larger than them, because we use the 4th nucleotide as the cut position, cas9 cut between 3rd and 4th\n","\n","\treturn\n","\t-------\n","\n","\t2d dict\n","\n","\t\"\"\"\n","\n","\tdist_dict={}\n","\tfor x in lines:\n","\t\tdist_dict[x[4]]={}\n","\t\tfor y in lines:\n","\t\t\tdist_dict[x[4]][y[4]] = x[-1]-y[-1]\n","\treturn dist_dict\n","\n","\n","\n","def is_gRNA_valid(cas9_cut_position,target_mutation,strand,user_target_mutation_pos,diff):\n","\t# cas9_cut_position=[chr,pos], pos is 1-based position, same as in vcf file\n","\t# target_mutation=[chr,pos], pos is 1-based position, same as in vcf file\n","\t\"\"\"\n","\tPBS sequence can't be on the same side to the target site in terms of the cut site\n","\n","\tThe position of the target mutation should be:\n","\tOn the right of the cas9 cut position if gRNA strand is +\n","\tOn the left of the cas9 cut position if gRNA strand is -\n","\n","\tuser_target_mutation_pos, mutation correct cause bug when strand = -\n","\n","\tReturn\n","\t------\n","\n","\tis gRNA valid, target mutation distance to cut site\n","\n","\n","\t\"\"\"\n","\tif cas9_cut_position[0] != target_mutation[0]:\n","\t\treturn -1\n","\tdistance = int(target_mutation[1]-cas9_cut_position[1])\n","\t# print (cas9_cut_position,target_mutation,strand,user_target_mutation_pos,diff,distance)\n","\tif strand==\"+\":\n","\t\tif distance>=0:\n","\t\t\treturn distance\n","\tif strand==\"-\":\n","\t\tif distance == 0:\n","\t\t\tif user_target_mutation_pos != target_mutation[1]:\n","\t\t\t\tdistance = -1\n","\t\tif distance<=0:\n","\t\t\tdistance = -distance\n","\t\t\tif diff > 0:\n","\t\t\t\tdistance  = distance - diff + 1\n","\t\t\treturn distance\n","\treturn -1\n","\n","\n","\n","\n","def get_gRNA_cut_site(start,end,strand,offset=-3):\n","\t# return 1-index pos\n","\t# cut site = the first base before cut near PAM direction\n","\n","\tif strand == \"+\":\n","\t\treturn int(end + offset)\n","\tif strand == \"-\":\n","\t\treturn int(start - offset +1)\n","\n","\n","\n","#------------------ featurize ---------------------------\n","\n","\n","def GC_content(seq):\n","\tGC=[\"G\",\"C\"]\n","\tcount=0\n","\tfor i in seq:\n","\t\tif i in GC:\n","\t\t\tcount+=1\n","\treturn float(count)/len(seq)\n","\tpass\n","\n","\n","\n","ulength = 31\n","# ViennaRNAاز کتابخانه\n","md = RNA.md()\n","md.max_bp_span = 70\n","md.window_size = 70\n","\n","def call_RNAplfold(seq,scaffold_length):\n","\t\"\"\"RNA fold - binding\n","\t\"\"\"\n","\t# scaffold - RTT - PBS\n","\t# we only care about RTT+PBS (3' extension) pairs with scaffold\n","\n","\tdata = []\n","\tfc = RNA.fold_compound(seq, md, RNA.OPTION_WINDOW)\n","\tfc.probs_window(ulength, RNA.PROBS_WINDOW_BPP | RNA.PROBS_WINDOW_UP, pf_window_callback2, data)\n","\n","\t# parse output\n","\tdf = pd.DataFrame(data)\n","\tdf2 = df.copy()\n","\tdf2[0] = df[1]\n","\tdf2[1] = df[0]\n","\n","\t#\n","\tdf = pd.concat([df,df2])\n","\tseq_length = 10\n","\tRTT_start = scaffold_length + 1\n","\tRTT_end = scaffold_length + seq_length\n","\tscaffold_start = 1\n","\tscaffold_end =  scaffold_length\n","\n","\t## subset df\n","\tdf = df[df[0]>=RTT_start]\n","\tdf = df[df[0]<=RTT_end]\n","\tdf = df[df[1]>=scaffold_start]\n","\tdf = df[df[1]<=scaffold_end]\n","\tdf = df[[0,2]]\n","\tdf = df.groupby(0).max()\n","\tmyDict = df[2].to_dict()\n","\n","\tvalue_list = []\n","\tfor i in range(seq_length):\n","\t\tRTT_pos = scaffold_length +i+ 1\n","\t\tif RTT_pos in myDict:\n","\t\t\tvalue_list.append(myDict[RTT_pos])\n","\t\telse:\n","\t\t\tvalue_list.append(0)\n","\treturn value_list\n","\n","\n","def pf_window_callback2(v, v_size, i, maxsize, what, data=None):\n","\tif what & RNA.PROBS_WINDOW_UP:\n","\t\tpass\n","\telse:\n","\t\tdata+=[[i,j,p] for j, p in enumerate(v) if (p is not None) and (p >= 0.01)]\n","\n","def local_alignments(ref,q):\n","\tquery = StripedSmithWaterman(ref)\n","\talignment = query(q)\n","\treturn alignment['optimal_alignment_score']\n","\n","\n","def alignments_to_cigar(ref,q):\n","\tMatch = 0\n","\tMis = 0\n","\tD = 0\n","\tI = 0\n","\tfor i in range(len(ref)):\n","\t\ta=ref[i]\n","\t\tb=q[i]\n","\t\tif a==\"-\":\n","\t\t\tI=I+1\n","\t\telif b==\"-\":\n","\t\t\tD=D+1\n","\t\telif a==b:\n","\t\t\tMatch+=1\n","\t\telse:\n","\t\t\tMis+=1\n","\treturn [Match,Mis,D,I]\n","\n","def global_alignments(ref,q):\n","\n","\ts1 = DNA(ref)\n","\ts2 = DNA(q)\n","\talignment, score, start_end_positions = global_pairwise_align_nucleotide(s1,s2,match_score=4,mismatch_score=1)\n","\treturn alignments_to_cigar(alignment[0]._string.decode(\"utf-8\"),alignment[1]._string.decode(\"utf-8\"))\n","\n","def is_dPAM(PAM_seq, RTT, cut_offset=-3):\n","\t# Assuming no N is RTT, which should be true\n","\t# match PAM seq to RTT, should be abs(cut_offset)\n","\t# print (PAM_seq, RTT)\n","\t# will need to do revcomp no matter what, because RTT is always xxxxxxxPAM\n","\n","\tseq = revcomp(RTT)\n","\tfwd_search = SeqUtils.nt_search(seq, PAM_seq)\n","\tflag = 1\n","\tif len(fwd_search) > 1:\n","\t\tif abs(cut_offset) in fwd_search:\n","\t\t\tflag = 0\n","\n","\treturn flag\n","\n","def target_to_RTT5_feature(pegRNA,nick_gRNA,target_loc,RTS_length,alt_length):\n","\t# 1. target mutation distance to cut 1 (pegRNA)\n","\t# 2. target mutation distance to cut 2 (nick-gRNA)\n","\t# target_loc [chr,pos]\n","\t# 3. cut 1 to cut 2\n","\tcut1 = get_gRNA_cut_site(pegRNA[1],pegRNA[2],pegRNA[3])\n","\t## if nick_gRNA not exist return a big number\n","\tif nick_gRNA[0] == \"0\":\n","\t\tcut2=0\n","\telse:\n","\t\tcut2 = get_gRNA_cut_site(nick_gRNA[1],nick_gRNA[2],nick_gRNA[3])\n","\n","\t# cut2 to cut1\n","\ta=cut2-cut1-1\n","\n","\n","\t# target to cut1\n","\tb=target_loc[1]-cut1\n","\n","\tif pegRNA[3]==\"-\":\n","\t\ta+=2 # match to coordinate system\n","\t\ta=-a\n","\t\tb=-b\n","\tc=cut2-target_loc[1]\n","\tif nick_gRNA[0] == \"0\":\n","\t\ta=np.nan\n","\t\tc=np.nan\n","\tif b <0:\n","\t\tprint (\"pegRNA to target is less than 0!\")\n","\t\texit()\n","\td = RTS_length - alt_length- b + 1 ## number of nucleotide to the RTT 5' end, from the target mutation (not including)\n","\tif d <0:\n","\t\tprint (\"pegRNA to target is less than 0!\")\n","\t\texit()\n","\tindex_list = [\"nick_to_pegRNA\",\"target_to_pegRNA\",\"target_to_ngRNA\",\"target_to_RTT5\"]\n","\tout = pd.DataFrame([a,b,c,d])\n","\tout.index = index_list\n","\treturn out\n","\n","\n","\tpass\n","\n","\n","#------------------ DeepSpCas9 score  ---------------------------\n","#قبلا در بالا مدل را دانملود و استفاده میکنم\n","\n","def list_to_fasta(l):\n","\tout = []\n","\tfor i in l:\n","\t\tif len(i) != 23:\n","\t\t\tprint (\"something is wrong\")\n","\t\tout.append(\">%s\"%(i[:20]))\n","\t\tout.append(\"AAAA%sAAA\"%(i))\n","\treturn \"\\n\".join(out)\n","def parse_webpage(c):\n","\ta=re.findall('\"([^\"]*)\"', str(c))\n","\t# get the random id\n","\tfor x in a:\n","\t\t# random id format could be changed during version updates\n","\t\tif \"DeepSpCas9/job/user\" in x:\n","\t\t\trandom_id = x.split(\"/\")[-1]\n","\turl = \"http://deepcrispr.info/DeepSpCas9/data/%s/Results.zip\"%(random_id)\n","\tdf = pd.read_csv(url,sep=\"\\t\")\n","\tdf[df.ID==df['Guide Sequence (20bp)']]\n","\tdf.index = df.ID.tolist()\n","\treturn df['DeepSpCas9 Score'].to_dict()\n","\n","def get_DeepSpCas9_score(gRNA_list):\n","\t\"\"\"Grab score from web server\n","\n","\tinput gRNA list should include PAM sequence, PAM is NGG\n","\t\"\"\"\n","\turl=\"http://deepcrispr.info/DeepSpCas9/\"\n","\tbr = mechanize.Browser()\n","\tbr.set_handle_robots(False) # ignore robots\n","\tbr.open(url)\n","\tbr.select_form(nr=0)\n","\tbr[\"ENTER_FASTA\"] = list_to_fasta(gRNA_list)\n","\tres = br.submit()\n","\toutput = res.read()\n","\tres = parse_webpage(output)\n","\tflag = False\n","\tfor i in gRNA_list:\n","\t\tif not i[:20] in res:\n","\t\t\tprint (\"gRNA: %s NOT FOUND!\"%(i[:20]))\n","\t\t\tprint (\"DeepSpCas9 API error!\")\n","\t\t\tflag = True\n","\t\t\tres[i[:20]] = 0\n","\tif flag:\n","\t\tprint (output)\n","\t\tprint (res)\n","\treturn res\n","# gRNA_list = ['GGAATCCCTTCTGCAGCACCAGG','GGCCCAGACTGAGCACGTGAAGG']\n","# res = get_DeepSpCas9_score(gRNA_list)\n","# GGAATCCCTTCTGCAGCACC    55.750\n","# GGCCCAGACTGAGCACGTGA    52.897\n","# Name: DeepSpCas9 Score, dtype: float64"]},{"cell_type":"markdown","metadata":{"id":"CBilk5RJqSfh"},"source":["Utilities 2\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E6dOxlnhp_Ot","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"error","timestamp":1692611110984,"user_tz":-210,"elapsed":1564,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"}},"outputId":"a75dd6f7-c040-43e5-c5bb-21d80baecee6"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6bb1537cfdf2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdash_core_components\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdash_html_components\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dash'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import dash\n","import dash_core_components as dcc\n","import dash_html_components as html\n","import pandas as pd\n","import plotly.graph_objs as go\n","import dash_table\n","from flask import Flask, send_from_directory\n","from urllib.parse import quote as urlquote\n","import dash_bootstrap_components as dbc\n","\n","# import plotly_express as px\n","from dash.dependencies import Input, Output, State\n","import re\n","import os\n","import numpy as np\n","from sklearn.cluster import KMeans\n","import plotly.figure_factory as ff\n","import os\n","import base64\n","import datetime\n","from datetime import datetime as dt\n","import pathlib\n","import easy_prime\n","import io\n","import csv\n","from easy_prime.utils import get_parameters, print_parameters,vcf2fasta,fasta2vcf\n","from easy_prime import target_mutation\n","import subprocess\n","from joblib import Parallel, delayed\n","import urllib\n","from io import StringIO\n","import uuid\n","from Bio import SeqIO\n","import math\n","import pandas as pd\n","import uuid\n","import subprocess\n","import matplotlib.pyplot as plt\n","npg_colors = [\"#E64B35\",\"#4DBBD5\",\"#00A087\",\"#3C5488\",\"#F39B7F\",\"#464d4f\"]\n","my_colors = {}\n","my_colors['sgRNA'] = npg_colors[0]\n","my_colors['PBS'] = npg_colors[1]\n","my_colors['RTT'] = npg_colors[2]\n","my_colors['ngRNA'] = npg_colors[3]\n","my_colors['variant'] = \"#e6fc3f\"\n","\n","\n","def get_version():\n","\n","\treturn \"v%s\"%(easy_prime.__version__)\n","\n","def vis_pegRNA_png(df_file,jid):\n","\t# bedtools 2.29.2\n","\t# print (\"call easy_prime vis\")\n","\tgenome_fasta = \"/home/yli11/Data/Human/hg19/fasta/hg19.fa\"\n","\tif os.path.isfile(f\"results/{jid}.fa\"):\n","\t\tsubprocess.call(f\"easy_prime_vis -f {df_file} -s results/{jid}.fa --output_file_name results/{jid}.png\",shell=True)\n","\telse:\n","\t\t# print (\"using genome fasta\")\n","\t\tcmd = f\"easy_prime_vis -f {df_file} -s {genome_fasta} --output_file_name results/{jid}.png\"\n","\t\t# print (cmd)\n","\t\tsubprocess.call(cmd,shell=True)\n","\tfig = f\"results/{jid}.png\"\n","\twith open(fig, \"rb\") as image_file:\n","\t\timg_string = base64.b64encode(image_file.read())\n","\treturn \"data:image/png;base64,%s\"%(img_string.decode(\"utf-8\"))\n","\n","\n","def df2csv_string(df):\n","\tcsv_string = df.to_csv(index=False, encoding='utf-8')\n","\tcsv_string = \"data:text/csv;charset=utf-8,%EF%BB%BF\" + urllib.parse.quote(csv_string)\n","\treturn csv_string\n","\n","def file_download_link(filename):\n","    \"\"\"Create a Plotly Dash 'A' element that downloads a file from the app.\"\"\"\n","    location = \"results/{}\".format(urlquote(filename))\n","    return html.A(filename, href=location,target=\"_blank\")\n","\n","def get_current_pegRNA_table_title_and_download_links(df,jid):\n","\tPE = \"%.1f\"%(df.predicted_efficiency[0])+\"%\"\n","\tuse_columns = ['chr','start','end','seq',\"type\",'strand']\n","\tshow_columns = ['#chr','start','end','seq',\"type\",'strand']\n","\tdf = df[use_columns]\n","\tdf.columns = show_columns\n","\ttable =  dash_table.DataTable(\n","\t\tid='pegRNA-table',\n","\t\tcolumns=[\n","\t\t\t{'name': i, 'id': i, 'deletable': False} for i in show_columns\n","\t\t],\n","\t\tdata=df.to_dict('records'),\n","\t)\n","\n","\theader = dbc.FormGroup(\n","\t\t[\n","\t\t\thtml.H5(\"Current pegRNA/ngRNA selection. Predicted efficiency: %s\"%(PE),style={\"margin-right\":10,\"margin-left\":10}),\n","\t\t\thtml.A(html.Button('Download current selection',className=\"btn btn-dark\"),href=df2csv_string(df[show_columns]),target=\"_blank\",download=\"current_design.csv\" ,style={\"margin-right\":10}),\n","\t\t\thtml.A(html.Button('Download all predictions',className=\"btn btn-dark\"),href=\"results/{}\".format(urlquote(\"%s_rawX_pegRNAs.csv.gz\"%(jid))),target=\"_blank\",style={\"margin-right\":10}),\n","\t\t],\n","\t\trow=True,\n","\t)\n","\treturn [header,table]\n","\n","def get_current_selection_table(df):\n","\tshow_columns = ['chr','start','end','seq',\"predicted_efficiency\",'strand']\n","\ttable =  dash_table.DataTable(\n","\t\tid='pegRNA-table',\n","\t\tcolumns=[\n","\t\t\t{'name': i, 'id': i, 'deletable': False} for i in show_columns\n","\t\t],\n","\t\tdata=df.to_dict('records'),\n","\t)\n","\n","\treturn [html.H5(\"Current pegRNA/ngRNA selection\"),table]\n","\n","\n","download_current_selection_button = html.A(html.Button('Submit feedback!'),href='https://github.com/czbiohub/singlecell-dash/issues/new',target=\"_blank\")\n","\n","\n","#---------------------------------  prime search ---------------------------\n","def write_fasta(file_name,myDict):\n","\tout = open(file_name,\"wt\")\n","\tfor k in myDict:\n","\t\tout.write(\">\"+k+\"\\n\")\n","\t\tout.write(myDict[k]+\"\\n\")\n","\tout.close()\n","def read_fasta(f):\n","\tmy_dict = {}\n","\tfor r in SeqIO.parse(f, \"fasta\"):\n","\t\tmy_dict[r.id] = str(r.seq).upper()\n","\treturn my_dict\n","def run_steps(t,**kwargs):\n","\n","\tt.init(**kwargs)\n","\tt.search(**kwargs)\n","\tt.predict(**kwargs)\n","\n","\treturn [t.topX,t.rawX,t.X_p,t.found_PE3b,t.found_PE3,t.found_dPAM,t.found_PE2,t.N_sgRNA_found]\n","\n","def run_easy_prime_backend():\n","\n","\terror_message = \"\"\n","\treturn False,error_message\n","\n","def run_easy_prime_backend(vcf,jid,parameters):\n","\t# print (vcf.head())\n","\tif vcf.shape[1]==5:\n","\t\tvcf[5] = vcf2fasta(vcf,**parameters)\n","\t\tvcf = vcf[list(range(6))]\n","\n","\tvariant_list = vcf[2].tolist()\n","\tmy_targets = [target_mutation(*r) for i,r in vcf.iterrows()]\n","\n","\tdf_list = [run_steps(t,**parameters) for t in my_targets]\n","\n","\tsummary = pd.DataFrame([x[3:8] for x in df_list]).astype(int)\n","\tsummary.columns = ['found_PE3b','found_PE3','found_dPAM','found_PE2',\"N_sgRNA_found\"]\n","\tsummary.index = variant_list\n","\tsummary.to_csv(\"results/%s_summary.csv\"%(jid),index=True)\n","\n","\tdf_top = pd.concat([x[0] for x in df_list])\n","\tif df_top.shape[0]==0:\n","\t\t# print (\"no pegRNA (including PE2) were found for the input file\")\n","\t\treturn summary,pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n","\tdf_top = df_top.sort_values(\"predicted_efficiency\",ascending=False)\n","\tdf_top.to_csv(\"results/%s_topX_pegRNAs.csv\"%(jid),index=False)\n","\tdf_all = pd.concat([x[1] for x in df_list])\n","\tdf_all = df_all.sort_values(\"predicted_efficiency\",ascending=False)\n","\tdf_all.to_csv(\"results/%s_rawX_pegRNAs.csv.gz\"%(jid),index=False,compression=\"gzip\")\n","\n","\tX_p = pd.concat([x[2] for x in df_list])\n","\tX_p = X_p.sort_values(\"predicted_efficiency\",ascending=False)\n","\tX_p.to_csv(\"results/%s_X_p_pegRNAs.csv.gz\"%(jid),index=True,compression=\"gzip\")\n","\treturn summary,df_top,df_all,X_p\n","\n","def PD2fasta_dict(input_string):\n","\tout = {}\n","\tmyDict = read_fasta(StringIO(input_string))\n","\tfor k in myDict:\n","\t\ts = myDict[k]\n","\t\tif s.count(\"(\")>1:\n","\t\t\treturn 0\n","\t\tbefore = s[:s.find(\"(\")]\n","\t\tafter = s[s.find(\")\")+1:]\n","\t\tmutation = s[s.find(\"(\")+1:s.find(\")\")]\n","\t\tif \"+\" in mutation:\n","\t\t\tmutation = mutation.replace(\"+\",\"\")\n","\t\t\tref = before+after\n","\t\t\talt = before+mutation+after\n","\t\telif \"-\" in mutation:\n","\t\t\tmutation = mutation.replace(\"-\",\"\")\n","\t\t\tref = before+mutation+after\n","\t\t\talt = before+after\n","\t\telse:\n","\t\t\tmutation = mutation.split(\"/\")\n","\t\t\tref = before+mutation[0]+after\n","\t\t\talt = before+mutation[1]+after\n","\t\tout[\"%s_ref\"%(k)] = ref\n","\t\tout[\"%s_alt\"%(k)] = alt\n","\treturn out\n","main_chr_human = [\"chr1\",\"chr2\",\"chr3\",\"chr4\",\"chr5\",\"chr6\",\"chr7\",\"chrX\",\"chr8\",\"chr9\",\"chr10\",\"chr11\",\"chr12\",\"chr13\",\"chr14\",\"chr15\",\"chr16\",\"chr17\",\"chr18\",\"chr20\",\"chrY\",\"chr19\",\"chr22\",\"chr21\",\"chrM\"]\n","\n","def is_valid_DNA(sequence):\n","\tvalid_dna = \"ACGT\"\n","\treturn all(i in valid_dna for i in sequence)\n","\n","def check_and_convert_input(input_type,chr,pos,variant_id,ref,alt,vcf_batch,fasta_input,PrimeDesign_input,jid):\n","\terror_flag = False\n","\terror_message = \"\"\n","\tif input_type == \"vcf_tab\":\n","\t\tif not \"chr\" in chr:\n","\t\t\tchr = \"chr\"+chr\n","\t\tif not chr in main_chr_human:\n","\t\t\treturn None, True,\"Input chromosome %s not found in hg19 main chromosomes\"%(chr)\n","\t\ttry:\n","\t\t\tpos = int(pos)\n","\t\texcept:\n","\t\t\treturn None, True,\"Input Position %s can't converted to integer\"%(pos)\n","\t\tname = variant_id\n","\t\tif name == \"\":\n","\t\t\treturn None, True,\"Input Name is empty!\"\n","\t\tref = ref.upper()\n","\t\tif ref == \"\":\n","\t\t\treturn None, True,\"Input Name is empty!\"\n","\t\talt = alt.upper()\n","\t\tif alt == \"\":\n","\t\t\treturn None, True,\"Input Name is empty!\"\n","\t\tif not is_valid_DNA(ref):\n","\t\t\treturn None, True,\"Input reference allele is not valid, only A,C,G,T is allowed!\"\n","\t\tif not is_valid_DNA(alt):\n","\t\t\treturn None, True,\"Input alternative allele is not valid, only A,C,G,T is allowed!\"\n","\t\tvcf = pd.DataFrame([[chr,pos,name,ref,alt]])\n","\n","\tif input_type == \"vcf_batch_tab\":\n","\t\ttry:\n","\t\t\tvcf_batch = vcf_batch.replace(\" \",\"\\t\")\n","\t\t\tvcf = pd.read_csv(StringIO(vcf_batch),comment=\"#\",sep=\"\\t\",header=None)\n","\t\t\tvcf[1] = vcf[1].astype(int)\n","\t\t\tvcf =vcf.drop_duplicates(2) # remove duplicated names\n","\t\t\tvcf[3] = [x.upper() for x in vcf[3]]\n","\t\t\tvcf[4] = [x.upper() for x in vcf[4]]\n","\t\texcept Exception as e:\n","\t\t\t# print (e)\n","\t\t\treturn None, True,\"Input vcf_batch can't be parsed correctly! %s\"%(e)\n","\tif input_type == \"fasta_tab\":\n","\t\ttry:\n","\t\t\tfile_name = \"results/%s.fa\"%(jid)\n","\t\t\tmyDict = read_fasta(StringIO(fasta_input))\n","\t\t\twrite_fasta(file_name,myDict)\n","\t\t\tvcf = fasta2vcf(file_name)\n","\t\texcept Exception as e:\n","\t\t\t# print (e)\n","\t\t\treturn None,True,\"Input fasta can't be parsed correctly! Make sure fasta length >= 50bp. Error: %s\"%(e)\n","\tif input_type == \"PrimeDesign_tab\":\n","\t\ttry:\n","\t\t\tfile_name = \"results/%s.fa\"%(jid)\n","\t\t\tmyDict = PD2fasta_dict(PrimeDesign_input)\n","\t\t\twrite_fasta(file_name,myDict)\n","\t\t\tvcf = fasta2vcf(file_name)\n","\t\texcept Exception as e:\n","\t\t\t# print (e)\n","\t\t\treturn None,True,\"Input PrimeDesign sequences can't be parsed correctly! Currently, combinatorial editing in this format is not supported! %s\"%(e)\n","\n","\n","\treturn vcf,False,error_message\n","\n","\n","\n","def read_easy_prime_output(jid):\n","\trawX = pd.read_csv(\"results/%s_rawX_pegRNAs.csv.gz\"%(jid))\n","\tX_p = pd.read_csv(\"results/%s_X_p_pegRNAs.csv.gz\"%(jid),index_col=0)\n","\tX_p['sample_ID'] = X_p.index.tolist()\n","\trawX.index = rawX.sample_ID.tolist()\n","\n","\trawX['location_name'] = rawX.chr+\"_\"+rawX.start.astype(str)+\"_\"+rawX.end.astype(str)+\"_\"+rawX.seq\n","\trawX['DeepSpCas9_score'] = X_p['cas9_score']\n","\trawX['target_pos'] = X_p['Target_pos']\n","\trawX['nick_pos'] = X_p['nick_to_pegRNA']\n","\trawX['PBS_length'] = X_p['PBS_length']\n","\trawX['RTT_length'] = X_p['RTT_length']\n","\trawX['PE3b'] = X_p['PE3b']\n","\treturn rawX,X_p\n","\n","def get_options_dict(jid):\n","\tdf = pd.read_csv(\"results/%s_summary.csv\"%(jid),index_col=0)\n","\t# print (df.head())\n","\tout = []\n","\tfirst_valid = None\n","\tfor i,r in df.iterrows():\n","\t\tif r.found_PE2 == 0:\n","\t\t\tout.append({'label': i + \" | no pegRNA found\",'disabled': True, 'value': i})\n","\t\telse:\n","\t\t\tif not first_valid:\n","\t\t\t\tfirst_valid = i\n","\t\t\tout.append({'label': i, 'value': i})\n","\treturn out,first_valid\n","\n","def get_annotation_dPAM(x):\n","\tif \"dPAM\" in x:\n","\t\treturn \"PAM-disruption\"\n","\treturn \"\"\n","\n","def get_annotation_PE3b(x):\n","\n","\tif \"PE3b\" in x:\n","\t\treturn \"PE3b\"\n","\treturn \"\"\n","def force_recommend_dPAM_PE3b(r,max_eff):\n","\trank = 0\n","\tif \"PE3b\" in r.sample_ID:\n","\t\tif not max_eff-r.predicted_efficiency>max_eff*0.1:\n","\t\t\trank += 1\n","\tif \"dPAM\" in r.sample_ID:\n","\t\trank += 1\n","\treturn rank\n","def to_sgRNA_table(rawX,sample_ID):\n","\trawX_df = rawX[rawX.sample_ID.str.contains(sample_ID)]\n","\trawX_df = rawX_df[rawX_df['type']=='sgRNA']\n","\t# X_p_df = X_p[X_p.sample_ID.str.contains(sample_ID)]\n","\trawX_df = rawX_df.sort_values('predicted_efficiency',ascending=False)\n","\trawX_df = rawX_df.drop_duplicates(['chr','start','end'])\n","\tcolumns = ['chr','start','end','seq','DeepSpCas9_score','strand','target_pos','annotation']\n","\t# tmp = rawX_df.copy()\n","\trawX_df['rank'] = rawX_df.apply(lambda r:force_recommend_dPAM_PE3b(r,rawX_df.predicted_efficiency.max()),axis=1)\n","\trawX_df = rawX_df.sort_values(['rank','predicted_efficiency'],ascending=False)\n","\trawX_df['annotation'] = rawX_df.sample_ID.apply(get_annotation_dPAM)\n","\n","\trawX_df = rawX_df.reset_index(drop=True)\n","\treturn rawX_df[columns]\n","\n","def to_sgRNA_table2(rawX,X_p,sample_ID):\n","\trawX_df = rawX[rawX.sample_ID.str.contains(sample_ID)]\n","\trawX_df = rawX_df[rawX_df['type']=='sgRNA']\n","\tX_p_df = X_p[X_p.sample_ID.str.contains(sample_ID)]\n","\trawX_df = rawX_df.sort_values('predicted_efficiency',ascending=False)\n","\trawX_df = rawX_df.drop_duplicates(['chr','start','end'])\n","\n","\tcolumns = ['chr','start','end','seq','DeepSpCas9_score','strand','target_pos','annotation']\n","\trawX_df['DeepSpCas9_score'] = X_p_df['cas9_score']\n","\trawX_df['target_pos'] = X_p_df['Target_pos']\n","\trawX_df['annotation'] = \"\"\n","\trawX_df = rawX_df.reset_index(drop=True)\n","\tID_list = rawX_df.sample_ID.tolist()\n","\treturn rawX_df[columns],ID_list\n","\n","\n","def to_ngRNA_table(rawX,sgRNA_location):\n","\tsample_ID_list = rawX[(rawX.location_name==sgRNA_location)&(rawX['type']=='sgRNA')].sample_ID.tolist()\n","\trawX_df = rawX[rawX.sample_ID.isin(sample_ID_list)]\n","\trawX_df = rawX_df[rawX_df['type']=='ngRNA']\n","\trawX_df = rawX_df.drop_duplicates(['chr','start','end'])\n","\tcolumns = ['chr','start','end','seq','nick_pos','strand','annotation']\n","\trawX_df['annotation'] = rawX_df.sample_ID.apply(get_annotation_PE3b)\n","\n","\trawX_df['rank'] = rawX_df.apply(lambda r:force_recommend_dPAM_PE3b(r,rawX_df.predicted_efficiency.max()),axis=1)\n","\t# print (rawX_df.predicted_efficiency.max())\n","\t# rawX_df = rawX_df.sort_values(['rank','predicted_efficiency'],ascending=False)\n","\t# print (rawX_df['rank'].unique())\n","\n","\trawX_df['nick_pos_abs'] = rawX_df['nick_pos'].abs()\n","\trawX_df = rawX_df.sort_values('nick_pos_abs')\n","\trawX_df = rawX_df.drop(['nick_pos_abs'],axis=1)\n","\trawX_df = rawX_df.reset_index(drop=True)\n","\t# print (rawX_df.head())\n","\n","\treturn rawX_df[columns],rawX_df.sort_values(['rank','predicted_efficiency'],ascending=False).index[0]\n","\n","\n","def to_PBS_table(rawX,sgRNA_location):\n","\tsample_ID_list = rawX[(rawX.location_name==sgRNA_location)&(rawX['type']=='sgRNA')].sample_ID.tolist()\n","\trawX_df = rawX[rawX.sample_ID.isin(sample_ID_list)]\n","\trawX_df = rawX_df[rawX_df['type']=='PBS']\n","\tcolumns = ['chr','start','end','seq','PBS_length','strand']\n","\trawX_df = rawX_df.drop_duplicates('seq')\n","\n","\trawX_df['rank'] = rawX_df.apply(lambda r:force_recommend_dPAM_PE3b(r,rawX_df.predicted_efficiency.max()),axis=1)\n","\t# rawX_df['PBS_length'] = rawX_df.seq.apply(len)\n","\trawX_df = rawX_df.sort_values('PBS_length')\n","\trawX_df = rawX_df.reset_index(drop=True)\n","\n","\treturn rawX_df[columns],rawX_df.sort_values(['rank','predicted_efficiency'],ascending=False).index[0]\n","\n","\n","def to_RTT_table(rawX,sgRNA_location):\n","\tsample_ID_list = rawX[(rawX.location_name==sgRNA_location)&(rawX['type']=='sgRNA')].sample_ID.tolist()\n","\trawX_df = rawX[rawX.sample_ID.isin(sample_ID_list)]\n","\trawX_df = rawX_df[rawX_df['type']=='RTT']\n","\tcolumns = ['chr','start','end','seq','RTT_length','strand']\n","\trawX_df = rawX_df.drop_duplicates('seq')\n","\t# rawX_df['RTT_length'] = rawX_df.seq.apply(len)\n","\trawX_df['rank'] = rawX_df.apply(lambda r:force_recommend_dPAM_PE3b(r,rawX_df.predicted_efficiency.max()),axis=1)\n","\trawX_df = rawX_df.sort_values('RTT_length')\n","\trawX_df = rawX_df.reset_index(drop=True)\n","\n","\treturn rawX_df[columns],rawX_df.sort_values(['rank','predicted_efficiency'],ascending=False).index[0]\n","\n","\n","\n","def to_RTT_table2(rawX,sample_ID_list,best_ID=None):\n","\tif not best_ID:\n","\t\tbest_ID = sample_ID_list[0]\n","\trawX_df = rawX[rawX.sample_ID.isin(sample_ID_list)]\n","\trawX_df = rawX_df[rawX_df['type']=='RTT']\n","\tcolumns = ['chr','start','end','seq','RTT_length','strand']\n","\trawX_df = rawX_df.drop_duplicates('seq')\n","\trawX_df['RTT_length'] = rawX_df.seq.apply(len)\n","\trawX_df = rawX_df.sort_values('RTT_length')\n","\trawX_df = rawX_df.reset_index(drop=True)\n","\treturn rawX_df[columns],rawX_df[rawX_df.sample_ID == best_ID].index.tolist()\n","\n","\n","def get_uid():\n","\t# return \"easy_prime_yli11_2021-05-24_result_dir\"\n","\treturn str(uuid.uuid4()).split(\"-\")[-1]\n","\n","\n","\n","\n","#--------------------------------- dash app utils ---------------------------\n","\n","\n","def df2bedjs(df,output):\n","\t# sample_ID,CHROM,POS,REF,ALT,type,seq,chr,start,end,strand,predicted_efficiency\n","\t# FIG5G_HEK293T_HEK3_6XHIS_chr9_110184619_110184639_+_GGCCCAGACTGAGCACGTGA_candidate_1808,chr9,110184636,G,GCACCATCATCACCATCAT,ngRNA,GTCAACCAGTATCCCGGTGC,chr9,110184723,110184743,-,0.6275171041488647\n","\tdf['name'] = df.apply(lambda r:\"\"\"{\"strand\":\"%s\",\"name\":\"%s\",\"color\":\"%s\"}\"\"\"%(r.strand,r['type'],my_colors[r['type']]),axis=1)\n","\ttrack_name = \"pegRNA_design_%.1f\"%(df.predicted_efficiency[0])\n","\tdf = df[['chr','start','end','name']]\n","\t# print (df.head())\n","\tdf.sort_values('start').to_csv(\"results/%s.bed\"%(output),sep=\"\\t\",header=False,index=False,quoting=csv.QUOTE_NONE)\n","\tos.system(\"bgzip -f results/{0}.bed;tabix -f -p bed results/{0}.bed.gz\".format(output))\n","\n","\treturn '''{\"type\":\"bedj\",\"url\":\"http://easy-prime-test-dev.us-west-2.elasticbeanstalk.com/results/%s.bed.gz\",\"stackheight\":20,\"stackspace\":1,\"name\":\"%s\"},'''%(output,track_name)\n"]},{"cell_type":"markdown","metadata":{"id":"O_b0eyHDJe-n"},"source":["# PegRNA"]},{"cell_type":"markdown","metadata":{"id":"KT_eAvpvGQ4G"},"source":["PegRNA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFMDtY2eFSyl"},"outputs":[],"source":["class sgRNA:\n","\tdef __init__(self,chr=None,start=None,end=None,seq=None,sgRNA_name=None,strand=None,cut_position=None,mutation_pos = None,mutation_ref = None,mutation_alt = None,variant_id=None,dist_dict=None,opposite_strand_sgRNAs=None,all_sgRNA_df=None,target_fa=None,scaffold_seq=None,user_target_pos=None,user_ref=None,user_alt=None,offset=None,target_to_sgRNA=None,PAM=None,DeepSpCas9=None,**kwargs):\n","\n","\t\t#search key is chr_start_end_seq because seq can be duplicated, this chr_start_end_seq is unique. This name doesn't show strand, but seq is alwasy 5-3 direction\n","\t\t#Searching steps\n","\t\t#1. RTT\n","\t\t#2. PBS\n","\t\t#3. ngRNA\n","\t#\t---------------------------------------------------------------------------------------------------------------------------------\n","\n","\t# مقدار دهی متغییر ها با مقادیر ارسال شده به کلاس\n","\t\tself.chr = chr\n","\t\tself.start = start\n","\t\tself.end = end\n","\t\tself.seq = seq\n","\t\tself.variant_id = variant_id\n","\t\tself.target_to_sgRNA = target_to_sgRNA\n","\t\tself.DeepSpCas9 = DeepSpCas9\n","\t\tself.is_dPAM = 0\n","\t\tself.PAM = PAM\n","\t\tself.offset = offset\n","\t\tself.sgRNA_name = sgRNA_name\n","\t\tself.uid = str(uuid.uuid4()).split(\"-\")[-1]\n","\t\t# self.name = \"_\".join([chr,str(start),str(end),seq])\n","\t\tself.strand = strand\n","\t\tself.cut_position = cut_position\n","\t\tprint (cut_position)\n","\t\t# exit()\n","\t\tself.target_pos = mutation_pos ## this is the corrected, actual position of variant\n","\t\tself.target_fa = target_fa\n","\t\tself.scaffold_seq = scaffold_seq\n","\t\t# self.max_nick_distance = max_nick_distance\n","\t\tself.ref = mutation_ref\n","\t\tself.alt = mutation_alt\n","\t\tself.dist_dict = dist_dict ## other gRNAs in search space\n","\t\tself.opposite_strand_sgRNAs = opposite_strand_sgRNAs\n","\t\t# self.candidate_pegRNA_df = candidate_pegRNA_df\t ## other gRNAs in search space\n","\t\tself.nick_gRNA_list = []\n","\t\tself.user_target_pos = user_target_pos\n","\t\tself.user_ref = user_ref\n","\t\tself.user_alt = user_alt\n","\n","\n","\n","\t\t#for rawX\n","\t\t#\t\tSearching steps\n","\t\t#1. RTT\n","\t\t#2. PBS\n","\t\t#3. ngRNA\n","#------------------------------------------------------------------\n","\t\t#برای فهم بهتر ویژگی های هر سه دنباله را از هم جدا کردم و برای هر یم فریم دیتای جداگانه ساختم.\n","\t\t#ویژگی های تاثیرگذار برای هر دنباله در اینجا مشخص می شود\n","\n","\t\tself.PBS_df = pd.DataFrame()\n","\t\tself.RTT_df = pd.DataFrame()\n","\t\tself.ngRNA_df = pd.DataFrame()\n","\t\tself.PBS_feature_list = [\"PBS_GC\",'PBS_length']\n","\t\t#بعد اینکه ویژگی تاثیرگذار را یافتم نوکلئوتیدهای آخر را حذف کردم\n","\t\t# self.RTT_feature_list = [\"target_to_RTT5\",\"RTT_GC\",\"RTT_length\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\"]\n","\t\tself.RTT_feature_list = [\"target_to_RTT5\",\"RTT_GC\",\"RTT_length\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n","\t\tself.ngRNA_feature_list = ['sgRNA_distance_to_ngRNA','is_PE3b']\n","\t\tself.rawX = pd.DataFrame()\n","\t\tself.X = pd.DataFrame()\n","\t\tself.X_p = pd.DataFrame()\n","\t\t# sgRNA name = chr,start,end,seq,strand\n","\t\t## flags\n","\t\tself.no_RTT = False ## alwasy assume we can find valid RTT\n","\t\tself.no_ngRNA = False ## alwasy assume we can find valid ngRNA\n","\n","\n","\n","\n","\n","#--------------------------------------------------------------------------------------------------------\n","#  PBS sequences هدف این تابع پیدا کردن\n","# find PBS sequences as bed format df\n","#\t\t:خروجی های این تابع\n","#\t\t1.PBS_df\n","#\t\t2.PBS_feature_list\n","#لیست و دیتا فریم را در ابتدای کلاس تعریف  کرده بودم\n","\tdef find_PBS(self,min_PBS_length=7,max_PBS_length=17,**kwargs):\n","\n","    #این فلگ در بالا به صورت پیش فرض 0 در نظر گرفته شده است\n","\t\tif self.no_RTT:\n","\t\t\treturn 0\n","\n","\t\tout = []\n","\t\tchr = self.chr\n","\n","\t\tif self.strand==\"+\":\n","\t\t\tend = self.cut_position\n","\t\t\tfor l in range(min_PBS_length,max_PBS_length+1):\n","\t\t\t\tstart = end-l\n","\t\t\t\tout.append([chr,start,end])\n","\t\tif self.strand==\"-\":\n","\t\t\tstart = self.cut_position - 1\n","\t\t\tfor l in range(min_PBS_length,max_PBS_length+1):\n","\t\t\t\tend = start+l\n","\t\t\t\tout.append([chr,start,end])\n","\t\tself.PBS_df = pd.DataFrame(out)\n","\t\tself.PBS_df.columns = ['chr','start','end']\n","\t\tself.PBS_df[\"strand\"] = get_opposite_strand(self.strand)\n","\t\tself.PBS_df.index = [\"%s_PBS_%s\"%(self.uid,i) for i in range(self.PBS_df.shape[0])]\n","\t\ttemp = get_fasta_simple(self.target_fa,self.PBS_df, self.user_target_pos)\n","\t\tself.PBS_df['seq'] = temp[3].tolist()\n","    ## when sgRNA is positive strand, RTT should use the negative strand\n","\t\tif self.strand == \"+\":\n","\t\t\tself.PBS_df['seq'] = [revcomp(x) for x in self.PBS_df['seq']]\n","\n","\t\tself.PBS_df['PBS_GC'] = [GC_content(x) for x in self.PBS_df['seq'] ]\n","\t\tself.PBS_df['PBS_length'] = [len(x) for x in self.PBS_df['seq'] ]\n","\t\tprint(self.PBS_df)\n","\n","\n","\n","\n","#---------------------------------------------------------------------------------------------\n","\t# find RTT sequences as bed format df\n","\t#\tOutput:\n","\t#1. RTT_df\n","\t#2. RTT_feature_list\n","\n","\tdef find_RTT(self,debug=0,min_RTT_length=10,max_RTT_length=20,max_max_RTT_length=40,min_distance_RTT5=5,**kwargs):\n","\n","\t\tout = []\n","\t\tchr = self.chr\n","\t\tpbs_start = None\n","\t\tpbs_end = None\n","\t\tuser_max_RTT_length = max_RTT_length\n","\t\tlarge_deletion_flag=False\n","\n","\t\tif len(self.ref)+min_distance_RTT5 > max_RTT_length: ## in case of large deletion\n","\t\t\tlarge_deletion_flag = True\n","\t\t\tmax_RTT_length = max_RTT_length+len(self.ref)\n","\t\t# target_to_RTT5_feature=[]\n","\t\tdeletion_length = len(self.ref)-len(self.alt)\n","\t\tif self.strand==\"+\":\n","\t\t\tstart = self.cut_position # remember out cut position, the actual nucleotide, we use -4\n","\t\t\tpbs_end = start\n","\t\t\tpbs_start = pbs_end - 14\n","\t\t\tfor l in range(min_RTT_length,max_RTT_length+1+max(0,deletion_length)):\n","\t\t\t\tend = start+l\n","\t\t\t\tif start+1<=self.target_pos <=end-min_distance_RTT5:\n","\t\t\t\t\tout.append([chr,start,end,end-self.target_pos-max(0,deletion_length)])\n","\t\tif self.strand==\"-\":\n","\t\t\tend = self.cut_position - 1\n","\t\t\tpbs_start = end\n","\t\t\tpbs_end = pbs_start + 14\n","\t\t\tfor l in range(min_RTT_length,max_RTT_length+1+max(0,deletion_length)):\n","\t\t\t\tstart = end-l\n","\t\t\t\tif end>=self.target_pos >=start+1+min_distance_RTT5:\n","\t\t\t\t\tout.append([chr,start,end,self.target_pos-start-1-max(0,deletion_length)])\n","\n","\t\tcurrent_max_RTT_length = max_RTT_length+5\n","\t\twhile len(out) == 0:\n","\t\t\tif current_max_RTT_length > max_max_RTT_length:\n","\t\t\t\tbreak\n","\t\t\tout,_,no_RTT_flag = self.find_longer_RTT(min_RTT_length=min_RTT_length,max_RTT_length=current_max_RTT_length,min_distance_RTT5=min_distance_RTT5,**kwargs)\n","\t\t\tif len(out) > 0:\n","\t\t\t\tprint (\"max_RTT_length increased from %s to %s\"%(max_RTT_length,current_max_RTT_length))\n","\t\t\t\tbreak\n","\t\t\tcurrent_max_RTT_length += 5\n","\n","\t\tif len(out) == 0:\n","\t\t\t## valid RTT not found\n","\t\t\tself.no_RTT = True\n","\t\t\tprint (\"No valid RTT found given current max length:%s\"%(max_max_RTT_length))\n","\t\t\treturn 0\n","\t\tself.RTT_df = pd.DataFrame(out)\n","\t\tself.RTT_df.columns = ['chr','start','end','target_to_RTT5']\n","\t\tself.RTT_df[\"strand\"] = get_opposite_strand(self.strand)\n","\t\tself.RTT_df.index = [\"%s_RTT_%s\"%(self.uid,i) for i in range(self.RTT_df.shape[0])]\n","\t\tif debug>10:\n","\t\t\tprint (self.target_fa)\n","\t\t\tprint (self.user_target_pos)\n","\t\ttemp = get_fasta_simple(self.target_fa,self.RTT_df, self.user_target_pos)\n","\t\tself.RTT_df['old_seq'] = temp[3].tolist()\n","\n","\t\t## add variant\n","\t\t# relative_pos = self.target_pos-r['start']-1 # start is 0-index\n","\t\tif debug>10:\n","\t\t\tpd.set_option('display.max_columns', None)\n","\t\t\tprint (self.RTT_df)\n","\t\tself.RTT_df['seq'] = [self.add_variant(r['old_seq'],self.target_pos-r['start']-1,self.ref,self.alt) for i,r in self.RTT_df.iterrows()]\n","\t\tself.RTT_df = self.RTT_df[self.RTT_df['seq']!=0]\n","\t\tif self.strand == \"+\": ## when sgRNA is positive strand, RTT should use the negative strand\n","\t\t\tself.RTT_df['seq'] = [revcomp(x) for x in self.RTT_df['seq']]\n","\t\t# print (self.RTT_df)\n","\t\tself.RTT_df['RTT_length'] = [len(x) for x in self.RTT_df['seq'] ]\n","\t\tif large_deletion_flag:\n","\t\t\tself.RTT_df = self.RTT_df[self.RTT_df['RTT_length']<=user_max_RTT_length]\n","\t\tself.RTT_df = self.RTT_df[self.RTT_df['RTT_length']>=min_RTT_length]\n","\t\t# filter out first C\n","\t\tself.RTT_df['firstC'] = [x[0] for x in self.RTT_df['seq']]\n","\t\tself.RTT_df = self.RTT_df[self.RTT_df['firstC']!=\"C\"]\n","\t\tself.RTT_df = self.RTT_df.drop(['firstC'],axis=1)\n","\n","\n","\t\tcurrent_max_RTT_length = max_RTT_length+5\n","\t\twhile self.RTT_df.shape[0] == 0:\n","\t\t\tif debug>=10:\n","\t\t\t\tprint (\"increasing max_RTT_length to:\", current_max_RTT_length)\n","\t\t\tif current_max_RTT_length > max_max_RTT_length:\n","\t\t\t\tbreak\n","\t\t\t_,RTT_df,no_RTT_flag = self.find_longer_RTT(min_RTT_length=min_RTT_length,max_RTT_length=current_max_RTT_length,min_distance_RTT5=min_distance_RTT5,**kwargs)\n","\t\t\tif RTT_df.shape[0] > 0:\n","\t\t\t\tprint (\"max_RTT_length increased from %s to %s\"%(max_RTT_length,current_max_RTT_length))\n","\t\t\t\tself.RTT_df = RTT_df\n","\t\t\t\tbreak\n","\t\t\tcurrent_max_RTT_length += 5\n","\n","\n","\n","\t\tif self.RTT_df.shape[0] == 0:\n","\t\t\t## valid RTT not found\n","\t\t\tself.no_RTT = True\n","\t\t\tprint (\"NO RTT found: new RTT sequence length is longer than: %s\"%(max_max_RTT_length))\n","\t\t\treturn 0\n","\n","\n","\t\t## make features\n","\t\t## modify it to fit fasta input\n","\t\tattached_minimal_PBS = sub_fasta_single(self.target_fa,self.user_target_pos, pbs_start,pbs_end)\n","\t\tif self.strand == \"+\": ## when sgRNA is positive strand, RTT should use the negative strand\n","\t\t\tattached_minimal_PBS = revcomp(attached_minimal_PBS)\n","\t\t# print (\"attached_minimal_PBS\",attached_minimal_PBS)\n","\t\t# print (self.RTT_df)\n","\n","\n","\t\tself.RTT_df['RNAfold_seq']= [(self.scaffold_seq+x+attached_minimal_PBS).replace(\"T\",\"U\") for x in self.RTT_df['seq']]\n","\t\tRNAfold_features_df = pd.DataFrame([call_RNAplfold(x,len(self.scaffold_seq))for x in self.RTT_df['RNAfold_seq']])\n","\t\t# print (RNAfold_features_df)\n","\t\tRNAfold_features_df.index = self.RTT_df.index.tolist()\n","\t\tself.RTT_df = pd.concat([self.RTT_df,RNAfold_features_df],axis=1)\n","\t\tself.RTT_df['RTT_GC'] = [GC_content(x) for x in self.RTT_df['seq'] ]\n","\n","\t\tself.RTT_df.columns = [str(x) for x in self.RTT_df.columns]\n","\t\tself.is_dPAM = is_dPAM(self.PAM, self.RTT_df['seq'][0], self.offset)\n","\t\t# print (self.RTT_df)\n","\n","\n","\n","#find RTT sequences as bed format df هدف تابع\n","\t\t#Output:\n","    #1.RTT_df\n","\t\t#2.RTT_feature_list\n","\n","\tdef find_longer_RTT(self,min_RTT_length=10,max_RTT_length=20,min_distance_RTT5=5,**kwargs):\n","\t\tout = []\n","\t\tchr = self.chr\n","\t\tpbs_start = None\n","\t\tpbs_end = None\n","\t\tuser_max_RTT_length = max_RTT_length\n","\t\tlarge_deletion_flag=False\n","\t\tif len(self.ref)+min_distance_RTT5 > max_RTT_length: ## in case of large deletion\n","\t\t\tlarge_deletion_flag = True\n","\t\t\tmax_RTT_length = max_RTT_length+len(self.ref)\n","\t\t# target_to_RTT5_feature=[]\n","\t\tif self.strand==\"+\":\n","\t\t\tstart = self.cut_position # remember out cut position, the actual nucleotide, we use -4\n","\t\t\tpbs_end = start\n","\t\t\tpbs_start = pbs_end - 14\n","\t\t\tfor l in range(min_RTT_length,max_RTT_length+1):\n","\t\t\t\tend = start+l\n","\t\t\t\tif start+1<=self.target_pos <=end-min_distance_RTT5:\n","\t\t\t\t\tout.append([chr,start,end,end-self.target_pos])\n","\t\tif self.strand==\"-\":\n","\t\t\tend = self.cut_position - 1\n","\t\t\tpbs_start = end\n","\t\t\tpbs_end = pbs_start + 14\n","\t\t\tfor l in range(min_RTT_length,max_RTT_length+1):\n","\t\t\t\tstart = end-l\n","\t\t\t\tif end>=self.target_pos >=start+1+min_distance_RTT5:\n","\t\t\t\t\tout.append([chr,start,end,self.target_pos-start-1])\n","\t\tif len(out) == 0:\n","\t\t\treturn out,self.RTT_df,True\n","\t\tself.RTT_df = pd.DataFrame(out)\n","\t\tself.RTT_df.columns = ['chr','start','end','target_to_RTT5']\n","\t\tself.RTT_df[\"strand\"] = get_opposite_strand(self.strand)\n","\t\tself.RTT_df.index = [\"%s_RTT_%s\"%(self.uid,i) for i in range(self.RTT_df.shape[0])]\n","\t\ttemp = get_fasta_simple(self.target_fa,self.RTT_df, self.user_target_pos)\n","\t\tself.RTT_df['old_seq'] = temp[3].tolist()\n","\n","\t\t## add variant\n","\t\t# relative_pos = self.target_pos-r['start']-1 # start is 0-index\n","\t\tself.RTT_df['seq'] = [self.add_variant(r['old_seq'],self.target_pos-r['start']-1,self.ref,self.alt) for i,r in self.RTT_df.iterrows()]\n","\t\tself.RTT_df = self.RTT_df[self.RTT_df['seq']!=0]\n","\t\tif self.strand == \"+\": ## when sgRNA is positive strand, RTT should use the negative strand\n","\t\t\tself.RTT_df['seq'] = [revcomp(x) for x in self.RTT_df['seq']]\n","\t\t# print (self.RTT_df)\n","\t\tself.RTT_df['RTT_length'] = [len(x) for x in self.RTT_df['seq'] ]\n","\t\tif large_deletion_flag:\n","\t\t\tself.RTT_df = self.RTT_df[self.RTT_df['RTT_length']<=user_max_RTT_length]\n","\t\tself.RTT_df = self.RTT_df[self.RTT_df['RTT_length']>=min_RTT_length]\n","\t\t# filter out first C\n","\t\tself.RTT_df['firstC'] = [x[0] for x in self.RTT_df['seq']]\n","\t\tself.RTT_df = self.RTT_df[self.RTT_df['firstC']!=\"C\"]\n","\t\tself.RTT_df = self.RTT_df.drop(['firstC'],axis=1)\n","\t\tif self.RTT_df.shape[0] == 0:\n","\t\t\treturn out,self.RTT_df,True\n","\t\treturn out,self.RTT_df,False\n","\n","#-----------------------------------------------------------------------------\n","\t\t#check if target mutation overlaps with ngRNA and update its sequence\tonly work for len(ref) = len(alt), namely substitutions\n","\t\t#return sequence\n","\t\t# check if overlaps\n","\n","\tdef make_PE3b_ngRNA(self,myIndex,start,end,seq,strand):\n","\t\ttarget_pos_list = list(range(self.target_pos,self.target_pos+len(self.ref)))\n","\t\tseq_pos_list = list(range(start+1,end+1))\n","\t\toverlaps = set(seq_pos_list).intersection(target_pos_list)\n","\n","\t\tif len(overlaps) == 0:\n","\t\t\treturn [myIndex,seq,0]\n","\t\t# print (seq,\"contain overlaps\",overlaps)\n","\t\tif strand == \"-\":\n","\t\t\tnew_seq = list(revcomp(seq))\n","\t\telse:\n","\t\t\tnew_seq = list(seq)\n","\t\tfor i in overlaps:\n","\t\t\trelative_ngRNA_pos = i - start - 1\n","\t\t\trelative_target_pos = i - self.target_pos\n","\t\t\tif relative_ngRNA_pos < 0 or relative_target_pos<0:\n","\t\t\t\tprint (\"Error: make_PE3b_ngRNA\",relative_target_pos,relative_ngRNA_pos,self.sgRNA_name,start,end,new_seq,strand,self.variant_id)\n","\t\t\t\treturn [myIndex,seq,0]\n","\t\t\t\trelative_ngRNA_pos = 0\n","\t\t\tngRNA_ref = new_seq[relative_ngRNA_pos]\n","\t\t\ttarget_ref = self.ref[relative_target_pos]\n","\t\t\ttarget_alt = self.alt[relative_target_pos]\n","\t\t\tif target_ref != ngRNA_ref:\n","\t\t\t\tprint (\"Error: target_ref != ngRNA_ref\",\"%s != %s\"%(target_ref,ngRNA_ref),relative_target_pos,relative_ngRNA_pos,start,end,new_seq,strand,self.variant_id)\n","\t\t\t\treturn [myIndex,seq,0]\n","\t\t\tnew_seq[relative_ngRNA_pos] = target_alt\n","\t\tif strand == \"-\":\n","\t\t\tnew_seq = revcomp(\"\".join(new_seq))\n","\t\t\treturn [myIndex,new_seq,1]\n","\t\telse:\n","\t\t\tnew_seq = \"\".join(new_seq)\n","\t\t\treturn [myIndex,new_seq,1]\n","\n","\n","\n","#------------------------------------------------------------------------------\n","\t#find all valid ngRNAs given the sgRNA name هدف تابع\n","\t#Input: ngRNA_df , gRNA_feature_list\n","\n","\tdef find_nick_gRNA(self,max_ngRNA_distance=100,max_max_ngRNA_distance=200,debug=0,**kwargs):\n","\t\tself.ngRNA_df = self.opposite_strand_sgRNAs.copy()\n","\t\t# print (self.ngRNA_df)\n","\t\tif self.ngRNA_df.shape[0] == 0:\n","\t\t\tself.no_ngRNA = True\n","\t\t\tprint (\"no ngRNA for %s\"%(self.sgRNA_name))\n","\t\t\treturn 0\n","\t\tself.ngRNA_df.index = [\"%s_ngRNA_%s\"%(self.uid,i) for i in range(self.ngRNA_df.shape[0])]\n","\t\tself.ngRNA_df.columns = ['chr','start','end','seq','sgRNA_name','strand']\n","\t\tif self.strand == \"-\":\n","\t\t\tself.ngRNA_df['sgRNA_distance_to_ngRNA'] = [-self.dist_dict[x][self.sgRNA_name] for x in self.ngRNA_df[\"sgRNA_name\"]]\n","\t\tif self.strand == \"+\":\n","\t\t\tself.ngRNA_df['sgRNA_distance_to_ngRNA'] = [self.dist_dict[x][self.sgRNA_name] for x in self.ngRNA_df['sgRNA_name']]\n","\t\t# print (max_ngRNA_distance,\"max_ngRNA_distance\")\n","\t\tcurrent_ngRNA_df = self.ngRNA_df[self.ngRNA_df['sgRNA_distance_to_ngRNA'].abs()<=max_ngRNA_distance]\n","\t\tcurrent_max_ngRNA_distance = max_ngRNA_distance + 20\n","\t\twhile current_ngRNA_df.shape[0] == 0:\n","\t\t\tif current_max_ngRNA_distance > max_max_ngRNA_distance:\n","\t\t\t\tself.ngRNA_df = current_ngRNA_df\n","\t\t\t\tbreak\n","\t\t\tcurrent_ngRNA_df = self.ngRNA_df[self.ngRNA_df['sgRNA_distance_to_ngRNA'].abs()<=current_max_ngRNA_distance]\n","\t\t\tif current_ngRNA_df.shape[0] > 0:\n","\t\t\t\tself.ngRNA_df = current_ngRNA_df\n","\t\t\t\tprint (\"max ngRNA distance increased from %s to %s:\"%(max_ngRNA_distance,current_max_ngRNA_distance))\n","\t\t\t\tbreak\n","\t\t\tcurrent_max_ngRNA_distance += 20\n","\t\tself.ngRNA_df = current_ngRNA_df\n","\t\tif self.ngRNA_df.shape[0] == 0:\n","\t\t\tprint (\"no ngRNA for max distance: %s\"%(max_ngRNA_distance))\n","\t\t\tself.no_ngRNA = True\n","\t\t\treturn 0\n","\n","\t\tself.ngRNA_df['is_PE3b'] = 0\n","\n","\t\tif len(self.ref) == len(self.alt): # check PE3b\n","\t\t\tpe3b = pd.DataFrame([self.make_PE3b_ngRNA(\t\ti,\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tr['start'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tr['end'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tr['seq'],\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tr['strand']\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t) for i,r in self.ngRNA_df.iterrows()])\n","\t\t\t# print (\"-\"*20,self.variant_id,\"-\"*20)\n","\t\t\t# print (pe3b)\n","\t\t\tpe3b = pe3b.set_index(0)\n","\t\t\tself.ngRNA_df[['seq','is_PE3b']] = pe3b[[1,2]]\n","\t  \t# print (self.ngRNA_df)\n","\n","\n","\n","\n","#-------------------------------------------------------------------------------\n","\t\t#Steps:\n","\t\t#Assume all input is on the positive strand\n","    #ref alt is the corrected version\n","\t\t#e.g., GC - > C becomes C to \"\" (empty)\n","\t\t#relative_pos 0-index\n","\n","\tdef add_variant(self,RTT_seq,relative_pos,ref,alt,**kwargs):\n","\n","\t\t## function check\n","\t\tif len(ref)>0:\n","\t\t\tget_ref = RTT_seq[relative_pos:relative_pos+len(ref)]\n","\t\t\t# print (self.sgRNA_name,\"relative_pos\",relative_pos,\"get_ref\",get_ref)\n","\t\t\tif get_ref != ref:\n","\t\t\t\tif len(get_ref)<len(ref):\n","\t\t\t\t\t## large deletion, given RTT is not long enough\n","\t\t\t\t\treturn 0\n","\t\t\t\tprint (self.variant_id,self.sgRNA_name,\"references do not match\",RTT_seq,relative_pos,ref,alt)\n","\t\t\t\treturn 0\n","\t\tif relative_pos < 0:\n","\t\t\tprint (self.variant_id,self.sgRNA_name,\"relative position < 0, result will not be correct!\")\n","\t\t\treturn 0\n","\t\t\trelative_pos = 0\n","\t\tnew_RTT = RTT_seq[:relative_pos]\t+ self.alt + RTT_seq[relative_pos+len(self.ref):]\n","\t\treturn new_RTT\n","\n","\n","\n","\n","#-------------------------------------------------------------------------------\n","#get rawX and X formated dataframe, we can use the itertools to take all combinations of the index then we concat them as rows, -> rawX \twe concat them as columns -> X\n","#input: PBS, RTT, ngRNA sequences and features\n","#output: self.rawX, \t\tself.X\n","\n","\tdef get_rawX_and_X(self,debug=0,**kwargs):\n","\n","\n","\t\trawX_columns = [\"seq\",\"chr\",\"start\",\"end\",\"strand\"]\n","\n","\t\tif self.no_RTT:\n","\t\t\treturn 0\n","\t\t## not allow PE2 cases\n","\t\tif self.no_ngRNA:\n","\t\t\tprint (\"no_ngRNA found\",self.sgRNA_name)\n","\t\t\treturn 0\n","\t\t\tself.ngRNA_df=pd.DataFrame([np.nan]*(len(self.ngRNA_feature_list)+len(rawX_columns))).T\n","\t\t\tself.ngRNA_df.columns = rawX_columns + self.ngRNA_feature_list\n","\t\tif debug>=10:\n","\t\t\tprint (self.variant_id,\"showing PBS_df, RTT_df, and ngRNA df\")\n","\t\t\tprint (self.PBS_df.head())\n","\t\t\tprint (self.RTT_df.head())\n","\t\t\tprint (self.ngRNA_df.head())\n","\t\tX_index = []\n","\t\tPBS_selected_rows =[]\n","\t\tRTT_selected_rows =[]\n","\t\tngRNA_selected_rows =[]\n","\t\tall_list = [self.PBS_df.index.tolist(),self.RTT_df.index.tolist(),self.ngRNA_df.index.tolist()]\n","\t\ttemp = list(itertools.product(*all_list))\n","\t\tcount = 0\n","\t\tfor s in temp:\n","\t\t\tcount += 1\n","\t\t\tcurrent_index = \"%s_%s_candidate_%s\"%(self.variant_id,self.sgRNA_name,count)\n","\t\t\t# current_index = \"%s_%s\"%(self.variant_id,count) # shorter name\n","\t\t\tif count == 1  and debug>10:\n","\t\t\t\tprint (current_index)\n","\t\t\tPBS_selected_rows.append(s[0])\n","\t\t\tRTT_selected_rows.append(s[1])\n","\t\t\tngRNA_selected_rows.append(s[2])\n","\t\t\tif self.ngRNA_df.at[s[2],'is_PE3b']==1:\n","\t\t\t\tcurrent_index+=\"_PE3b\"\n","\t\t\t\t# print (s[2],\"PE3B\")\n","\t\t\tif self.is_dPAM:\n","\t\t\t\tcurrent_index+=\"_dPAM\"\n","\t\t\t\t# print (self.sgRNA_name,\"dPAM\")\n","\t\t\tif self.no_ngRNA:\n","\t\t\t\tcurrent_index+=\"_PE2\"\n","\t\t\tX_index.append(current_index)\n","\n","\n","\t\t# ------------------------------------------------------------  rawX  ------------------------------------------------------------\n","\t\trawX_PBS = self.PBS_df.loc[PBS_selected_rows][rawX_columns]\n","\t\trawX_RTT = self.RTT_df.loc[RTT_selected_rows][rawX_columns]\n","\t\trawX_ngRNA = self.ngRNA_df.loc[ngRNA_selected_rows][rawX_columns]\n","\t\trawX_sgRNA = pd.DataFrame([self.seq,self.chr,self.start,self.end,self.strand]).T\n","\t\trawX_sgRNA.columns = rawX_columns\n","\t\trawX_sgRNA = rawX_sgRNA.loc[[0]*len(ngRNA_selected_rows)][rawX_columns]\n","\t\trawX_PBS['sample_ID']  = X_index\n","\t\trawX_RTT['sample_ID']  = X_index\n","\t\trawX_ngRNA['sample_ID']  = X_index\n","\t\trawX_sgRNA['sample_ID']  = X_index\n","\t\trawX = pd.concat([rawX_PBS,rawX_RTT,rawX_ngRNA,rawX_sgRNA])\n","\t\trawX['CHROM'] = self.chr\n","\t\trawX['POS'] = self.user_target_pos\n","\t\trawX['REF'] = self.user_ref\n","\t\trawX['ALT'] = self.user_alt\n","\t\trawX['type'] = ['PBS']*rawX_PBS.shape[0]+['RTT']*rawX_RTT.shape[0]+['ngRNA']*rawX_ngRNA.shape[0]+['sgRNA']*rawX_ngRNA.shape[0]\n","\t\tself.rawX = rawX[[\"sample_ID\",\"CHROM\",\"POS\",\"REF\",\"ALT\",\"type\",\"seq\",\"chr\",\"start\",\"end\",\"strand\"]]\n","\t\tself.rawX = self.rawX.sort_values(\"sample_ID\")\n","\t\tself.rawX.index = self.rawX['sample_ID'].tolist()\n","\n","\n","\n","\t\t# ------------------------------------------------------------  X  ------------------------------------------------------------\n","\n","\t\tX_PBS = self.PBS_df.loc[PBS_selected_rows][self.PBS_feature_list]\n","\t\tX_PBS = X_PBS.reset_index(drop=True)\n","\t\tX_RTT = self.RTT_df.loc[RTT_selected_rows][self.RTT_feature_list]\n","\t\tX_RTT = X_RTT.reset_index(drop=True)\n","\t\tX_ngRNA = self.ngRNA_df.loc[ngRNA_selected_rows][self.ngRNA_feature_list]\n","\t\tX_ngRNA = X_ngRNA.reset_index(drop=True)\n","\t\tself.X = pd.concat([X_PBS,X_RTT,X_ngRNA],axis=1)\n","\t\tself.X.index = X_index\n","\t\tself.X['is_dPAM'] = self.is_dPAM\n","\t\tself.X['target_to_sgRNA'] = self.target_to_sgRNA\n","\t\tself.X['DeepSpCas9'] = self.DeepSpCas9\n","\t\tprint (\"kkkkkkkkkkkkkkkkk\")\n","\t\tprint (\"init\",sgRNA_name)\n"]},{"cell_type":"markdown","metadata":{"id":"aA1yaxl8GtrU"},"source":["# Target mutation"]},{"cell_type":"code","source":["#تعدادی از ویژگی های تاثیر گذار در دقت خروجی ویرایش مد نظر اینجا تعریف می شوند و تعدادی هم که در سلول بالا و کلاس sgRNA تعریف شده اند\n","# (nick_to_pegRNA', 'target_to_pegRNA', 'target_to_RTT5','aln_ref_alt_mis', 'aln_ref_alt_del', 'aln_ref_alt_ins',  'PBS_GC', 'RTS_GC','PBS_length', 'RTS_length', 0, 1, 2, 3, 4, 5, 6, 7,\n","# (nick_to_pegRNA,target_to_pegRNA,'is_dPAM' ,'aln_ref_alt_mis', 'aln_ref_alt_del', 'aln_ref_alt_ins')define here\n","\n","# (target_to_RTT5, RTS_GC, RTS_length,0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 ) defined  in sgRNA class / find_RTT\n","# (PBS_GC,PBS_length):  defined in sgRNA class /find_PBS\n","\n","\n","\n","#solve the problem when user specification of ref, alt contain redundancy ATTTT-> ATTT, should be T -> \"\" G - > GC will  be \"\" C\n","def find_mutation_pos(pos,ref,alt):\n","\tcount=0\n","\tfor i in range(min(len(ref),len(alt))):\n","\t\tx=ref[i]\n","\t\ty=alt[i]\n","\t\tif x != y:\n","\t\t\treturn pos,ref[i:],alt[i:]\n","\t\telse:\n","\t\t\tpos+=1\n","\t\t\tcount+=1\n","\treturn pos,ref[count:],alt[count:]\n","\n","\n","class target_mutation:\n","\tdef __init__(self,chr,pos,name,ref,alt,target_fa,**kwargs):\n","\t  #sgRNA name: chr_start_end_strand_seq\n","\t\t#target_mutation name: id_chr_pos_ref_alt\n","    #pos is corrected, and the corrected pos, ref, alt is used\n","    #\ttarget_fa is the +-1000 extended sequences\n","\n","\t\tself.chr = chr\n","\t\tself.target_pos = pos\n","\t\tself.name = name.replace(\"/\",\"_\").replace(\",\",\"_\")\n","\t\tself.ref = ref\n","\t\tself.alt = alt\n","\t\tself.target_fa = target_fa\n","\t\tself.debug_folder = \"easy_prime_debug_files\"\n","\t\tself.dist_dict = {}\n","\t\tself.strand_dict = {}\n","\t\tself.rawX = pd.DataFrame()\n","\t\tself.X = pd.DataFrame()\n","\t\tself.X_p = pd.DataFrame()\n","\t\tself.topX = pd.DataFrame()\n","\t\tself.allX = pd.DataFrame()\n","\t\tself.pegRNA_flag=True\n","\t\t## flags\n","\t\tself.found_PE3b = False\n","\t\tself.found_PE3 = False\n","\t\tself.found_PE2 = False\n","\t\tself.found_dPAM = False\n","\t\tself.N_sgRNA_found = 0\n","\n","\n","\t\t# self.feature_for_prediction = [\"sgRNA_distance_to_ngRNA\",\"target_to_sgRNA\",\"target_to_RTT5\",\"N_subsitution\",\"N_deletion\",\"N_insertions\",\"PBS_GC\",\"RTT_GC\",\"PBS_length\",\"RTT_length\",'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\"is_dPAM\"] # match the order of training features\n","\t\tself.feature_for_prediction = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9','DeepSpCas9',\"sgRNA_distance_to_ngRNA\",\"is_dPAM\",'is_PE3b','RTT_GC', 'RTT_length', 'PBS_GC', 'PBS_length', 'N_subsitution', 'N_deletion', 'N_insertions',\"target_to_sgRNA\",\"target_to_RTT5\"] # match the order of training features\n","\t\t# self.feature_rename = [\"ngRNA_pos\",\"Target_pos\",\"Target_end_flank\",\"N_subsitution\",\"N_deletion\",\"N_insertions\",\"PBS_GC\",\"RTT_GC\",\"PBS_length\",\"RTT_length\",'Folding_DS_1', 'Folding_DS_2', 'Folding_DS_3', 'Folding_DS_4', 'Folding_DS_5', 'Folding_DS_6', 'Folding_DS_7', 'Folding_DS_8', 'Folding_DS_9','Folding_DS_10',\"is_dPAM\"]\n","\t\tself.PE3_model_feature_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'cas9_score', 'nick_to_pegRNA', 'dPAM', 'PE3b', 'RTT_GC', 'RTT_length', 'PBS_GC', 'PBS_length', 'N_subsitution', 'N_deletion', 'N_insertions', 'Target_pos', 'Target_end_flank']\n","\t\tself.PE2_model_feature_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'cas9_score', 'RTT_GC', 'RTT_length', 'PBS_GC', 'PBS_length', 'N_subsitution', 'N_deletion', 'N_insertions', 'Target_pos', 'Target_end_flank','dPAM']\n","\n","\n","\n","\t\tself.mutation_pos,self.mutation_ref,self.mutation_alt = find_mutation_pos(pos,ref,alt)\n","\t\tself.sgRNA_strand_df={}\n","\t\tself.sgRNA_strand_df[\"+\"]=pd.DataFrame()\n","\t\tself.sgRNA_strand_df[\"-\"]=pd.DataFrame()\n","\t\tself.valid_init_sgRNA = pd.DataFrame()\n","\t\tself.all_sgRNA = pd.DataFrame() # used to find ngRNA\n","\n","\t\t#---------------- features --------------------------------------------------------------------------------------------------------------------------\n","\t\t# target mutation feature\n","\t\tself.ref_alt = global_alignments(self.ref,self.alt)\n","\t\tself.sgRNA_target_distance_dict = {} ## contain valid and invalid sgRNA in the key, but the latter with  distance <0\n","\t\tself.DeepSpCas9_dict = {}\n","\t\tself.sgRNA_target_dPAM_dict = {} ## contain binary values of whether the target affect this sgRNA PAM\n","\t\t# sgRNA distance to ngRNA\n","\t\tself.dist_dict = {} ## sgRNA_ngRNA_distance_dict\n","\n","\n","\tdef init(self,gRNA_search_space=200,search_iteration=1,sgRNA_length=20,PAM=\"NGG\",offset=-3,debug=0,genome_fasta=None,max_RTT_length=40,min_distance_RTT5=5,max_target_to_sgRNA=10,max_max_target_to_sgRNA=30,**kwargs):\n","\t\t#first step: search sgRNA\n","\t\t#second step: search PBS\n","\t\t#search for candidate sgRNAs around target mutation\n","\t\t#Input:1-\tgRNA_search_space: extend pos by +- gRNA_search_space\n","    #2-search_iteration: if in the search space defined by gRNA_search_space, we fail to find sgRNAs, we will extend the gRNA_search_space further to find at least one sgRNA. (no need to increase it)\n","\t\t#Output:chr, start, end, sgRNA name, seq, strand, cut_position, valid\n","\t\t#These will be used later: self.offset ,self.PAM\n","\n","\t\tif debug>0:\n","\t\t\tsubprocess.call(\"mkdir -p %s\"%(self.debug_folder),shell=True)\n","\t\t\tself.offset = offset\n","\t\tself.PAM = PAM\n","\n","\n","\t\t### find all sgRNA given a sequence\n","\t\tfor i in range(search_iteration):\n","\t\t\textend = gRNA_search_space*(i+1)\n","\t\t\tif i >=1:\n","\t\t\t\tprint (\"No sgRNA were found using %s gRNA_search_space\"%(extend))\n","\t\t\t## modified for fasta input\n","\t\t\tstart = max(self.mutation_pos-extend,0)\n","\t\t\tend = self.mutation_pos+extend\n","\t\t\tif len(self.target_fa) <= extend*2:\n","\t\t\t\tsearch_fa = self.target_fa\n","\t\t\t\tstart = 0\n","\t\t\telse:\n","\t\t\t\tsearch_fa = sub_fasta_single(self.target_fa,self.target_pos, start,end)\n","\t\t\tdf = run_pam_finder(search_fa,\"N\"*sgRNA_length,self.PAM,start,self.chr)\n","\t\t\t## df contains all sgRNAs\n","\t\t\tself.N_sgRNA_found = df.shape[0]\n","\n","\t\t\tif df.shape[0] > 0:\n","\t\t\t\tself.DeepSpCas9_dict = get_DeepSpCas9_score(df[4].unique().tolist())\n","\t\t\ttry:\n","\t\t\t\tdf[1] = df[1].astype(int)\n","\t\t\t\tdf[2] = df[2].astype(int)\n","\t\t\t\t## sgRNA name\n","\t\t\t\tdf[4] = df[0]+\"_\"+df[1].astype(str)+\"_\"+df[2].astype(str)+\"_\"+df[5].astype(str)+\"_\"+df[3].astype(str)\n","\t\t\t\tdf.index = df[4].to_list()\n","\t\t\t\tdf['cut'] = [get_gRNA_cut_site(x[1],x[2],x[5],self.offset) for i,x in df.iterrows()]\n","\t\t\t\tdf['target_distance'] = [is_gRNA_valid([r[0],r['cut']],[self.chr,self.mutation_pos],r[5],self.target_pos,len(self.mutation_ref)) for i,r in df.iterrows()]\n","\n","\n","\t\t\t\t## gRNA validation given target mutation\n","\t\t\t\tif debug > 5:\n","\t\t\t\t\tprint (\"total sgRNA found (contain invalid sgRNAs): %s\"%(df.shape[0]))\n","\t\t\t\t\tdf.to_csv(\"%s/%s.init.all_sgRNAs.bed\"%(self.debug_folder,self.name),sep=\"\\t\",header=False,index=False)\n","\n","\t\t\t\tself.valid_init_sgRNA = df[df.target_distance.between(1,max_target_to_sgRNA)][[0,1,2,3,4,5,'cut']]\n","\t\t\t\tcurrent_max_target_to_sgRNA = max_target_to_sgRNA+5\n","\n","\t\t\t\twhile self.valid_init_sgRNA.shape[0] == 0:\n","\t\t\t\t\tif debug>=10:\n","\t\t\t\t\t\tprint (\"increasing max_target_to_sgRNA to:\", current_max_target_to_sgRNA)\n","\t\t\t\t\tif current_max_target_to_sgRNA > max_max_target_to_sgRNA:\n","\t\t\t\t\t\tbreak\n","\t\t\t\t\tself.valid_init_sgRNA = df[df.target_distance.between(1,current_max_target_to_sgRNA)][[0,1,2,3,4,5,'cut']]\n","\t\t\t\t\tif self.valid_init_sgRNA.shape[0] > 0:\n","\t\t\t\t\t\tprint (\"max_target_to_sgRNA increased from %s to %s\"%(max_target_to_sgRNA,current_max_target_to_sgRNA))\n","\t\t\t\t\t\tbreak\n","\t\t\t\t\tcurrent_max_target_to_sgRNA += 5\n","\t\t\t\t## sgRNA features\n","\t\t\t\tself.sgRNA_target_distance_dict = df['target_distance'].to_dict()\n","\n","\t\t\t\tif debug > 5:\n","\t\t\t\t\tprint (\"showing sgRNAs between 1 to %s\"%(current_max_target_to_sgRNA))\n","\t\t\t\t\tprint (df[df.target_distance.between(1,current_max_target_to_sgRNA)])\n","\t\t\t\tdf = df.drop(['target_distance'],axis=1)\n","\t\t\t\tif self.valid_init_sgRNA.shape[0] == 0:\n","\t\t\t\t\tprint (\"No sgRNA was found for %s using %s gRNA_search_space\"%(self.name,extend))\n","\t\t\t\t\tcontinue\n","\t\t\t\telse:\n","\t\t\t\t\tself.found_PE2 = True\n","\t\t\t\t\tprint (\"%s valid sgRNAs found for  %s\"%(self.valid_init_sgRNA.shape[0],self.name))\n","\t\t\t\t\tself.dist_dict = distance_matrix(df.values.tolist())\n","\t\t\t\t\tself.sgRNA_strand_df['+'] = df[df[5]==\"+\"][[0,1,2,3,4,5]]\n","\t\t\t\t\tself.sgRNA_strand_df['-'] = df[df[5]==\"-\"][[0,1,2,3,4,5]]\n","\t\t\t\t\tself.all_sgRNA = df.copy()\n","\t\t\t\t\t# self.sgRNA_target_dPAM_dict = {i: is_dPAM(PAM_seq, RTT, self.offset) for i, r in self.valid_init_sgRNA.iterrows()}\n","\t\t\t\t\t# self.sgRNA_target_dPAM_dict = {i: is_dPAM(self.PAM, self.target_pos,self.ref,self.alt,r[0:4].tolist()) for i, r in self.valid_init_sgRNA.iterrows()}\n","\n","\n","\t\t\t\t\tbreak\n","\n","\t\t\texcept Exception as e:\n","\t\t\t\tprint (e)\n","\t\t\t\tprint (\"Error or No sgRNA was found for %s using %s gRNA_search_space\"%(self.name,extend))\n","\n","\t\tif debug > 5:\n","\t\t\tprint (\"Target name: \",self.name)\n","\t\t\tprint (self.valid_init_sgRNA.head().to_string(index=False))\n","\n","\n","\tdef search(self,debug=0,scaffold=None,**kwargs):\n","\t\t#Second step: search for all possible PBS, RTS, pegRNA, nick-gRNA combos\n","\t\t#Input:length min and max to define search space\n","\t\t#Output:1. valid sgRNA list\n","\t\t#     \t2. PBS dataframe\n","\t\t#       3. RTT dataframe\n","\t\t#       4. ngRNA dataframe\n","\n","\t\tif not self.found_PE2:\n","\t\t\treturn 0\n","\n","\n","\t\tself.sgRNA_list = [sgRNA(\n","\t\t\t\t\t\t\t\tchr = x[0],\n","\t\t\t\t\t\t\t\tstart = x[1],\n","\t\t\t\t\t\t\t\tend = x[2],\n","\t\t\t\t\t\t\t\tseq = x[3],\n","\t\t\t\t\t\t\t\tsgRNA_name = x[4],\n","\t\t\t\t\t\t\t\tstrand = x[5],\n","\t\t\t\t\t\t\t\tcut_position = x[6],\n","\t\t\t\t\t\t\t\tmutation_pos = self.mutation_pos,mutation_ref = self.mutation_ref,mutation_alt = self.mutation_alt,\n","\t\t\t\t\t\t\t\tuser_target_pos = self.target_pos,user_ref = self.ref,user_alt = self.alt,\n","\t\t\t\t\t\t\t\toffset = self.offset,target_to_sgRNA = self.sgRNA_target_distance_dict[x[4]],\n","\t\t\t\t\t\t\t\tvariant_id = self.name,\n","\t\t\t\t\t\t\t\tdist_dict = self.dist_dict,\n","\t\t\t\t\t\t\t\topposite_strand_sgRNAs = self.sgRNA_strand_df[get_opposite_strand(x[5])],\n","\t\t\t\t\t\t\t\tall_sgRNA_df = self.all_sgRNA,\n","\t\t\t\t\t\t\t\ttarget_fa = self.target_fa,\n","\t\t\t\t\t\t\t\tscaffold_seq = scaffold,\n","\t\t\t\t\t\t\t\tPAM = self.PAM,\n","\t\t\t\t\t\t\t\tDeepSpCas9 = self.DeepSpCas9_dict[x[3]]\n","\t\t\t\t\t\t\t\t)\n","\t\t\t\t\t\tfor x in self.valid_init_sgRNA.values.tolist()]\n","\n","\t\t[run_sgRNA_search(s,**dict(kwargs,debug=debug)) for s in self.sgRNA_list]\n","\n","\t\tself.rawX = pd.concat([s.rawX for s in self.sgRNA_list])\n","\t\tif debug>=10:\n","\t\t\tprint (self.name,\"combined rawX:\")\n","\t\t\tprint (self.rawX.head())\n","\t\tif self.rawX.shape[0]==0:\n","\t\t\tself.found_PE2=False\n","\t\t\treturn 0\n","\t\tself.X = pd.concat([s.X for s in self.sgRNA_list])\n","\t\tno_ngRNA = sum([s.no_ngRNA for s in self.sgRNA_list])\n","\t\tif no_ngRNA == len(self.sgRNA_list):\n","\t\t\tprint (\"%s only PE2 found\"%(self.name))\n","\t\telse:\n","\t\t\tself.found_PE3 = True\n","\n","\n","\t\tself.X['N_insertions'] = self.ref_alt[2]\n","\t\tself.X['N_subsitution'] = self.ref_alt[1]\n","\t\tself.X['N_deletion'] = self.ref_alt[3]\n","\n","\n","\t\tself.found_PE3b = (self.X['is_PE3b']==1).any()\n","\t\tself.found_dPAM = (self.X['is_dPAM']==1).any()\n","\n","\n","\n","\n","#بعد پیدا کردن همه  رشته ها حالا باید اسکور آنها را پیش بینی کنیم.\n","\tdef predict(self,debug=0,PE2_model=None,PE3_model=None,**kwargs):\n","\t\tif not self.found_PE2:\n","\t\t\treturn 0\n","\n","\t\t#مدل های ذخیره شده را اینجا باز می کند\n","\t\twith open(PE2_model, 'rb') as file:\n","\t\t\txgb_model_PE2 = pickle.load(file)\n","\t\twith open(PE3_model, 'rb') as file:\n","\t\t\txgb_model_PE3 = pickle.load(file)\n","\n","\t\tself.X = self.X[self.feature_for_prediction]\n","\t\tself.X.columns = self.PE3_model_feature_names\n","\n","\t\t# Split into PE2 and PE3 feature matrix\n","\t\tX_PE2 = self.X[self.X.nick_to_pegRNA.isnull()]\n","\t\tX_PE3 = self.X[~self.X.nick_to_pegRNA.isnull()]\n","\n","#تابع پیش بینی را اینجا فراخوانی می کنیم\n","\t\tpred_y_PE2 = xgb_model_PE2.predict(X_PE2[self.PE2_model_feature_names])\n","\t\tpred_y_PE3 = xgb_model_PE3.predict(X_PE3)\n","\n","\t\tmyPred = pd.DataFrame()\n","\t#نتایج هر 3 مدل با هم ترکیب می شود.\n","\t#pred_y_PE2.tolist() OR pred_y_PE3.tolist()\n","\t\tmyPred['predicted_efficiency'] = pred_y_PE2.tolist()+pred_y_PE3.tolist()#+DNABERTmodel.tolist()+myoldmodel()\n","\t\tmyPred.index = X_PE2.index.tolist()+X_PE3.index.tolist()\n","\t\tself.X_p = pd.concat([self.X,myPred],axis=1)\n","\t\tself.rawX['predicted_efficiency'] = myPred.loc[self.rawX.index]['predicted_efficiency']\n","\n","\n","#این دو مقدار نهایی حاصل از کد من هست که باید پرینت شود.\n","\t\tself.X_p = self.X_p.sort_values(\"predicted_efficiency\",ascending=False)\n","\t\tself.rawX = self.rawX.sort_values(\"predicted_efficiency\",ascending=False)\n","\n","\n","\t\t# میتوانی این قسمت ها را حذف کنی\n","\t\t# recommend dPAM when ever possible\n","\t\ttmp = self.rawX.copy()\n","\t\tif self.found_dPAM:\n","\t\t\ttmp = tmp[tmp.index.str.contains('dPAM')]\n","\t\t# recommend PE3b except when its predicted efficiency is 10% smaller than the highest ones\n","\t\ttmp['rank'] = tmp.apply(lambda r:force_recommend_dPAM_PE3b(r,tmp.predicted_efficiency.max()),axis=1)\n","\t\ttmp = tmp.sort_values(['rank','predicted_efficiency'],ascending=False)\n","\t\ttmp = tmp.drop(['rank'],axis=1)\n","\t\tself.topX = tmp.loc[tmp.index[0]]\n","\n","\n","\n","def run_sgRNA_search(s,**kwargs):\n","\ts.find_RTT(**kwargs)\n","\ts.find_PBS(**kwargs)\n","\ts.find_nick_gRNA(**kwargs)\n","\ts.get_rawX_and_X(**kwargs)\n"],"metadata":{"id":"EqWo_liWMQgM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AXLnpbbnqP7Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jVXI5Gg5KWD7"},"source":["# Final model"]},{"cell_type":"code","source":["def print_parameters(myDict):\n","\tmyGroup = {}\n","\tmyGroup['Prime Editing'] = ['genome_fasta','scaffold','n_jobs','debug','PE2_model','PE3_model','extend_length']\n","\tmyGroup['PBS searching'] = ['min_PBS_length','max_PBS_length']\n","\tmyGroup['RTT searching'] = ['min_RTT_length','max_RTT_length','min_distance_RTT5','max_max_RTT_length']\n","\tmyGroup['sgRNA searching'] = ['gRNA_search_space','sgRNA_length','offset','PAM','max_target_to_sgRNA','max_max_target_to_sgRNA']\n","\tmyGroup['ngRNA searching'] = ['max_ngRNA_distance']\n","\tfor k in myGroup:\n","\t\tprint_group(myDict,myGroup[k],k)\n","\n","\n","def print_group(myDict,myList,group_title):\n","\tprint (\"-------- Parameter Group: %s --------\"%(group_title))\n","\tfor l in myList:\n","\t\tprint (\"%s: %s\"%(l,myDict[l]))\n","\n","\n","#تعریف پارامترهای پیش فرض\n","def get_parameters(config):\n","\tp_dir = os.path.dirname(os.path.realpath(__file__)) + \"/\"\n","\t# return dict\n","\tparameters = {}\n","\t# default parameters\n","\tpre_defined_list = {}\n","\t#------------ Prime Editing related-----------\n","\t#این ورودی را باید برای برنامه فراهم کنم\n","\tpre_defined_list[\"genome_fasta\"] = \"/home/yli11/Data/Human/hg19/fasta/hg19.fa\"\n","\tpre_defined_list[\"n_jobs\"] = -1\n","\tpre_defined_list[\"scaffold\"] = \"GTTTTAGAGCTAGAAATAGCAAGTTAAAATAAGGCTAGTCCGTTATCAACTTGAAAAAGTGGCACCGAGTCGGTGC\"\n","\tpre_defined_list[\"debug\"] = 0\n","\tpre_defined_list[\"extend_length\"] = 1000 # extracting +- 1000bp center at target pos from the genome, in 99.9% cases, you don't need to change this. If change to less than 500, will trigger fasta input mode, may cause error.\n","\t#   مدل های از پیش آموزش دیده را اینجا معرفی می کنم.\n","\t# می تونی DEEPPRIME بزاری\n","\tpre_defined_list[\"PE2_model\"] = p_dir+\"../model/PE2_model_final.py\"\n","\tpre_defined_list[\"PE3_model\"] = p_dir+\"../model/PE3_model_final.py\"\n","\n","\t#------------ PBS -----------\n","\tpre_defined_list[\"min_PBS_length\"] = 10\n","\tpre_defined_list[\"max_PBS_length\"] = 15\n","\n","\t#------------ RTT -----------\n","\tpre_defined_list[\"min_RTT_length\"] = 10\n","\tpre_defined_list[\"max_RTT_length\"] = 20 # if no candidate is found, this value will be increased by 5, max to max_max_RTT_length\n","\tpre_defined_list[\"max_max_RTT_length\"] = 50\n","\tpre_defined_list[\"min_distance_RTT5\"] = 5\n","\n","\t#------------ sgRNA -----------\n","\tpre_defined_list[\"gRNA_search_space\"] = 200\n","\tpre_defined_list[\"sgRNA_length\"] = 20\n","\tpre_defined_list[\"offset\"] = -3\n","\tpre_defined_list[\"PAM\"] = \"NGG\"\n","\tpre_defined_list[\"max_target_to_sgRNA\"] = 10 # if no candidate is found, this value will be increased by 5, max to max_max_target_to_sgRNA\n","\tpre_defined_list[\"max_max_target_to_sgRNA\"] = 30\n","\n","\t#------------ ngRNA ------------\n","\tpre_defined_list[\"max_ngRNA_distance\"] = 100 # if no candidate is found, this value will be increased by 20, max to max_max_ngRNA_distance\n","\tpre_defined_list[\"max_max_ngRNA_distance\"] = 200\n","\tpre_defined_list[\"search_iteration\"] = 1 # not affect anything\n","\n","\ttry:\n","\t\twith open(config, 'r') as f:\n","\t\t\tmanifest_data = yaml.load(f,Loader=yaml.FullLoader)\n","\texcept:\n","\t\tprint (\"Config data is not provided or not parsed successfully, Default parameters were used.\")\n","\n","\tfor p in pre_defined_list:\n","\t\ttry:\n","\t\t\tparameters[p] = manifest_data[p]\n","\t\texcept:\n","\t\t\tparameters[p] = pre_defined_list[p]\n","\treturn parameters\n"],"metadata":{"id":"4SaTqUKO7Vap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QuS79sLQrLqK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"executionInfo":{"elapsed":10,"status":"error","timestamp":1693465804769,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"5LhsX47qKgxW","outputId":"dfa0688d-d355-4b82-fe47-c3ef33bc720e"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-eff1db8ae911>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-eff1db8ae911>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# ------------------------- get parameters ----------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#from easy_prime.utils import get_parameters, print_parameters,vcf2fasta,fasta2vcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mprint_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'get_parameters' is not defined"]}],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","import sys\n","import argparse\n","import datetime\n","import getpass\n","import os\n","\n","#Output: The output folder will contain:\n","#1. all pegRNA + ngRNA combination for the input vcf file\n","#2. top1 pegRNA + ngRNA combination for each variant\n","#3. visualization of the top1s [TODO]\n","#4. a summary file of each variant\n","\n","# گرفتن ورودی ها به شکل فایل\n","def my_args():\n","\tmainParser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter,description=\"pegRNA design\")\n","\tusername = getpass.getuser()\n","\n","\tmainParser.add_argument('-f','--input_file',  help=\"vcf or fasta\",required=True)\n","\tmainParser.add_argument('-c','--config',  help=\"A YAML file specifying parameters\",default=None)\n","\n","\tmainParser.add_argument('-o','--output',  help=\"output dir\",default=\"easy_prime_%s_%s_result_dir\"%(username,str(datetime.date.today())))\n","\n","\t#add parameters above\n","\targs = mainParser.parse_args()\n","\treturn args\n","\n","\n","# دو گامی که در سکشن بالا تعریف کرده ام را اینجا فراخوانی می کنم.\n","def run_steps(t,**kwargs):\n","\tt.init(**kwargs)\n","\tt.search(**kwargs)\n","\tt.predict(**kwargs)\n","\treturn [t.topX,t.rawX,t.X_p,t.found_PE3b,t.found_PE3,t.found_dPAM,t.found_PE2,t.N_sgRNA_found]\n","\n","\n","\n"]},{"cell_type":"code","source":["\n","def main():\n","\n","\t#پارامترها را به صورت فایل میگیرم\n","  #برای هر تارگت کلاس بالا را فراخوانی می کنم\n","\targs = my_args()\n","\t# ------------------------- get parameters ----------------------------------------------\n","\n","\tparameters = get_parameters(args.config)\n","\tprint_parameters(parameters)\n","\n","\ttry:\n","\t\tvcf = pd.read_csv(args.input_file,comment=\"#\",sep=\"\\t\",header=None)\n","\t\tvcf[1] = vcf[1].astype(int)\n","\t\tvcf =vcf.drop_duplicates(2) # remove duplicated names\n","\t\tvcf[3] = [x.upper() for x in vcf[3]]\n","\t\tvcf[4] = [x.upper() for x in vcf[4]]\n","\t\tvcf[5] = vcf2fasta(vcf,**parameters)\n","\t\tvcf = vcf[list(range(6))]\n","\n","\texcept:\n","\t\ttry:\n","\t\t\tprint (\"Reading fasta file: %s\"%(args.input_file))\n","\t\t\tvcf = fasta2vcf(args.input_file)\n","\t\t\tprint (vcf)\n","\t\texcept:\n","\t\t\tprint (\"Can't read %s as vcf or fasta. Please check input. Exit...\"%(args.input_file))\n","\t\t\texit()\n","\n","\tvariant_list = vcf[2].tolist()\n","\n","\n","## for each target, create target mutation class\n","\tmy_targets = [target_mutation(*r) for i,r in vcf.iterrows()]\n","\n","\n","\n","#find best pegRNAs\n","# backend can affect this parallization, if so, user show use n_jobs=1\n","\tif parameters['n_jobs'] == 1:\n","\t\tdf_list = [run_steps(t,**parameters) for t in my_targets]\n","\telse:\n","\t\tfrom joblib import Parallel, delayed\n","\t\tdf_list = Parallel(n_jobs=parameters['n_jobs'],verbose=10)(delayed(run_steps)(t,**parameters) for t in my_targets)\n","\n","\n","#--------------------------------------------ضروری نیست می توانی این ها را حذف کنی-------------------------------------------------------------------------\n","\t# save output\n","\t#یا این کد ها و یا کدهای نوشته شده قبلی، فقط چاپ سطری در بالا\n","\timport subprocess\n","\tsubprocess.call(\"mkdir -p %s\"%(args.output),shell=True)\n","\tsummary = pd.DataFrame([x[3:8] for x in df_list]).astype(int)\n","\tsummary.columns = ['found_PE3b','found_PE3','found_dPAM','found_PE2',\"N_sgRNA_found\"]\n","\tsummary.index = variant_list\n","\tsummary.to_csv(\"%s/summary.csv\"%(args.output),index=True)\n","\n","\tdf_top = pd.concat([x[0] for x in df_list])\n","\tif df_top.shape[0]==0:\n","\t\tprint (\"no pegRNA were found for the input file: %s\"%(args.input_file))\n","\t\tsys.exit()\n","\tdf_top = df_top.sort_values(\"predicted_efficiency\",ascending=False)\n","\tdf_top.to_csv(\"%s/topX_pegRNAs.csv\"%(args.output),index=False)\n","\n","\tdf_all = pd.concat([x[1] for x in df_list])\n","\tdf_all = df_all.sort_values(\"predicted_efficiency\",ascending=False)\n","\tdf_all.to_csv(\"%s/rawX_pegRNAs.csv.gz\"%(args.output),index=False,compression=\"gzip\")\n","\n","\tX_p = pd.concat([x[2] for x in df_list])\n","\tX_p = X_p.sort_values(\"predicted_efficiency\",ascending=False)\n","\tX_p.to_csv(\"%s/X_p_pegRNAs.csv.gz\"%(args.output),index=True,compression=\"gzip\")\n","\n","\n","\n","\n","if __name__ == \"__main__\":\n","\tmain()"],"metadata":{"id":"ct_dLa95zTHB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hFGrW1nMQFa-"},"source":["#visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9284,"status":"ok","timestamp":1692256239325,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"lPtY7LawVIfJ","outputId":"995c68f1-e75c-49cf-ba4e-a9257add4d50"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting dna_features_viewer\n","  Downloading dna_features_viewer-3.1.2-py3-none-any.whl (31 kB)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from dna_features_viewer) (3.7.1)\n","Requirement already satisfied: Biopython in /usr/local/lib/python3.10/dist-packages (from dna_features_viewer) (1.81)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dna_features_viewer) (23.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->dna_features_viewer) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->dna_features_viewer) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->dna_features_viewer) (4.42.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->dna_features_viewer) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->dna_features_viewer) (1.23.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->dna_features_viewer) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->dna_features_viewer) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->dna_features_viewer) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->dna_features_viewer) (1.16.0)\n","Installing collected packages: dna_features_viewer\n","Successfully installed dna_features_viewer-3.1.2\n"]}],"source":["!pip install dna_features_viewer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"elapsed":1176,"status":"error","timestamp":1692256245570,"user":{"displayName":"nasrin alipanahi","userId":"15324140091620980566"},"user_tz":-210},"id":"kqUVxH2OPpuD","outputId":"e76eebad-6c85-4d83-d155-74704ce9697c"},"outputs":[{"name":"stderr","output_type":"stream","text":["usage: ipykernel_launcher.py [-h] -f RAWX -s GENOME_FASTA [-t FIGURE_TYPE]\n","                             [--sample_id SAMPLE_ID]\n","                             [--output_file_name OUTPUT_FILE_NAME] [-o OUTPUT]\n","ipykernel_launcher.py: error: the following arguments are required: -s/--genome_fasta\n"]},{"ename":"SystemExit","evalue":"ignored","output_type":"error","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]}],"source":["#visualization\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import sys\n","import argparse\n","import datetime\n","import getpass\n","import os\n","from dna_features_viewer import GraphicFeature, GraphicRecord\n","import pandas as pd\n","import uuid\n","import subprocess\n","import matplotlib.pyplot as plt\n","npg_colors = [\"#E64B35\",\"#4DBBD5\",\"#00A087\",\"#3C5488\",\"#F39B7F\",\"#464d4f\"]\n","my_colors = {}\n","my_colors['sgRNA'] = npg_colors[0]\n","my_colors['PBS'] = npg_colors[1]\n","my_colors['RTT'] = npg_colors[2]\n","my_colors['ngRNA'] = npg_colors[3]\n","my_colors['variant'] = \"#e6fc3f\"\n","\"\"\"\n","\n","Output\n","--------\n","\n","The output folder will contain:\n","1. all pegRNA + ngRNA combination for the input vcf file\n","2. top1 pegRNA + ngRNA combination for each variant\n","3. visualization of the top1s [TODO]\n","4. a summary file of each variant\n","\n","\"\"\"\n","\n","def my_args():\n","\tmainParser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter,description=\"easy_prime for pegRNA design\")\n","\tusername = getpass.getuser()\n","\n","\tmainParser.add_argument('-f','--rawX',  help=\"input rawX format, last column with predicted efficiency\",required=True)\n","\tmainParser.add_argument('-s','--genome_fasta',  help=\"input genome sequences\",required=True)\n","\tmainParser.add_argument('-t','--figure_type',  help=\"png or pdf\",default=\"png\")\n","\tmainParser.add_argument('--sample_id',  help=\"only plot this sample id\",default=None)\n","\tmainParser.add_argument('--output_file_name',  help=\"use only when plot one pegRNA, output_file_name.figure_type, will overwrite -t -o options.\",default=None)\n","\tmainParser.add_argument('-o','--output',  help=\"output dir\",default=\"easy_prime_vis_%s_%s\"%(username,str(datetime.date.today())))\n","\n","\t##------- add parameters above ---------------------\n","\targs = mainParser.parse_args()\n","\treturn args\n","\n","def write_file(file_name,message):\n","\tout = open(file_name,\"wt\")\n","\tout.write(message)\n","\tout.close()\n","def get_fasta_single(chr,start,end,genome_fasta=None):\n","\tout_bed = str(uuid.uuid4()).split(\"-\")[-1]\n","\tout_fa = str(uuid.uuid4()).split(\"-\")[-1]\n","\twrite_file(out_bed,\"%s\\t%s\\t%s\"%(chr,start,end))\n","\tcommand = \"bedtools getfasta -fi %s -bed %s -fo %s -tab\"%(genome_fasta,out_bed,out_fa)\n","\tsubprocess.call(command,shell=True)\n","\tlines = open(out_fa).readlines()[0]\n","\tseq = lines.split()[-1]\n","\tsubprocess.call(\"rm %s;rm %s\"%(out_bed,out_fa),shell=True)\n","\treturn seq\n","def get_strand(x):\n","\tif x == \"+\":\n","\t\treturn 1\n","\telse:\n","\t\treturn -1\n","def find_mutation_pos(pos,ref,alt):\n","\t\"\"\"solve the problem when user specification of ref, alt contain redundancy\n","\tATTTT-> ATTT, should be T -> \"\"\n","\tG - > GC will  be \"\" C\n","\t\"\"\"\n","\tcount=0\n","\tfor i in range(min(len(ref),len(alt))):\n","\t\tx=ref[i]\n","\t\ty=alt[i]\n","\t\tif x != y:\n","\t\t\treturn pos,ref[i:],alt[i:]\n","\t\telse:\n","\t\t\tpos+=1\n","\t\t\tcount+=1\n","\treturn pos,ref[count:],alt[count:]\n","\n","def plot_main(df,output=None,genome_fasta=None,figure_type=\"png\",output_file_name=None,**kwargs):\n","\t\"\"\"Given one instance of Prime Editing prediction (rawX format), generate DNA visualization\n","\n","\tInput\n","\t--------\n","\tthe data frame contains 4 rows: RTT, PBS, sgRNA, ngRNA\n","\n","\t\"\"\"\n","\tpegRNA_id = df.index.tolist()[0]\n","\tvariant_id = pegRNA_id.split(\"_\")[0]\n","\tchr = df['CHROM'][0]\n","\tstart = df['start'].min()\n","\tstart -= start%10\n","\tstart -= 1\n","\tstart = max(start,0)\n","\tend = df['end'].max()\n","\tend -= end%10\n","\tend += 10\n","\tdf = df.fillna(\"\")\n","\tvariant_pos = df.POS.min()\n","\tref = df.REF[0]\n","\talt = df.ALT[0]\n","\ttry:\n","\t\tcorrect_pos,new_ref,new_alt = find_mutation_pos(variant_pos,ref,alt)\n","\texcept:\n","\t\tcorrect_pos,new_ref,new_alt = variant_pos,ref,alt\n","\tpredicted_efficiency = df.predicted_efficiency[0]*100\n","\tpos = variant_pos-start\n","\tpos_rel_correct = correct_pos-start\n","\tsequence = get_fasta_single(chr,start,end,genome_fasta).upper()\n","\n","\tfeature_list = []\n","\tfor s,r in df.iterrows():\n","\t\tr_start = r.start-start\n","\t\tr_end = r_start+(r.end-r.start)\n","\t\tr_strand = get_strand(r.strand)\n","\t\tgf = GraphicFeature(start=r_start, end=r_end, strand=r_strand,\n","\t\t\tcolor=my_colors[r.type],label=r.type)\n","\t\tfeature_list.append(gf)\n","\trecord = GraphicRecord(sequence=sequence, features=feature_list)\n","\n","\tax, _ = record.plot(figure_width=int(len(sequence)/5))\n","\trecord.plot_sequence(ax)\n","\tif len(new_ref) > 0:\n","\t\tfor xxx in range(len(new_ref)):\n","\t\t\tax.fill_between((pos_rel_correct-1.5+xxx, pos_rel_correct-0.5+xxx), +1000, -1000, alpha=0.5,color=my_colors['variant'])\n","\telse:\n","\t\tax.fill_between((pos-1.5, pos-0.5), +1000, -1000, alpha=0.5,color=my_colors['variant'])\n","\tlocs, labels = plt.xticks()\n","\tnew_labels = []\n","\tflag = True\n","\tfor i in locs:\n","\t\tif flag:\n","\t\t\tnew_labels.append(\"%s %s\"%(chr,int(start+i+1)))\n","\t\t\tflag=False\n","\t\telse:\n","\t\t\tnew_labels.append(int(start+i+1))\n","\tplt.xticks(locs,new_labels)\n","\tdPAM=\"\"\n","\tif \"dPAM\" in pegRNA_id:\n","\t\tdPAM = \"PAM disruption\"\n","\tif \"PE3b\" in pegRNA_id:\n","\t\tdPAM += \", PE3b\"\n","\tif dPAM!=\"\":\n","\t\tdPAM += \"\\n\"\n","\tmyTitle = \"ID: %s, CHR: %s, POS: %s, REF: %s, ALT: %s \\n %s Predicted efficiency: %.1f\"%(variant_id,chr,variant_pos,ref,alt,dPAM,predicted_efficiency)+\"%\"\n","\n","\n","\tplt.title(myTitle)\n","\tif output_file_name!= None:\n","\t\tax.figure.savefig(output_file_name, bbox_inches='tight')\n","\telse:\n","\t\tax.figure.savefig(f'{output}/{pegRNA_id}.{figure_type}', bbox_inches='tight')\n","\n","\n","def main():\n","\n","\targs = my_args()\n","\tif not os.path.isfile(args.genome_fasta):\n","\t\tprint (f\"genome fasta NOT FOUND: {args.genome_fasta}\")\n","\tdf = pd.read_csv(args.rawX,index_col=0)\n","\tsubprocess.call(f\"mkdir -p {args.output}\",shell=True)\n","\tfor i in df.index.unique().tolist():\n","\t\tif args.sample_id != None:\n","\t\t\tif i != args.sample_id:\n","\t\t\t\tcontinue\n","\t\tprint (f\"Processing {i}...\")\n","\t\tplot_main(df.loc[i],**vars(args))\n","\n","\n","if __name__ == \"__main__\":\n","\tmain()"]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyODclPf1eUJqWosdgfFiVvJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1c155b3d74c2405bb4540a3aaee253b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_813363e6576f45abb8c00adbc907dd57","IPY_MODEL_1662bfe054944570af1d7a21eca7fa35","IPY_MODEL_4823f9fc3386403395b7bc632beaaf20"],"layout":"IPY_MODEL_b26e5762c972496f8bd3e6211580f764"}},"813363e6576f45abb8c00adbc907dd57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f438617b09c246f6a7feb1e7fec7a970","placeholder":"​","style":"IPY_MODEL_481236939b3f4dc9bea725e98fa546ae","value":"Downloading (…)lve/main/config.json: 100%"}},"1662bfe054944570af1d7a21eca7fa35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bea2b9b50ace43909f255dbc60807d2e","max":536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62070c96f5b14e9f88b434a274bf1fb4","value":536}},"4823f9fc3386403395b7bc632beaaf20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_982ebf474326463594631a06ae3c5f66","placeholder":"​","style":"IPY_MODEL_3dc5ba9278f44128995a28fc56e9b077","value":" 536/536 [00:00&lt;00:00, 37.1kB/s]"}},"b26e5762c972496f8bd3e6211580f764":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f438617b09c246f6a7feb1e7fec7a970":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"481236939b3f4dc9bea725e98fa546ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bea2b9b50ace43909f255dbc60807d2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62070c96f5b14e9f88b434a274bf1fb4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"982ebf474326463594631a06ae3c5f66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dc5ba9278f44128995a28fc56e9b077":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9632be642e1646158bee913582e8b44b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b2b28054d1e4f4b96deeb7d5772d2e8","IPY_MODEL_b2ae4a32e73c44e89aa90c5de9be3b5d","IPY_MODEL_53ab2127905c45f086d458566ab4b290"],"layout":"IPY_MODEL_8ffc0cd03e5d461fb6e20521917a2479"}},"3b2b28054d1e4f4b96deeb7d5772d2e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e07c3ae0af5e48429306c3bfd45e0eca","placeholder":"​","style":"IPY_MODEL_b0a0c52704dd45348fa390f7d746c3ea","value":"Downloading pytorch_model.bin: 100%"}},"b2ae4a32e73c44e89aa90c5de9be3b5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca5e8c834e734b81b3855549f6cb002d","max":186714784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54097f16bef749b1a81f7b319f6d8467","value":186714784}},"53ab2127905c45f086d458566ab4b290":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3ac4c5365d84e28a235b868e498d57d","placeholder":"​","style":"IPY_MODEL_afebb2a91a314a82ad92a33afd6ca783","value":" 187M/187M [00:04&lt;00:00, 51.5MB/s]"}},"8ffc0cd03e5d461fb6e20521917a2479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e07c3ae0af5e48429306c3bfd45e0eca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0a0c52704dd45348fa390f7d746c3ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca5e8c834e734b81b3855549f6cb002d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54097f16bef749b1a81f7b319f6d8467":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b3ac4c5365d84e28a235b868e498d57d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afebb2a91a314a82ad92a33afd6ca783":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}